# Tech Stack and Conventions

## Last updated: 2025-07-09

This document captures the agreed-upon architectural decisions for persistence, auth, media storage, and future analytics.

## 1. Stack Overview

| Layer | Choice | Rationale |
|-------|--------|----------|
| Types | snake_case everywhere - DB & App | Supabase uses snake_case for table names and variables, and this is easy to read and no surprises or need to convert in FE. transient variables in react can still use camelCase if desired. |
| Relational DB | **Postgres (Supabase)** | Managed Postgres with integrated auth & RLS; fits structured research data. |
| Auth | **Supabase Auth** | Email / SSO; interviewer accounts map to `auth.users`. |
| Media Storage | **Cloudflare R2** | Low-cost object storage for large audio / video files. Supabase stores only signed-URL + metadata. |
| Vector Search (future) | **pgvector** extension on Supabase | Enables semantic similarity between themes / categories. |
| App Framework | **React Router 7** | Universal React routing with feature-based organization; middleware-based auth; context-driven data access; allows o3/BAML processing in loaders/actions. |

## 2. Tenancy & ACL Model

* Multi-tenant SaaS → every row scoped by `accounts.account_id` (UUID).
* `accounts` & `user_accounts` control membership & roles.
* Row-Level Security (RLS) policies restrict CRUD to members of the same `account_id`.
* Media ACL: Not stored right now, just uploading to AAI for transcription. Future: files stored in R2 under path `account_id/<uuid>`.  Download/stream via **signed URLs** generated by a Supabase Edge Function that validates the caller’s JWT & account membership.

## 3. High-Level Entity Diagram

<!-- TODO: add diagram -->

## 4. Table & Types Specifications (supabase schema `public`)

This project strictly follows the declarative schema definition approach defined (here)[`/docs/supabase-howto.md`].

### 4.x Types

Types are generated from the DB schema using `supabase/types.ts`. Run `supabase gen types typescript --project-id rbginqvgkonnoktrttqv > supabase/types.ts` to generate the types and then add the one-line export type … = Tables<"..."> helper in the relevant feature’s types.ts.

Auto-generate types from queries in our db.ts files that components can import. We can get the nested CountriesWithCities type like this:

```ts
import { QueryResult, QueryData, QueryError } from '@supabase/supabase-js'
const countriesWithCitiesQuery = supabase.from('countries').select(`
  id,
  name,
  cities (
    id,
    name
  )
`)
type CountriesWithCities = QueryData<typeof countriesWithCitiesQuery>
const { data, error } = await countriesWithCitiesQuery
if (error) throw error
const countriesWithCities: CountriesWithCities = data
```

Reference: [docs](https://supabase.com/docs/guides/api/rest/generating-types#type-shorthands)

Prefer typed columns for data, but in future if we need to store JSONB, use `https://supabase.com/docs/guides/api/rest/generating-types#defining-custom-json-types` to define custom JSON types.

### 4.1  Core Multi-Tenant Accounts in schema `accounts`

Using basejump inspired separate accounts schema
Migration files for setting up and configuration done.
Definitive table specs to be stored in `supabase/schemas`

### Core Tables

accounts
accounts_users
projects
people
personas
interviews
insights
tags
opportunities

TODO:

* [x] separate tables into files
* [x] add indexes, triggers, RLS policies
* [x] renamed research_projects -> projects. modify in FE too
* [x] error saving new user (maybe due to missing org_id and incomplete setup of new schema. Redo and retry)
* [x] New user signup should create account and project
* [x] AddInterview button needs accountId and projectId to send to /api/upload-file in body. _NavLayout loader gets this db and passes it down in AuthContext. So AddInterviewButton should get it from there via useAuthContext?

## 4.10 Vector Similarity (pgvector)

* Enable `CREATE EXTENSION IF NOT EXISTS pgvector;` on Supabase.
* Store `embedding` vectors for `themes` & optionally `insights`.
* Example query to populate embeddings with OpenAI:

  ```sql
  update themes
  set embedding = openai_embed(name)
  where embedding is null;
  ```

## 4.11 Creation & Updates & ACLs

### 4.11.1 Creation

When a user signs up, they are created in `auth.users` by Supabase,
Triggers should then:

* create a default `organizations` record with `name: "My Team"` and `role: owner`.
* create a default `user_org_memberships` record with `role: owner`.
* create a default `user_settings` record with `theme: "dark"`, `language: "en"`, `title: ""`, `role: "interviewer"`, `onboarding_completed: false`, `app_activity: {}`, `metadata: {}`.
* create a default `research_projects` record with `code: "001"` and `title: "My First Project"` and `org_id` linked to the default `organizations` record.

### 4.11.2 Updates

* Create a trigger for insert and update to set field `updated_at` to `now()`.
* Run this trigger on all tables that have an `updated_at` field.

### 4.11.3 ACLs

* Row-Level Security (RLS) policies restrict CRUD to members of the same `org_id`.

## 4.11.3 ACLs

* Row-Level Security (RLS) policies restrict CRUD to members of the same `org_id`.
**`insights`**, **`quotes`**, **`themes`**, **`opportunities`**, **`personas`**, **`research_projects`**, **`people`**, **`interviews`**, **`media_files`**:
  * Members of the org can read, create, update, delete rows in these tables

The following tables have additional policies:

* **`organizations`**:
  * `insert` open only to API/service role; users never create orgs directly.
  * No delete by user.
  * Only owner can update.
  * (Prevent spam orgs.)

* **`user_org_memberships`**:
  * `select` owners; members see only their own row.
  * `insert/delete` owners only.
  * (Hide the full roster from non-admins.)

* **`user_settings`**:
  * Use `user_id = auth.uid()` in addition to `is_in_org(org_id)` for read/write.
  * (Each user edits only their prefs.)

* **`media_files`**:
  * Allow `insert` when `uploaded_by = auth.uid()` and `is_in_org(org_id)`.
  * (Enforce proper attribution.)

* **`tags`** (global):
  * Leave RLS **off** or make it read-only for everyone, insert/update restricted to service role.
  * (Shared glossary.)

Materialized views (`theme_counts_mv`) refresh under service role; add `for select using (is_in_org(org_id))` if it has `org_id`. (Keep isolation consistent.)

* Media ACL: files stored in R2 under path `org_id/<uuid>`.  Download/stream via **signed URLs** generated by a Supabase Edge Function that validates the caller’s JWT & org membership.

### Core Pattern Sample Code

```sql
-- helper that lists the orgs the signed‑in user belongs to
create or replace view v_current_user_orgs as
select org_id, role
from public.user_org_memberships
where user_id = auth.uid();

-- convenience Boolean (faster than EXISTS sub‑query)
create or replace function is_in_org(uuid) returns boolean
language sql stable as $$
  select exists(
    select 1 from v_current_user_orgs where org_id = $1
  );
$$;
```

**Default policy template**

```sql
alter table <TABLE> enable row level security;

-- Read
create policy "org members can read"
  on <TABLE>
  for select
  using ( is_in_org(org_id) );

-- Write (any member)
create policy "org members can insert"
  on <TABLE>
  for insert
  with check ( is_in_org(org_id) );

-- Update/Delete (only owners)
create policy "only owners can modify"
  on <TABLE>
  for update using ( exists (
        select 1 from v_current_user_orgs
        where org_id = <TABLE>.org_id and role = 'owner'
  ));
create policy "only owners can delete"
  on <TABLE>
  for delete using ( exists (
        select 1 from v_current_user_orgs
        where org_id = <TABLE>.org_id and role = 'owner'
  ));
```

## 5. Routing

We are using programmatic route files, rolled up into app/routes.ts to support feature consolidation, where a feature directory has components, pages and a route file. Each feature route file gets aggregated into a single app/routes.ts. [docs](https://reactrouter.com/start/framework/routing)

| Syntax                         | Resulting URL / behaviour                                                                       | Built‑in?                                                         |
| ------------------------------ | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| `_index.tsx`                   | Parent URL itself (index route)                                                                 | ✔                                                                 |
| `parent.child.tsx`             | `/parent/child` (the dot adds **/** and nests layouts)                                          | ✔ ([React Router][1])                                             |
| `$id.tsx`                      | `/123` dynamic segment → `params.id`                                                            | ✔ ([React Router][1])                                             |
| `($lang).page.tsx`             | `/page` **or** `/en/page` – segment wrapped in **()** is *optional*                             | ✔ ([React Router][1])                                             |
| `_auth.login.tsx`              | `/login` but rendered inside a hidden “auth” layout (leading `_` creates a **pathless layout**) | ✔ ([React Router][1])                                             |
| `parent_.mine.tsx`             | `/parent/mine` with **no** parent layout (trailing `_` removes layout nesting)                  | ✔ ([React Router][1])                                             |
| `$.tsx` or `files.$.tsx`       | Splat / catch‑all (`/anything`)                                                                 | ✔ ([React Router][1])                                             |
| `sitemap[.]xml.tsx`            | Escapes special chars → `/sitemap.xml`                                                          | ✔ ([React Router][1])                                             |
| `folder+` (e.g. `_dashboard+`) | Treat folder as a route segment **and** let you co‑locate extra files without becoming routes   | **➕ Requires** community add‑on `remix-flat-routes` ([GitHub][2]) |

[1]: https://reactrouter.com/how-to/file-route-conventions "File Route Conventions  | React Router"
[2]: https://github.com/remix-run/remix/discussions/8473 "Nested folders and nested / non-nested routes · remix-run remix · Discussion #8473 · GitHub"

## 6. Process Interview Media & Extract Insights

### 6.1 Ingestion & Storage

| Phase | Storage | Key Steps |
|-------|---------|-----------|
| **1 – MVP** | Google Drive links | 1. User pastes a Drive URL.<br>2. Convert the link to a direct-download URL (per AssemblyAI guide). ** Note we had issues, Google did not return clean download links, instead had virus scan html etc. files too large. So we are doing local file upload. Temp storage on AAI who then deletes it. for now. TODO: upgrade to store in r2. |
| **2 – Prod** | Supabase R2 (S3-compatible) | 1. Client requests a presigned upload URL via Edge Function (JWT-authenticated).<br>2. Client uploads media directly to R2.<br>3. Edge Function inserts a `media_files` row with metadata.<br>4. Client requests short-lived signed download URLs the same way. |

### 6.2 Transcription

1. Submit media URL to AssemblyAI.
2. Poll for completion.
3. Store full transcript in `interview.transcript`.

### 6.3 Insight Generation

1. Push a job to **pgmq** queue `transcribe` once the transcript is saved.
2. Worker (or Remix action for MVP) pulls transcript text.
3. Run **o3** + **BAML** to produce structured JSON: insights, quotes, themes, personas, opportunities.
4. Insert rows via `@supabase/supabase-js` with full type safety.

### 6.4 Embeddings & Clustering

1. Generate OpenAI embedding for each `insights.jtbd`.
2. Store vector in `insights.embedding`.
3. Display insights clusters in Recharts Cartesian plot.
4. Reduce dimensions to 2D. Use UMAP and DBSCAN to cluster insights by JTBD and Category. (t-SNE alternative)

* Scatter-plot in the UI → fetch `SELECT id, name, embedding FROM themes` and apply PCA/UMAP in client.

### 6.5 User Notification

1. On success, notify with insight count and link to interview.
2. On failure, notify with error message.

## 7. Pipeline Orchestration

### 7.1 Transcription

Implement a pipeline queue for handling different stages of the transcription process.
This will be more robust incase of error, and should prevent data loss, enabling restarts, etc.
Can also update user notifications to show progress.

* Allow user to past transcript file to the Add Interview button. The tranascript text should be added into an `interview` row in the DB.
And start the transcription pipeline from the `transcribe` pgmq queue.

TODO: Add details on how.

```mermaid
graph TD
    A(User uploads media) --> B[Store URL (Drive or R2)]
    B --> C[AssemblyAI Transcription]
    C -->|transcript ready| D[Save transcript to DB]
    D --> E[pgmq: enqueue 'transcribe']
    E --> F[o3 + BAML worker]
    F --> G[Insert insights & embeddings]
    G --> H[Notify user]
```

* **Queues / Workers** – `pgmq` for reliable jobs; future heavy processing via Edge Function.
* **Security** – presigned R2 URLs validated by org JWT.

## 8. Setup pipeline

* Add pgmq queue for transcript processing to supabase. Done. named 'transcribe' and added to schema
* Define pipeline flow to handle transcript processing: Provide File URL -> transacribe audio with assembly AI  -> save to db -> notify user

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

## 9. Migration & Seeding Strategy

* All DB structure is defined with declarative schemas in `supabase/schemas`.  Migrations are auto-generated via `supabase db diff` and stored in `supabase/migrations`. We then run `supabase db push` to apply the migrations to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.
* pgvector enabled in initial migration.
* Seed scripts insert default categories, sample tags, and demo personas for Storybook/testing.

* [ ] Figure out how to run embedding migrations to install extensions

---

Please **review** and confirm or suggest edits. Once approved I will:

1. Add helper Edge Function stubs for R2 upload/download.
2. Add pgmq queue for transcript processing.

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

3. Implement adaptive embedding search: <https://supabase.com/blog/matryoshka-embeddings>

## Notes

When we modify the schema, we should run `supabase db diff` to generate a migration. This will create a new migration file in the `supabase/migrations` directory. We should then run `supabase db push` to apply the migration to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.

## Reference docs and code samples

* Transcribe using AssemblyAI. [AssemblyAI docs](https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file)
* AssemblyAI can transcribe google drive files.
* [how to convert google files to downloadable](https://www.assemblyai.com/docs/guides/transcribing-google-drive-file)
* [supabase automatic embeddings](https://supabase.com/docs/guides/ai/automatic-embeddings)
* Using Supabase functions to generate embeddings. see [supabase-howto.md](supabase-howto.md)
