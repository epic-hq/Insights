# Database & Storage Plan – Interview Insights

## Last updated: 2025-07-09

This document captures the agreed-upon architectural decisions for persistence, auth, media storage, and future analytics.

## 1. Stack Overview

| Layer | Choice | Rationale |
|-------|--------|----------|
| Relational DB | **Postgres (Supabase)** | Managed Postgres with integrated auth & RLS; fits structured research data. |
| Auth | **Supabase Auth** | Email / SSO; interviewer accounts map to `auth.users`. |
| Media Storage | **Cloudflare R2** | Low-cost object storage for large audio / video files. Supabase stores only signed-URL + metadata. |
| Vector Search (future) | **pgvector** extension on Supabase | Enables semantic similarity between themes / categories. |
| App Framework | **Remix (React Router 7)** | Universal React routing; fits Supabase + edge functions; allows o3/BAML processing in Remix actions/loaders. |

## 2. Tenancy & ACL Model

* Multi-tenant SaaS → every row scoped by `accounts.account_id` (UUID).
* `accounts` & `user_accounts` control membership & roles.
* Row-Level Security (RLS) policies restrict CRUD to members of the same `account_id`.
* Media ACL: Not stored right now, just uploading to AAI for transcription. Future: files stored in R2 under path `account_id/<uuid>`.  Download/stream via **signed URLs** generated by a Supabase Edge Function that validates the caller’s JWT & account membership.

## 3. High-Level Entity Diagram

```text
accounts──┐
          ├─< user_accounts >─auth.users
          │
 research_projects──┐
                    ├─< interviews >─┐
                    │               ├─< media_files > (R2)
                    │               └─< transcripts >
                    │
 insignts──┐                ┌─< quotes >
           └─< insight_tags >──tags (global)

```

## 4. Table Specifications (supabase schema `public`)

General process for defining DB is to create individual schema files in `supabase/schemas` that include indexes, triggers, RLS. Then run `supabase db diff` to generate migration files. Then run `supabase db push` to apply the migrations to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql. `supabase db reset --linked` will reset the hosted database.

Exception: Local DB can't run pgmq extension.

* so we need to run `CREATE EXTENSION IF NOT EXISTS pgmq;` in the database.
* separate migration file to run to setup queues `supabase/migrations/99Custom_pgmq.sql`

### 4.1  Core Multi-Tenant Accounts in schema `accounts`

Using basejump inspired separate accounts schema
Migration files for setting up and configuration done.
Definitive table specs to be stored in `supabase/schemas`

TODO:

* [x] separate tables into files
* [x] add indexes, triggers, RLS policies
* [x] renamed research_projects -> projects. modify in FE too
* [x] error saving new user (maybe due to missing org_id and incomplete setup of new schema. Redo and retry)
* [ ] New user signup should create account and project
* [ ] AddInterview button needs accountId and projectId to send to /api/upload-file in body. _NavLayout loader gets this db and passes it down in AuthContext. So AddInterviewButton should get it from there via useAuthContext?

### 4.2  Research Projects

Make one by default on org creation.

`research_projects`
| id | uuid PK |
| org_id | uuid FK |
| code | text | slug/short label e.g. `teacher_research` |
| title | text |
| description | text |
| created_at | timestamptz |
| updated_at | timestamptz |

### 4.3  Interviews & Media

`interviews`
| id | uuid PK |
| org_id | uuid FK |
| project_id | uuid FK ↗ research_projects.id |
| people_id | uuid FK ↗ people.id |
| title | text |
| interview_date | date |
| interviewer_id | uuid FK ↗ auth.users.id |
| transcript | text |
| segment | text |
| duration_min | int |
| status | text `uploaded` / `transcribed` / `processed` |
| created_at | timestamptz |
| updated_at | timestamptz |

`media_files`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK nullable |
| r2_path | text | `org_id/<uuid>` |
| file_name | text |
| mime_type | text |
| size_bytes | bigint |
| uploaded_by | uuid FK auth.users.id |
| uploaded_at | timestamptz |

<!-- TODO: Deprecate since we store in interviews -->
`transcripts`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK |
| text | text |
| source_json | jsonb |
| created_at | timestamptz |

### 4.4  Qualitative Insights

The focus is on identifying key statements and insights that can be used to inform product development.
We want to identify pain points, friction, and desired outcomes the user has. These can be related or not.

`insights`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK |
| tag | text |
| category | text |
| journey_stage | text |
| impact | smallint 1-5 |
| novelty | smallint 1-5 |
| jtbd | text |
| motivation | text |
| pain | text |
| desired_outcome | text |
| emotional_response | text low/neutral/high |
| opportunity_ideas | text[] |
| confidence | text low/medium/high |
| contradictions | text |
| embedding | vector (pgvector) NULL | semantic representation of insight text |
| created_at | timestamptz |
| updated_at | timestamptz |

`quotes`
| id | uuid PK |
| org_id | uuid FK |
| insight_id | uuid FK |
| quote | text |
| timestamp_sec | int |
| created_at | timestamptz |

### 4.5  Themes & Categories (flat)

`themes`
| id | uuid PK |
| org_id | uuid FK |
| name | text |
| category | text | discrete, no parent |
| color_hex | text |
| embedding | vector | generated from `name` for similarity search |
| created_at | timestamptz |

Materialized view `theme_counts_mv` aggregates `insights` → themes for dashboard treemap.

### 4.6  Personas & Opportunities

`personas`
| id | uuid PK |
| org_id | uuid FK |
| name | text |
| description | text |
| percentage | numeric |
| color_hex | text |
| created_at | timestamptz |

`opportunities`
| id | uuid PK |
| org_id | uuid FK |
| title | text |
| owner_id | uuid FK auth.users.id nullable |
| kanban_status | text explore/validate/build |
| related_insight_ids | uuid[] |
| created_at | timestamptz |

### 4.7  Global Tag Glossary

`tags` (GLOBAL scope)
| tag | text PK |
| description | text |

`insight_tags`
| insight_id | uuid FK |
| tag | text FK tags.tag |

### 4.8  People

These are mostly going to be interviewees, or test subjects, people we observe using product in some way.

`people`
| id | uuid PK |
| org_id | uuid FK |
| name | text |
| description | text |
| segment | text |
| persona | text |
| age | int |
| gender | text |
| income | int |
| education | text |
| occupation | text |
| location | text |
| contact_info | jsonb |
| preferences | text |
| created_at | timestamptz |
| updated_at | timestamptz |

## 4.10 Vector Similarity (pgvector)

* Enable `CREATE EXTENSION IF NOT EXISTS pgvector;` on Supabase.
* Store `embedding` vectors for `themes` & optionally `insights`.
* Example query to populate embeddings with OpenAI:

  ```sql
  update themes
  set embedding = openai_embed(name)
  where embedding is null;
  ```

## 4.11 Creation & Updates & ACLs

### 4.11.1 Creation

When a user signs up, they are created in `auth.users` by Supabase,
Triggers should then:

* create a default `organizations` record with `name: "My Team"` and `role: owner`.
* create a default `user_org_memberships` record with `role: owner`.
* create a default `user_settings` record with `theme: "dark"`, `language: "en"`, `title: ""`, `role: "interviewer"`, `onboarding_completed: false`, `app_activity: {}`, `metadata: {}`.
* create a default `research_projects` record with `code: "001"` and `title: "My First Project"` and `org_id` linked to the default `organizations` record.

### 4.11.2 Updates

* Create a trigger for insert and update to set field `updated_at` to `now()`.
* Run this trigger on all tables that have an `updated_at` field.

### 4.11.3 ACLs

* Row-Level Security (RLS) policies restrict CRUD to members of the same `org_id`.

## 4.11.3 ACLs

* Row-Level Security (RLS) policies restrict CRUD to members of the same `org_id`.
**`insights`**, **`quotes`**, **`themes`**, **`opportunities`**, **`personas`**, **`research_projects`**, **`people`**, **`interviews`**, **`media_files`**:
  * Members of the org can read, create, update, delete rows in these tables

The following tables have additional policies:

* **`organizations`**:
  * `insert` open only to API/service role; users never create orgs directly.
  * No delete by user.
  * Only owner can update.
  * (Prevent spam orgs.)

* **`user_org_memberships`**:
  * `select` owners; members see only their own row.
  * `insert/delete` owners only.
  * (Hide the full roster from non-admins.)

* **`user_settings`**:
  * Use `user_id = auth.uid()` in addition to `is_in_org(org_id)` for read/write.
  * (Each user edits only their prefs.)

* **`media_files`**:
  * Allow `insert` when `uploaded_by = auth.uid()` and `is_in_org(org_id)`.
  * (Enforce proper attribution.)

* **`tags`** (global):
  * Leave RLS **off** or make it read-only for everyone, insert/update restricted to service role.
  * (Shared glossary.)

Materialized views (`theme_counts_mv`) refresh under service role; add `for select using (is_in_org(org_id))` if it has `org_id`. (Keep isolation consistent.)

* Media ACL: files stored in R2 under path `org_id/<uuid>`.  Download/stream via **signed URLs** generated by a Supabase Edge Function that validates the caller’s JWT & org membership.

### Core Pattern Sample Code

```sql
-- helper that lists the orgs the signed‑in user belongs to
create or replace view v_current_user_orgs as
select org_id, role
from public.user_org_memberships
where user_id = auth.uid();

-- convenience Boolean (faster than EXISTS sub‑query)
create or replace function is_in_org(uuid) returns boolean
language sql stable as $$
  select exists(
    select 1 from v_current_user_orgs where org_id = $1
  );
$$;
```

**Default policy template**

```sql
alter table <TABLE> enable row level security;

-- Read
create policy "org members can read"
  on <TABLE>
  for select
  using ( is_in_org(org_id) );

-- Write (any member)
create policy "org members can insert"
  on <TABLE>
  for insert
  with check ( is_in_org(org_id) );

-- Update/Delete (only owners)
create policy "only owners can modify"
  on <TABLE>
  for update using ( exists (
        select 1 from v_current_user_orgs
        where org_id = <TABLE>.org_id and role = 'owner'
  ));
create policy "only owners can delete"
  on <TABLE>
  for delete using ( exists (
        select 1 from v_current_user_orgs
        where org_id = <TABLE>.org_id and role = 'owner'
  ));
```

## 5. Routing

Flatroutes in react-router 7 enabled

| Syntax                         | Resulting URL / behaviour                                                                       | Built‑in?                                                         |
| ------------------------------ | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| `_index.tsx`                   | Parent URL itself (index route)                                                                 | ✔                                                                 |
| `parent.child.tsx`             | `/parent/child` (the dot adds **/** and nests layouts)                                          | ✔ ([React Router][1])                                             |
| `$id.tsx`                      | `/123` dynamic segment → `params.id`                                                            | ✔ ([React Router][1])                                             |
| `($lang).page.tsx`             | `/page` **or** `/en/page` – segment wrapped in **()** is *optional*                             | ✔ ([React Router][1])                                             |
| `_auth.login.tsx`              | `/login` but rendered inside a hidden “auth” layout (leading `_` creates a **pathless layout**) | ✔ ([React Router][1])                                             |
| `parent_.mine.tsx`             | `/parent/mine` with **no** parent layout (trailing `_` removes layout nesting)                  | ✔ ([React Router][1])                                             |
| `$.tsx` or `files.$.tsx`       | Splat / catch‑all (`/anything`)                                                                 | ✔ ([React Router][1])                                             |
| `sitemap[.]xml.tsx`            | Escapes special chars → `/sitemap.xml`                                                          | ✔ ([React Router][1])                                             |
| `folder+` (e.g. `_dashboard+`) | Treat folder as a route segment **and** let you co‑locate extra files without becoming routes   | **➕ Requires** community add‑on `remix-flat-routes` ([GitHub][2]) |

[1]: https://reactrouter.com/how-to/file-route-conventions "File Route Conventions  | React Router"
[2]: https://github.com/remix-run/remix/discussions/8473 "Nested folders and nested / non-nested routes · remix-run remix · Discussion #8473 · GitHub"

## 6. Process Interview Media & Extract Insights

### 6.1 Ingestion & Storage

| Phase | Storage | Key Steps |
|-------|---------|-----------|
| **1 – MVP** | Google Drive links | 1. User pastes a Drive URL.<br>2. Convert the link to a direct-download URL (per AssemblyAI guide). ** Note we had issues, Google did not return clean download links, instead had virus scan html etc. files too large. So we are doing local file upload. Temp storage on AAI who then deletes it. for now. TODO: upgrade to store in r2. |
| **2 – Prod** | Supabase R2 (S3-compatible) | 1. Client requests a presigned upload URL via Edge Function (JWT-authenticated).<br>2. Client uploads media directly to R2.<br>3. Edge Function inserts a `media_files` row with metadata.<br>4. Client requests short-lived signed download URLs the same way. |

### 6.2 Transcription

1. Submit media URL to AssemblyAI.
2. Poll for completion.
3. Store full transcript in `interview.transcript`.

### 6.3 Insight Generation

1. Push a job to **pgmq** queue `transcribe` once the transcript is saved.
2. Worker (or Remix action for MVP) pulls transcript text.
3. Run **o3** + **BAML** to produce structured JSON: insights, quotes, themes, personas, opportunities.
4. Insert rows via `@supabase/supabase-js` with full type safety.

### 6.4 Embeddings & Clustering

1. Generate OpenAI embedding for each `insights.jtbd`.
2. Store vector in `insights.embedding`.
3. Display insights clusters in Recharts Cartesian plot.
4. Reduce dimensions to 2D. Use UMAP and DBSCAN to cluster insights by JTBD and Category. (t-SNE alternative)

* Scatter-plot in the UI → fetch `SELECT id, name, embedding FROM themes` and apply PCA/UMAP in client.

### 6.5 User Notification

1. On success, notify with insight count and link to interview.
2. On failure, notify with error message.

## 7. Pipeline Orchestration

### 7.1 Transcription

Implement a pipeline queue for handling different stages of the transcription process.
This will be more robust incase of error, and should prevent data loss, enabling restarts, etc.
Can also update user notifications to show progress.

* Allow user to past transcript file to the Add Interview button. The tranascript text should be added into an `interview` row in the DB.
And start the transcription pipeline from the `transcribe` pgmq queue.

TODO: Add details on how.

```mermaid
graph TD
    A(User uploads media) --> B[Store URL (Drive or R2)]
    B --> C[AssemblyAI Transcription]
    C -->|transcript ready| D[Save transcript to DB]
    D --> E[pgmq: enqueue 'transcribe']
    E --> F[o3 + BAML worker]
    F --> G[Insert insights & embeddings]
    G --> H[Notify user]
```

* **Queues / Workers** – `pgmq` for reliable jobs; future heavy processing via Edge Function.
* **Security** – presigned R2 URLs validated by org JWT.

## 8. Setup pipeline

* Add pgmq queue for transcript processing to supabase. Done. named 'transcribe' and added to schema
* Define pipeline flow to handle transcript processing: Provide File URL -> transacribe audio with assembly AI  -> save to db -> notify user

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

## 9. Migration & Seeding Strategy

* All DB structure is defined with declarative schemas in `supabase/schemas`.  Migrations are auto-generated via `supabase db diff` and stored in `supabase/migrations`. We then run `supabase db push` to apply the migrations to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.
* pgvector enabled in initial migration.
* Seed scripts insert default categories, sample tags, and demo personas for Storybook/testing.

* [ ] Figure out how to run embedding migrations to install extensions

---

Please **review** and confirm or suggest edits. Once approved I will:

1. Add helper Edge Function stubs for R2 upload/download.
2. Add pgmq queue for transcript processing.

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

3. Implement adaptive embedding search: <https://supabase.com/blog/matryoshka-embeddings>

## Notes

When we modify the schema, we should run `supabase db diff` to generate a migration. This will create a new migration file in the `supabase/migrations` directory. We should then run `supabase db push` to apply the migration to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.

## Reference docs and code samples

* Transcribe using AssemblyAI. [AssemblyAI docs](https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file)
* AssemblyAI can transcribe google drive files.
* [how to convert google files to downloadable](https://www.assemblyai.com/docs/guides/transcribing-google-drive-file)
* [supabase automatic embeddings](https://supabase.com/docs/guides/ai/automatic-embeddings)
* Using Supabase functions to generate embeddings. see [supabase-howto.md](supabase-howto.md)
