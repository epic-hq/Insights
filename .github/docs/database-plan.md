# Database & Storage Plan – Interview Insights

## Last updated: 2025-07-09

This document captures the agreed-upon architectural decisions for persistence, auth, media storage, and future analytics.

## 1. Stack Overview

| Layer | Choice | Rationale |
|-------|--------|----------|
| Relational DB | **Postgres (Supabase)** | Managed Postgres with integrated auth & RLS; fits structured research data. |
| Auth | **Supabase Auth** | Email / SSO; interviewer accounts map to `auth.users`. |
| Media Storage | **Cloudflare R2** | Low-cost object storage for large audio / video files. Supabase stores only signed-URL + metadata. |
| Vector Search (future) | **pgvector** extension on Supabase | Enables semantic similarity between themes / categories. |
| App Framework | **Remix (React Router 7)** | Universal React routing; fits Supabase + edge functions; allows o3/BAML processing in Remix actions/loaders. |

## 2. Tenancy & ACL Model

* Multi-tenant SaaS → every row scoped by `org_id` (UUID).
* `organizations` & `user_org_memberships` control membership & roles.
* Row-Level Security (RLS) policies restrict CRUD to members of the same `org_id`.
* Media ACL: files stored in R2 under path `org_id/<uuid>`.  Download/stream via **signed URLs** generated by a Supabase Edge Function that validates the caller’s JWT & org membership.

## 3. High-Level Entity Diagram

```text
organizations──┐
               ├─< user_org_memberships >─auth.users (interviewers)
               │
 research_projects──┐
                    ├─< interviews >─┐
                    │               ├─< media_files > (R2)
                    │               └─< transcripts >
                    │
 insignts──┐                ┌─< quotes >
           └─< insight_tags >──tags (global)

themes (flat)
personas (per org)
opportunities (per org)
```

## 4. Table Specifications (supabase schema `public`)

### 4.1  Core Multi-Tenant

`organizations`
| Column | Type | Notes |
| id | uuid PK | `gen_random_uuid()` |
| name | text | |
| created_at | timestamptz | default `now()` |

`user_org_memberships`
| user_id | uuid PK ↗ auth.users.id |
| org_id | uuid PK ↗ organizations.id |
| role | text | `owner`, `member` |
| joined_at | timestamptz default `now()` |

### 4.2  Research Projects

`research_projects`
| id | uuid PK |
| org_id | uuid FK |
| code | text | slug/short label e.g. `teacher_research` |
| title | text |
| description | text |
| created_at | timestamptz |

### 4.3  Interviews & Media

`interviews`
| id | uuid PK |
| org_id | uuid FK |
| project_id | uuid FK ↗ research_projects.id |
| title | text |
| interview_date | date |
| interviewer_id | uuid FK ↗ auth.users.id |
| participant_pseudonym | text |
| segment | text |
| duration_min | int |
| status | text `uploaded` / `transcribed` / `processed` |
| created_at | timestamptz |

`media_files`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK nullable |
| r2_path | text | `org_id/<uuid>` |
| file_name | text |
| mime_type | text |
| size_bytes | bigint |
| uploaded_by | uuid FK auth.users.id |
| uploaded_at | timestamptz |

`transcripts`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK |
| text | text |
| source_json | jsonb |
| created_at | timestamptz |

### 4.4  Qualitative Data

`insights`
| id | uuid PK |
| org_id | uuid FK |
| interview_id | uuid FK |
| tag | text |
| category | text |
| journey_stage | text |
| impact | smallint 1-5 |
| novelty | smallint 1-5 |
| jtbd | text |
| motivation | text |
| pain | text |
| desired_outcome | text |
| emotional_response | text low/neutral/high |
| opportunity_ideas | text[] |
| confidence | text low/medium/high |
| contradictions | text |
| embedding | vector (pgvector) NULL | semantic representation of insight text |
| created_at | timestamptz |

`quotes`
| id | uuid PK |
| org_id | uuid FK |
| insight_id | uuid FK |
| quote | text |
| timestamp_sec | int |
| created_at | timestamptz |

### 4.5  Themes & Categories (flat)

`themes`
| id | uuid PK |
| org_id | uuid FK |
| name | text |
| category | text | discrete, no parent |
| color_hex | text |
| embedding | vector | generated from `name` for similarity search |
| created_at | timestamptz |

Materialized view `theme_counts_mv` aggregates `insights` → themes for dashboard treemap.

### 4.6  Personas & Opportunities

`personas`
| id | uuid PK |
| org_id | uuid FK |
| name | text |
| description | text |
| percentage | numeric |
| color_hex | text |
| created_at | timestamptz |

`opportunities`
| id | uuid PK |
| org_id | uuid FK |
| title | text |
| owner_id | uuid FK auth.users.id nullable |
| kanban_status | text explore/validate/build |
| related_insight_ids | uuid[] |
| created_at | timestamptz |

### 4.7  Global Tag Glossary

`tags` (GLOBAL scope)
| tag | text PK |
| description | text |

`insight_tags`
| insight_id | uuid FK |
| tag | text FK tags.tag |

## 5. Vector Similarity (pgvector)

* Enable `CREATE EXTENSION IF NOT EXISTS pgvector;` on Supabase.
* Store `embedding` vectors for `themes` & optionally `insights`.
* Example query to populate embeddings with OpenAI:

  ```sql
  update themes
  set embedding = openai_embed(name)
  where embedding is null;
  ```

* Scatter-plot in the UI → fetch `SELECT id, name, embedding FROM themes` and apply PCA/UMAP in client.

## 6. Process Interview Media & Extract Insights

### 6.1 Ingestion & Storage

| Phase | Storage | Key Steps |
|-------|---------|-----------|
| **1 – MVP** | Google Drive links | 1. User pastes a Drive URL.<br>2. Convert the link to a direct-download URL (per AssemblyAI guide). ** Note we had issues, Google did not return clean download links, instead had virus scan html etc. files too large. So we are doing local file upload. Temp storage on AAI who then deletes it. for now. TODO: upgrade to store in r2. |
| **2 – Prod** | Supabase R2 (S3-compatible) | 1. Client requests a presigned upload URL via Edge Function (JWT-authenticated).<br>2. Client uploads media directly to R2.<br>3. Edge Function inserts a `media_files` row with metadata.<br>4. Client requests short-lived signed download URLs the same way. |

### 6.2 Transcription

1. Submit media URL to AssemblyAI.
2. Poll for completion.
3. Store full transcript in `interview.transcript`.

### 6.3 Insight Generation

1. Push a job to **pgmq** queue `transcribe` once the transcript is saved.
2. Worker (or Remix action for MVP) pulls transcript text.
3. Run **o3** + **BAML** to produce structured JSON: insights, quotes, themes, personas, opportunities.
4. Insert rows via `@supabase/supabase-js` with full type safety.

### 6.4 Embeddings & Clustering

1. Generate OpenAI embedding for each `insights.jtbd`.
2. Store vector in `insights.embedding`.
3. (Optional) For theme scatter-plot: t-SNE to 2-D → Recharts Cartesian plot.

### 6.5 User Notification

1. On success, notify with insight count and link to interview.
2. On failure, notify with error message.

## 7. Pipeline Orchestration

```mermaid
graph TD
    A(User uploads media) --> B[Store URL (Drive or R2)]
    B --> C[AssemblyAI Transcription]
    C -->|transcript ready| D[Save transcript to DB]
    D --> E[pgmq: enqueue 'transcribe']
    E --> F[o3 + BAML worker]
    F --> G[Insert insights & embeddings]
    G --> H[Notify user]
```

* **Queues / Workers** – `pgmq` for reliable jobs; future heavy processing via Edge Function.
* **Security** – presigned R2 URLs validated by org JWT.

## 8. Setup pipeline

* Add pgmq queue for transcript processing to supabase. Done. named 'transcribe' and added to schema
* Define pipeline flow to handle transcript processing: Provide File URL -> transacribe audio with assembly AI  -> save to db -> notify user

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

## 9. Migration & Seeding Strategy

* All DB structure is defined with declarative schemas in `supabase/schemas`.  Migrations are auto-generated via `supabase db diff` and stored in `supabase/migrations`. We then run `supabase db push` to apply the migrations to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.
* pgvector enabled in initial migration.
* Seed scripts insert default categories, sample tags, and demo personas for Storybook/testing.

---

Please **review** and confirm or suggest edits. Once approved I will:

1. Add helper Edge Function stubs for R2 upload/download.
2. Add pgmq queue for transcript processing.

* <https://github.com/pgmq/pgmq?tab=readme-ov-file#sql-examples>

3. Implement adaptive embedding search: <https://supabase.com/blog/matryoshka-embeddings>

## Notes

When we modify the schema, we should run `supabase db diff` to generate a migration. This will create a new migration file in the `supabase/migrations` directory. We should then run `supabase db push` to apply the migration to the database. or `supabase db reset` to reset the database to the state of the migration files. It will drop the database and recreate it from the migration files and run seed.sql.

## Reference docs and code samples

* Transcribe using AssemblyAI. [AssemblyAI docs](https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file)
* AssemblyAI can transcribe google drive files.
* [how to convert google files to downloadable](https://www.assemblyai.com/docs/guides/transcribing-google-drive-file)
* [supabase automatic embeddings](https://supabase.com/docs/guides/ai/automatic-embeddings)
