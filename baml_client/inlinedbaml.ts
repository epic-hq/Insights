/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "apply_conversation_lens.baml": "// Generic lens application that works with any template definition\n// This is the dynamic engine that drives all conversation lenses\n\nclass LensFieldValue {\n  field_key string @description(\"Matches field_key from template\")\n  value string @description(\"Extracted value or summary\")\n  confidence float @description(\"0.0-1.0 confidence score\")\n  evidence_ids string[] @description(\"IDs of supporting evidence\")\n}\n\nclass LensSectionResult {\n  section_key string @description(\"Matches section_key from template\")\n  fields LensFieldValue[] @description(\"Extracted field values\")\n}\n\nclass LensEntityResult {\n  entity_type string @description(\"e.g., stakeholders, objections, next_steps\")\n  items LensEntityItem[] @description(\"Extracted entities\")\n}\n\nclass LensEntityItem {\n  name string\n  role string?\n  description string?\n  confidence float\n  evidence_ids string[]\n}\n\nclass LensRecommendation {\n  type string @description(\"next_step, follow_up, risk, opportunity\")\n  description string\n  priority \"high\" | \"medium\" | \"low\"\n  rationale string?\n  evidence_ids string[]\n}\n\nclass ConversationLensResult {\n  sections LensSectionResult[]\n  entities LensEntityResult[]\n  recommendations LensRecommendation[]\n  overall_confidence float\n  processing_notes string?\n}\n\nfunction ApplyConversationLens(\n  template_definition: string,\n  template_name: string,\n  evidence_json: string,\n  interview_context: string,\n  custom_instructions: string?\n) -> ConversationLensResult {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert conversation analyst. Apply the following analytical lens/framework\n    to extract structured insights from interview evidence.\n\n    ## Template: {{ template_name }}\n    {{ template_definition }}\n\n    ## Interview Context\n    {{ interview_context }}\n\n    {% if custom_instructions %}\n    ## Custom Instructions\n    {{ custom_instructions }}\n    {% endif %}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n    1. For each section and field defined in the template, extract the relevant information\n    2. Always cite evidence_ids that support each extraction\n    3. Assign confidence scores based on how directly the evidence supports the extraction\n    4. Generate actionable recommendations based on the analysis\n    5. If a field cannot be determined from the evidence, indicate low confidence\n    6. For entities (stakeholders, next_steps, etc.), extract all relevant items mentioned\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "auto_insights.baml": "// Auto-Insights BAML Schema and Function\n// Generates executive-level insights and recommendations from user research data\n\nclass ActionButton {\n  label string @description(\"Button text for the action\")\n  action_type string @description(\"Type of action: create_opportunity | prioritize_insight | schedule_research | create_persona | tag_insights\")\n  parameters string @description(\"Action-specific parameters as JSON string\")\n  priority string @description(\"Action priority: High | Medium | Low\")\n}\n\nclass ExecutiveInsight {\n  title string @description(\"Executive-level insight title (5-8 words)\")\n  insight string @description(\"Strategic insight or recommendation (2-3 sentences without the fluff)\")\n  evidence string[] @description(\"Supporting evidence from user research (quotes, data points)\")\n  business_impact string @description(\"Business impact description and potential value\")\n  impact_level string @description(\"Impact level: High | Medium | Low\")\n  confidence_level string @description(\"Confidence in this insight: High | Medium | Low\")\n  personas_affected string[] @description(\"Which personas this insight affects most\")\n  recommended_actions ActionButton[] @description(\"Actionable next steps with buttons\")\n  category string @description(\"Insight category: Revenue | Product | User Experience | Market | Risk\")\n}\n\nclass OpportunityRecommendation {\n  title string @description(\"Opportunity title\")\n  description string @description(\"Detailed opportunity description\")\n  revenue_potential string @description(\"Revenue potential: High | Medium | Low\")\n  effort_estimate string @description(\"Implementation effort: High | Medium | Low\")\n  target_personas string[] @description(\"Primary personas who would benefit\")\n  supporting_insights string[] @description(\"Key insights that support this opportunity\")\n  competitive_advantage string @description(\"How this creates competitive advantage\")\n  recommended_actions ActionButton[] @description(\"Next steps to pursue this opportunity\")\n}\n\nclass PersonaAnalysis {\n  persona_name string @description(\"Persona name\")\n  key_pain_points string[] @description(\"Top 3 pain points for this persona\")\n  unmet_needs string[] @description(\"Unmet needs and desired outcomes\")\n  revenue_potential string @description(\"Revenue potential from this persona: High | Medium | Low\")\n  willingness_to_pay string @description(\"Likelihood to pay for solutions: High | Medium | Low\")\n  recommended_solutions string[] @description(\"Specific solutions this persona would value\")\n  competitive_threats string[] @description(\"How competitors might target this persona\")\n}\n\nclass AutoInsightsResponse {\n  executive_summary string @description(\"High-level summary of key findings (3-4 sentences)\")\n  top_opportunities OpportunityRecommendation[] @description(\"Top 3-5 revenue-generating opportunities\")\n  critical_insights ExecutiveInsight[] @description(\"Most important strategic insights\")\n  persona_analysis PersonaAnalysis[] @description(\"Analysis of each key persona\")\n  competitive_considerations string[] @description(\"Key competitive pressures and threats\")\n  immediate_actions ActionButton[] @description(\"Top 3 immediate actions to take\")\n  strategic_recommendations string[] @description(\"Long-term strategic recommendations\")\n}\n\nfunction GenerateAutoInsights(\n  research_data: string,\n  competitive_context: string,\n  business_goals: string\n) -> AutoInsightsResponse {\n  client \"CustomGPT4o\"\n  prompt #\"\n    You are a senior product strategist and user research expert analyzing comprehensive user research data to generate executive-level insights and recommendations.\n\n    ## Research Data\n    {{ research_data }}\n\n    ## Competitive Context\n    {{ competitive_context }}\n\n    ## Business Goals\n    {{ business_goals }}\n\n    ## Your Task\n    Analyze this data to answer key executive questions:\n\n    1. **What are the top revenue-generating opportunities?**\n       - Identify opportunities with highest revenue potential\n       - Consider market size, willingness to pay, and competitive advantage\n       - Prioritize based on effort vs. impact\n\n    2. **What are the most critical pain points to solve?**\n       - Focus on high-impact, high-frequency pain points\n       - Consider emotional intensity and business impact\n       - Identify pain points that competitors aren't addressing\n\n    3. **Which personas offer the best revenue potential?**\n       - Analyze willingness to pay by persona\n       - Consider market size and accessibility\n       - Identify underserved segments\n\n    4. **What changes would benefit different personas most?**\n       - Persona-specific recommendations\n       - Consider journey stage and context\n       - Prioritize changes with broad appeal\n\n    5. **Given competitive pressures, what are the most profitable opportunities?**\n       - Consider competitive landscape\n       - Identify differentiation opportunities\n       - Focus on defensible advantages\n\n    ## Analysis Guidelines\n    - **Be Strategic**: Focus on business impact, not just user satisfaction\n    - **Be Specific**: Provide concrete, actionable recommendations\n    - **Be Evidence-Based**: Ground insights in actual user research data\n    - **Be Prioritized**: Rank opportunities by revenue potential and feasibility\n    - **Be Competitive**: Consider how to win against competitors\n\n    ## Action Button Guidelines\n    Create actionable buttons with these types:\n    - `create_opportunity`: Creates new opportunity with title and description\n    - `prioritize_insight`: Marks insight as high priority for follow-up\n    - `schedule_research`: Schedules additional research on specific topic\n    - `create_persona`: Creates new persona based on findings\n    - `tag_insights`: Tags related insights for better organization\n\n    Parameters should include relevant IDs, titles, descriptions, and metadata.\n\n    ## Output Requirements\n    - **Executive Summary**: 3-4 sentences highlighting the most important findings\n    - **Top Opportunities**: 3-5 opportunities ranked by revenue potential\n    - **Critical Insights**: 5-7 strategic insights with evidence and actions\n    - **Persona Analysis**: Detailed analysis of each key persona\n    - **Competitive Considerations**: Key threats and competitive responses needed\n    - **Immediate Actions**: Top 3 actions to take in the next 30 days\n    - **Strategic Recommendations**: Long-term strategic direction\n\n    Focus on insights that drive business value and competitive advantage.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test function for development\ntest GenerateAutoInsights_Sample {\n  functions [GenerateAutoInsights]\n  args {\n    research_data #\"\n      # Sample Research Data\n      ## Overview\n      - Total Insights: 45\n      - Total Interviews: 12\n      - Total People: 8\n      - Date Range: 2024-01-15 to 2024-03-20\n\n      ## Top Insights\n      ### Time Management Struggles (Category: User Experience)\n      - Pain: Users spend 2-3 hours daily on manual planning\n      - Desired Outcome: Automated planning that saves time\n      - Evidence: \"I waste so much time just figuring out what to do next\" (Interview #3)\n      - Impact: 5/5, Novelty: 3/5\n      - Personas: Busy Professional, Student\n\n      ### Lack of Progress Visibility (Category: Product)\n      - Pain: Users can't see long-term progress toward goals\n      - Desired Outcome: Clear progress tracking and milestones\n      - Evidence: \"I never know if I'm actually getting closer to my goals\" (Interview #7)\n      - Impact: 4/5, Novelty: 4/5\n      - Personas: Goal-Oriented Achiever\n\n      ## Personas\n      ### Busy Professional (60% of users)\n      - Top Pain Points: Time management, Context switching, Overwhelm\n      - Desired Outcomes: Efficiency, Focus, Work-life balance\n\n      ### Student (25% of users)\n      - Top Pain Points: Procrastination, Study planning, Motivation\n      - Desired Outcomes: Better grades, Reduced stress, Time for social life\n    \"#\n    competitive_context #\"\n      Key competitors include Notion, Todoist, and Asana. Most focus on task management but lack intelligent planning and progress visualization.\n    \"#\n    business_goals #\"\n      - Achieve $1M ARR within 18 months\n      - Build defensible AI-powered planning features\n      - Target productivity-focused professionals and students\n    \"#\n  }\n}\n",
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPTo3 {\n  provider openai\n  options {\n    model \"o3\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPTo3Mini {\n  provider openai\n  options {\n    model \"o3-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between openai clients only\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
  "contextual_suggestions.baml": "// Enhanced contextual suggestions for project setup and interview questions\n// Provides real-time suggestions based on project context and user input\n// Supports both project goals setup and interview question generation\n\nclass ContextualSuggestions {\n  decision_questions string[] @description(\"Contextual decision that the user needs to make in order to best achieve their goal. \")\n  assumptions string[] @description(\"Relevant assumptions\")\n  unknowns string[] @description(\"Key research questions/unknowns and what must be learned to help make a decision.\")\n  organizations string[] @description(\"Target organization types\")\n  roles string[] @description(\"Target user roles\")\n  interview_questions string[] @description(\"Interview questions for specific categories\")\n}\n\nfunction GenerateContextualSuggestions(\n  research_goal: string,\n  current_input: string,\n  suggestion_type: string, // \"decision_questions\", \"assumptions\", \"unknowns\", \"organizations\", \"roles\", \"interview_questions\"\n  existing_items: string[],\n  rejected_items: string[],\n  project_context: string,\n  custom_instructions: string,\n  response_count: int,\n  question_category: string? // For interview questions: \"context\", \"pain\", \"workflow\", etc.\n) -> string[] {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher helping someone set up their research project and create interview questions.\n    Generate {{ response_count }} highly relevant, contextual suggestions for the {{ suggestion_type }} field.\n\n    PROJECT CONTEXT:\n    - Research Goal: {{ research_goal }}\n    - Current Input Being Typed: \"{{ current_input }}\"\n    - Exclude (already added or previously shown): {{ existing_items }}\n    - Rejected Items (avoid similar suggestions): {{ rejected_items }}\n    - Additional Context: {{ project_context }}\n    {% if custom_instructions %}- Custom Instructions: {{ custom_instructions }}{% endif %}\n    {% if question_category %}- Question Category: {{ question_category }}{% endif %}\n\n    CRITICAL REQUIREMENTS:\n    - Build upon the research goal and ESPECIALLY the current input (\"{{ current_input }}\") as the primary direction\n    - The current input should heavily influence the suggestions - expand on its theme and direction\n    - Avoid generating any suggestions similar to those in the exclude list: {{ existing_items }}\n    - Avoid generating suggestions similar to rejected items: {{ rejected_items }}\n    - Make suggestions specific to the research domain mentioned in the goal\n    - If current input exists, treat it as the primary context and build complementary suggestions\n    {% if custom_instructions %}- Follow the custom instructions: {{ custom_instructions }}{% endif %}\n\n    GENERATE SUGGESTIONS FOR: {{ suggestion_type }}\n\n    {% if suggestion_type == \"decision_questions\" %}\n   Generate specific, actionable decisions that the user could make to advance their business goal. Each decision should:\n\t\t- Directly influence product, marketing, or customer strategy\n\t\t- Be informed by customer behavior or insights\n\t\t- Lead to measurable outcomes that can validate success\n\t\t- Reduce uncertainty about what to build, whom to target, or how to position the product\n\n    Format examples:\n\t\t- \"Prioritize building automated cash-flow projections over manual expense tracking\"\n\t\t- \"Focus on milestone-based progress tracking instead of daily streaks\"\n\t\t- \"Gate collaboration tools behind premium plans instead of storage limits\"\n\t\t- \"Launch a loyalty program rewarding clients for re-booking the same freelancer\"\n    {% endif %}\n\n    {% if suggestion_type == \"assumptions\" %}\n    Generate testable assumptions that are core beliefs driving this research. Focus on:\n    - Specific customer behavior patterns you believe to be true\n    - Market conditions or competitive dynamics you're assuming\n    - Product/feature beliefs that influence your roadmap\n    - Business model assumptions that affect strategy\n\n    Make them concrete and testable. Format examples:\n    - \"Customers value outcome X more than feature Y\"\n    - \"Users abandon the product primarily due to onboarding friction\"\n    - \"Price sensitivity decreases once customers see clear ROI\"\n    - \"Our target market prefers self-service over human support\"\n    {% endif %}\n\n    {% if suggestion_type == \"unknowns\" %}\n    Generate research questions that are critical unknowns that create uncertainty in decision-making. Focus on:\n    - Knowledge gaps that could dramatically change your strategy if filled\n\t\t- Customer context, goals, friction and pain points that could influence the user's decision\n    - Customer behavior patterns that you're unsure about\n    - Market dynamics that could affect adoption or success\n    - Competitive threats or advantages that remain unclear\n\n    Frame as specific uncertainties. Format examples:\n    - \"Customer willingness to pay for premium features\"\n    - \"Which competitor features drive the most switching\"\n    - \"How much friction customers will tolerate before churning\"\n    - \"Whether our value prop resonates with mid-market vs enterprise\"\n    {% endif %}\n\n    {% if suggestion_type == \"organizations\" %}\n    Generate specific organization types that would be ideal participants for this research. Focus on:\n    - Company sizes, stages, and revenue ranges that match your target market\n    - Industry verticals where your research goal is most relevant\n    - Business models that align with what you're trying to learn\n    - Market segments that face the problems you're investigating\n\n    Be specific about characteristics. Format examples:\n    - \"Series A B2B SaaS companies (50-200 employees)\"\n    - \"Ecommerce brands with $1M-10M annual revenue\"\n    - \"Digital marketing agencies serving SMB clients\"\n    - \"Healthcare startups in regulatory-heavy markets\"\n    {% endif %}\n\n    {% if suggestion_type == \"roles\" %}\n    Generate specific user roles that would provide the most valuable insights for this research. Focus on:\n    - Decision makers who influence purchasing or adoption decisions\n    - End users who directly experience the problems you're researching\n    - Stakeholders who would be affected by potential solutions\n    - Roles that span different levels (individual contributors, managers, executives)\n\n    Include seniority and functional context. Format examples:\n    - \"VP of Product (50-500 person companies)\"\n    - \"Customer Success Manager at SaaS companies\"\n    - \"Marketing Operations Director\"\n    - \"Small business owner (solo or 2-10 employees)\"\n    {% endif %}\n\n    {% if suggestion_type == \"interview_questions\" %}\n    Generate specific, well-crafted interview questions{% if question_category %} for the {{ question_category }} category{% endif %}. Focus on:\n    - Open-ended questions that encourage detailed responses\n    - Questions that align with the research goal and current input direction\n    - Questions that would provide actionable insights\n    - Questions appropriate for the specified category context\n    {% if question_category == \"context\" %}- Background and situational questions{% endif %}\n    {% if question_category == \"pain\" %}- Questions about problems, frustrations, and challenges{% endif %}\n    {% if question_category == \"workflow\" %}- Questions about processes, behaviors, and current methods{% endif %}\n    {% if question_category == \"goals\" %}- Questions about objectives, desired outcomes, and motivations{% endif %}\n    {% if question_category == \"constraints\" %}- Questions about limitations, barriers, and restrictions{% endif %}\n    {% if question_category == \"willingness\" %}- Questions about pricing, value perception, and purchase decisions{% endif %}\n    {% if question_category == \"demographics\" %}- Questions about background, role, and organizational context{% endif %}\n\n    Format examples:\n    - \"Can you walk me through how you currently [process/task]?\"\n    - \"What's the biggest challenge you face when [context]?\"\n    - \"Tell me about a time when [situation] didn't go as planned.\"\n    - \"How do you decide whether to [decision/action]?\"\n    {% endif %}\n\n    REQUIREMENTS:\n    - Generate exactly {{ response_count }} suggestions\n    - Each suggestion should be 4-25 words (interview questions can be slightly longer)\n    - Avoid duplicating any in exclude list: {{ existing_items }}\n    - Avoid suggestions similar to rejected items: {{ rejected_items }}\n    - Be specific and actionable, not generic\n    - Directly relate to the research goal and current input context\n    - Use clear, professional language that a researcher would understand\n    - PRIORITIZE building upon the current input (\"{{ current_input }}\") as the main direction\n    {% if custom_instructions %}- Follow custom instructions: {{ custom_instructions }}{% endif %}\n\n    Return only a JSON array of exactly {{ response_count }} strings, like: [\"suggestion 1\", \"suggestion 2\", \"suggestion 3\"]\n  \"#\n}\n",
  "contextual_suggestions.tests.baml": "// Tests for GenerateContextualSuggestions\n\ntest GenerateContextualSuggestions_DecisionQuestions_SaaS {\n  functions [GenerateContextualSuggestions]\n  args {\n    research_goal \"Increase trial-to-paid conversion for a B2B SaaS analytics product\"\n    current_input \"Users drop off after connecting their first data source\"\n    suggestion_type \"decision_questions\"\n    existing_items [\"What blocks teams from completing setup?\", \"Which roles influence purchase?\"]\n    project_context \"SMB teams evaluating analytics tools; 14-day trials; self-serve onboarding\"\n  }\n}\n\ntest GenerateContextualSuggestions_Roles_Healthcare {\n  functions [GenerateContextualSuggestions]\n  args {\n    research_goal \"Improve patient intake and follow‑up in outpatient clinics\"\n    current_input \"Confusion around discharge instructions and next steps\"\n    suggestion_type \"roles\"\n    existing_items [\"Front-desk staff\", \"Primary-care physicians\"]\n    project_context \"Regional nonprofit hospital network; 6 clinics; chronic care programs for diabetes and hypertension\"\n  }\n}\n\n",
  "conversation_analysis.baml": "// Standalone conversation analyzer schema\n\nclass ConversationQuestion {\n  question string\n  asked_by string?\n  intent string?\n  evidence_snippet string?\n  confidence float\n}\n\nclass ParticipantGoal {\n  speaker string?\n  goal string\n  evidence_snippet string?\n  confidence float\n}\n\nclass ConversationTakeaway {\n  priority \"high\" | \"medium\" | \"low\"\n  summary string\n  evidence_snippets string[]\n}\n\nclass ConversationRecommendation {\n  focus_area string\n  action string\n  rationale string\n}\n\nclass ConversationAnalysis {\n  overview string\n  duration_estimate string?\n  questions ConversationQuestion[]\n  participant_goals ParticipantGoal[]\n  key_takeaways ConversationTakeaway[]\n  open_questions string[]\n  recommended_next_steps ConversationRecommendation[]\n}\n\nfunction AnalyzeStandaloneConversation(\n  transcript: string,\n  context: string\n) -> ConversationAnalysis {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert conversation analyst helping revenue teams understand standalone call recordings.\n\n    Transcript:\n    {{ transcript }}\n\n    Context (may be empty):\n    {{ context }}\n\n    Produce a structured analysis that:\n      1. Identifies the explicit questions asked, who asked them, and the underlying intent.\n      2. Infers each participant's goals or objectives from their statements.\n      3. Summarizes the key takeaways that matter for sales or discovery follow-up, citing short evidence snippets.\n      4. Highlights open questions or missing information that should be resolved next.\n      5. Recommends next steps that keep the deal or relationship moving forward.\n\n    Requirements:\n      - Keep evidence snippets under 200 characters. Use exact quotes when possible.\n      - Confidence scores must be between 0 and 1.\n      - Never hallucinate participants not present in the transcript.\n      - If intent or speaker cannot be determined, leave the optional fields null.\n      - Maintain a concise but actionable overview paragraph for executives.\n  \"#\n}\n",
  "conversation_takeaways.baml": "// High-level conversation value assessment across all lenses\n\nclass ConversationEvidence {\n  id string @description(\"Evidence UUID for linking back\")\n  verbatim string @description(\"Exact quote from the conversation\")\n  gist string? @description(\"AI-generated summary of the evidence\")\n  speaker string? @description(\"Who said this\")\n  evidence_type string? @description(\"Type of evidence: pain_point, desire, commitment, etc.\")\n  timestamp_start float? @description(\"When this was said in the conversation (seconds)\")\n}\n\nclass ConversationTakeaways {\n  value_synopsis string @description(\"1-2 sentences: How valuable was this conversation overall? What made it uniquely powerful or inline supportive?\")\n  critical_next_step string @description(\"1 sentence: The single most important next step or caution based on all perspectives\")\n  future_improvement string @description(\"1 sentence: What could be improved on future calls\")\n  supporting_evidence_ids string[] @description(\"IDs of evidence items that most strongly support these takeaways\")\n}\n\nfunction ExtractConversationTakeaways(\n  evidence: ConversationEvidence[],\n  bant_summary: string?,\n  meddic_summary: string?,\n  stakeholders_summary: string?,\n  duration_minutes: int?,\n  custom_instructions: string?\n) -> ConversationTakeaways {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing this conversation to assess its value and identify next steps.\n\n    Interview Duration: {{ duration_minutes }} minutes\n    Evidence Items: {{ evidence | length }}\n\n    ## Evidence from Conversation\n    {% for item in evidence %}\n    ---\n    ID: {{ item.id[:8] }}\n    {% if item.speaker %}Speaker: {{ item.speaker }}{% endif %}\n    {% if item.timestamp_start %}Time: {{ item.timestamp_start | round }}s{% endif %}\n    {% if item.evidence_type %}Type: {{ item.evidence_type }}{% endif %}\n\n    Quote: \"{{ item.verbatim }}\"\n    {% if item.gist %}Summary: {{ item.gist }}{% endif %}\n    {% endfor %}\n\n    {% if bant_summary %}\n    ## BANT/GPCT Analysis\n    {{ bant_summary }}\n    {% endif %}\n\n    {% if meddic_summary %}\n    ## MEDDIC Analysis\n    {{ meddic_summary }}\n    {% endif %}\n\n    {% if stakeholders_summary %}\n    ## Stakeholders Identified\n    {{ stakeholders_summary }}\n    {% endif %}\n\n    ## Task\n    {% if custom_instructions %}\n    **IMPORTANT: Custom analysis instructions have been provided. Follow these instructions while still returning the required JSON structure:**\n\n    {{ custom_instructions }}\n\n    You MUST still return valid JSON with the required fields below, but adapt the content, tone, language, and focus according to the custom instructions above.\n    {% endif %}\n\n    Provide a practical business assessment. Return JSON with these fields:\n\n    {\n      \"value_synopsis\": \"1-2 sentences: What made this conversation valuable? Mention specific topics discussed (e.g., 'discussed budget constraints', 'identified key pain point with X') rather than evidence numbers.\",\n      \"critical_next_step\": \"1 sentence: Most important next action based on what was discussed. Be specific.\",\n      \"future_improvement\": \"1 sentence: One concrete improvement for future calls.\",\n      \"supporting_evidence_ids\": [\"id1\", \"id2\", \"id3\"]\n    }\n\n    For supporting_evidence_ids, include 3-5 evidence IDs from above (8-character prefixes like \"156715a5\"). Pick the most impactful quotes that support your assessment.\n\n    Write in clear, practical business language. Reference what was discussed, not evidence numbers.\n  \"#\n}\n",
  "derive_persona_facets.baml": "// Derive Persona Facets BAML Schema and Function\n// Phase 2: Synthesizes enduring persona traits from raw evidence\n\nclass PersonaFacet {\n  person_key string @description(\"Reference to person from extraction\")\n  kind_slug string @description(\"One: motivation | value | attitude | skill | preference | personality | identity | belief | habit | constraint\")\n  value string @description(\"≤12 words; enduring trait phrasing. E.g., 'values autonomy in work', 'prefers visual learning over text', 'motivated by social impact'\")\n  evidence_refs int[] @description(\"List of FacetMention.index values supporting this trait\")\n  confidence float @description(\"0-1; based on frequency, consistency, and salience\")\n  frequency int @description(\"Number of distinct supporting mentions\")\n  reasoning string? @description(\"≤20 words explaining why this is an enduring trait vs situational\")\n}\n\nclass PersonaExtraction {\n  persona_facets PersonaFacet[] @description(\"Enduring traits for each person\")\n  summary string? @description(\"1-2 sentence synthesis of persona patterns across all participants\")\n}\n\nfunction DerivePersonaFacetsFromEvidence(\n  extraction: Extraction\n) -> PersonaExtraction {\n  client \"CustomGPT5\"\n  prompt #\"\nYou are a research analyst synthesizing persona insights from structured evidence.\n\n## Task\nGiven evidence turns and facet mentions, infer **significant and enduring persona facets** for each participant.\n\n## Steps\n1. **Group by person**: Cluster all FacetMention items by `person_key`. Validate that each `person_key` matches one of the `extraction.people[*].person_key`. Ignore mentions whose key is missing or not in the roster.\n2. **Identify patterns**: Look for recurring themes, consistent attitudes, stated values, behavioral habits. Track how traits shift (or stay stable) across different job scenarios, roles, or environments called out in the interview.\n3. **Promote to traits**: Elevate mentions that reflect significant choices, preferences and values or that reveal stable characteristics (not one-off comments or interview topics).\n4. **Merge similar**: Combine semantically similar mentions into a single PersonaFacet with multiple evidence_refs.\n5. **Filter noise**: Skip generic interview content (topics discussed but not personal traits). Only keep facets that explain why they act the way they do across contexts.\n6. **Capture purchase intent**: When participants discuss products/services, extract facets that encode their evaluation criteria, willingness-to-pay thresholds, or decision triggers.\n\n\n## PersonaFacet Criteria\nEach `PersonaFacet.value` must be:\n- **Enduring**: Represents a stable trait, not momentary state\n- **Personal**: Describes the person, not just interview content\n- **Meaningful**: Highlights a differentiated choice, tension, willingness-to-pay stance, or value (skip generic attributes everyone would share)\n- **Specific**: Concrete phrasing with subject+predicate (e.g., \"prefers async communication for focus\")\n- **Evidence-backed**: Supported by at least 1 FacetMention (ideally 2+)\n\n## kind_slug Guide\n- **motivation**: What drives them (e.g., \"motivated by learning new skills\")\n- **value**: What they believe matters (e.g., \"values work-life balance\")\n- **attitude**: How they view things (e.g., \"skeptical of AI accuracy\")\n- **skill**: What they're good at (e.g., \"proficient in visual design\")\n- **preference**: How they like to work (e.g., \"prefers written documentation\")\n- **personality**: Behavioral tendencies (e.g., \"introverted in large groups\")\n- **identity**: Self-concept (e.g., \"identifies as generalist designer\")\n- **belief**: Worldview elements (e.g., \"believes design should serve society\")\n- **habit**: Regular behaviors (e.g., \"reviews notes daily before class\")\n- **constraint**: Limitations (e.g., \"limited by budget for tools\")\n\n## Evidence\n{{ extraction }}\n\n## Guardrails\n- Each `evidence_refs` array must contain valid `FacetMention.index` values from the input.\n- Never merge mentions from different people; keep persona facets scoped to one `person_key`. If multiple people share the same behavior, create separate facets referencing their respective evidence.\n- `confidence` should reflect: frequency (more mentions = higher), consistency (contradictions lower it), salience (strong emotional/attitudinal signal).\n- Do NOT create facets for interview topics unless they reveal a personal stance/value/habit.\n- When merging mentions, combine `evidence_refs` arrays.\n- Prefer 3-10 high-quality facets per person over 50+ low-signal ones.\n\nOutput ONLY valid JSON conforming to {{ ctx.output_format }}.\n\"#\n}\n\n// Test with sample extraction\ntest DerivePersonaFacets_Sample {\n  functions [DerivePersonaFacetsFromEvidence]\n  args {\n    extraction {\n      people [\n        {\n          person_key: \"participant-1\"\n          display_name: \"SPEAKER 2\"\n          inferred_name: \"Kai\"\n          role: \"participant\"\n        }\n      ]\n      evidence [\n        {\n          index: 0\n          person_key: \"participant-1\"\n          gist: \"Uses AI daily for essay writing\"\n          chunk: \"I use AI majority of the time when working through essays to help connect ideas together and format properly.\"\n          verbatim: \"I use AI majority of the time\"\n          anchors: {\n            speaker_label: \"SPEAKER 2\"\n          }\n          confidence: \"high\"\n        },\n        {\n          index: 1\n          person_key: \"participant-1\"\n          gist: \"Prefers working solo over groups\"\n          chunk: \"I think personally I work better when I'm alone.\"\n          verbatim: \"I work better when I'm alone\"\n          anchors: {\n            speaker_label: \"SPEAKER 2\"\n          }\n          confidence: \"high\"\n        }\n      ]\n      facet_mentions [\n        {\n          index: 0\n          parent_index: 0\n          person_key: \"participant-1\"\n          kind_slug: \"tool\"\n          value: \"uses AI for essay writing and formatting\"\n          confidence: 0.9\n        },\n        {\n          index: 1\n          parent_index: 0\n          person_key: \"participant-1\"\n          kind_slug: \"behavior\"\n          value: \"uses AI majority of time for academic work\"\n          confidence: 0.85\n        },\n        {\n          index: 2\n          parent_index: 1\n          person_key: \"participant-1\"\n          kind_slug: \"preference\"\n          value: \"prefers solo work over group work\"\n          confidence: 0.9\n        },\n        {\n          index: 3\n          parent_index: 1\n          person_key: \"participant-1\"\n          kind_slug: \"value\"\n          value: \"values working independently\"\n          confidence: 0.8\n        }\n      ]\n      scenes []\n    }\n  }\n}\n",
  "extract_evidence.baml": "// ============================================================================\n// Extract Evidence - Primary BAML Schema and Function\n// ============================================================================\n// Produces normalized evidence units from transcripts with timestamp anchors\n// for precise media playback and auditability.\n//\n// Previous version (extract_evidence.baml with string-based Anchor class) has\n// been deprecated in favor of this integer-based millisecond approach.\n// ============================================================================\n\n// === TurnAnchors: Standardized anchor format for transcript evidence ===\n// Uses integer milliseconds for direct video/audio seeking\nclass TurnAnchors {\n  start_ms int? @description(\"CRITICAL: Start time in milliseconds. Extract from transcript timestamps or chapter data. This is REQUIRED for video playback.\")\n  end_ms int? @description(\"End time in milliseconds when available\")\n  chapter_title string? @description(\"Optional chapter/section title\")\n  char_span int[]? @description(\"Optional [start,end] character offsets in transcript\")\n}\n\nclass EvidenceTurn {\n  person_key string @description(\"REQUIRED: Exact match to Person.person_key (e.g., 'participant-1', 'interviewer-1'). Must reference a person defined in the people array.\")\n  speaker_label string? @description(\"Literal transcript speaker label, e.g., 'SPEAKER A', 'Speaker B' or the provided diarization name\")\n  gist string @description(\"≤12-word essence of the turn; slide-like headline\")\n  chunk string @description(\"2–5 sentences capturing the person's full thought\")\n  verbatim string @description(\"≤15-word exact quote/snippet from the chunk\")\n  anchors TurnAnchors @description(\"Anchors to source for auditability\")\n  // confidence string @description(\"low | medium | high\")\n  why_it_matters string? @description(\"≤10 words on consequence/importance (e.g., trigger/impact; note if generalizable)\")\n\tfacet_mentions FacetMention[] @description(\"Facet mentions that appear in this turn\")\n  isQuestion bool? @description(\"TRUE if this turn contains a question (any speaker). Useful for filtering question-response patterns.\")\n\n  // Empathy map (high-signal only; leave empty if none)\n  says string[]? @description(\"High-signal quotes only; 0–2 (≤120 chars). Use when wording carries unique meaning beyond verbatim.\")\n  does string[]? @description(\"High-signal behaviors; 0–2. Imperative phrasing (present-habitual). Include frequency/recency if available.\")\n  thinks string[]? @description(\"High-signal inferred beliefs; 0–2. Only when justified by evidence.\")\n  feels string[]? @description(\"High-signal emotions; 0–2, with brief context and trigger if present.\")\n  pains string[]? @description(\"High-signal obstacles; 0–2. Prefer job-story: When [situation], blocked by [obstacle].\")\n  gains string[]? @description(\"High-signal outcomes; 0–2. Prefer job-story: so I can [outcome].\")\n}\n\nclass FacetMention {\n  // index int @description(\"0-based index within the stream for ordering\")\n  // parent_index int @description(\"Index of the EvidenceTurn this mention derives from\")\n  person_key string @description(\"REQUIRED: Exact match to Person.person_key. Must match the person_key of the parent EvidenceTurn.\")\n  kind_slug string @description(\"One: goal | pain | behavior | tool | value | requirements | preference | demographic | context | artifact | emotion\")\n  value string @description(\"CRITICAL: Human-readable descriptive text (≤12 words), NOT an ID or reference number. Examples: 'Healthcare Professional', 'prefers explicit topic mapping for workflow', 'requires calendar integration to schedule study'. NEVER use formats like 'ID:123' or numeric references. Prefer verb+object or noun+modifier. Include trigger/condition and objective when helpful.\")\n  quote string? @description(\"Optional ≤15-word supporting quote from the parent turn\")\n  // confidence float? @description(\"Discrete buckets recommended: 1, 0.75, 0.5, 0.25, 0\")\n}\n\nclass Scene {\n  scene_id string @description(\"Stable id for the scene/segment\")\n  start_index int @description(\"First EvidenceTurn index in the scene\")\n  end_index int @description(\"Last EvidenceTurn index in the scene\")\n  topic string @description(\"Short topic label for the scene\")\n  summary string? @description(\"1–2 sentence summary of what the scene covers\")\n}\n\nclass Person {\n  person_key string @description(\"REQUIRED: Deterministic slug like 'participant-1', 'participant-2', 'interviewer-1'. Number based on first appearance order. This MUST be used consistently in all EvidenceTurn and FacetMention references.\")\n  speaker_label string? @description(\"Literal transcript speaker label, e.g., 'SPEAKER A', 'Speaker B' or the provided diarization name\")\n\tperson_name string? @description(\"The person's common name, like John Smith, Sally A., etc.\")\n\tinferred_name string? @description(\"Preferred name if confidently inferred from context\")\n\trole string? @description(\"their role in the coversation (participant | interviewer | observer | moderator | customer | Sales Rep\")\n}\n\nclass Extraction {\n\t//  people EvidenceParticipant[]\n\t people Person[]\n\t evidence EvidenceTurn[] @description(\"Chronological stream of evidence turns\")\n\t facet_mentions FacetMention[] @description(\"Flattened array of all facet mentions for easier phase-2 processing\")\n\t scenes Scene[]\n}\n\nclass SpeakerUtterance {\n  speaker string @description(\"Speaker label like 'SPEAKER A', 'SPEAKER B'\")\n  text string @description(\"The utterance text\")\n  start int? @description(\"Start time in milliseconds\")\n  end int? @description(\"End time in milliseconds\")\n}\n\n// === Shared Support Classes ===\n\nclass Chapter {\n  start_ms int @description(\"Chapter start time in milliseconds\")\n  end_ms int? @description(\"Chapter end time in milliseconds (optional)\")\n  summary string? @description(\"Brief summary of this chapter/section\")\n  title string? @description(\"Chapter or section title\")\n}\n\nclass FacetCatalogKind {\n  slug string @description(\"Kind identifier, e.g., goal | pain | task | tool | value\")\n  label string @description(\"Display label for the kind\")\n}\n\nclass FacetCatalogEntry {\n  facet_account_id int @description(\"Facet account ID (primary key from facet_account table)\")\n  kind_slug string @description(\"Kind slug this facet belongs to\")\n  label string @description(\"Preferred display label\")\n  alias string? @description(\"Project-level alias to show instead of label when present\")\n  synonyms string[]? @description(\"Known synonyms and aliases\")\n}\n\nclass FacetCatalog {\n  kinds FacetCatalogKind[] @description(\"Merged catalog of facet kinds (project ▶ account ▶ global)\")\n  facets FacetCatalogEntry[] @description(\"Merged facet entries available to this project\")\n  version string @description(\"Opaque version string for caching and diffing\")\n}\n\nfunction ExtractEvidenceFromTranscriptV2(\n  speaker_transcripts: SpeakerUtterance[],\n  chapters: Chapter[],\n  language: string,\n  facet_catalog: FacetCatalog\n) -> Extraction {\n  client \"CustomGPT5\"\n  prompt #\"\nYou are an expert UX researcher.\nYour task is to produce an exhaustive, chronological Event Stream from an interview transcript so the reader can follow what happened moment by moment, with explicit mention-level signals. Do not summarize; capture every distinct signal as a separate mention. Do not perform catalog linking in this pass.\n\n## Steps\n1. Identify every human speaker. Populate the `people` array once with:\n   - `person_key`: deterministic slug per human such as `participant-1`, `participant-2`, `interviewer-1`. Derive the number from first appearance order. Reuse the EXACT same `person_key` string for all references to that person. Never reuse a slug for different humans.\n   - `display_name`: the literal transcript label (e.g., \"SPEAKER 2\", \"Kai\", \"Interviewer\").\n   - `inferred_name` and `role` when confident (role ∈ participant | interviewer | moderator | observer | customer | sales_rep).\n   - Include any known segments/personas/organization in the optional fields when the transcript states them.\n2. Slice the transcript into coherent, chronological turns (where each turn is a single speaker). Emit one `EvidenceTurn` per turn, anchored to the correct `person_key` with gist, chunk, verbatim, tags, anchors, confidence, and empathy map fields.\n3. For each `EvidenceTurn`, emit one or more `FacetMention` items—one per distinct, atomic signal (goal, pain, behavior, tool, value, preference, demographic, context, artifact, emotion, feature, price). Each `FacetMention` must reference its parent `EvidenceTurn` via `parent_index`. Keep `value` concrete and readable in isolation (≤12 words). Prefer verb+object or noun+modifier. Avoid vague superlatives (e.g., \"best\", \"amazing\") unless paired with a criterion. Include a short `quote` when high-signal.\n4. Segment the conversation into `Scene`s when the topic/goal shifts. Each scene spans a contiguous block of `EvidenceTurn.index` values and has a short topic label.\n\n## Selection Priorities\nHigh-severity pains, frequent/recency-marked behaviors, explicit goals, success criteria.\nWorkarounds, hacks, switching triggers, evaluation criteria, blockers, willingness-to-pay signals.\nMoments that reveal motivations, anxieties, decision criteria, or definitions of success.\n\n## SKIP Non-Evidence (Do NOT Extract)\n- Weather talk, bathroom breaks, technical difficulties\n- Social pleasantries (\"nice to meet you\", \"how are you\", \"have a great day\")\n- Procedural questions (\"can we continue?\", \"is this recording?\", \"can you hear me?\")\n- Off-topic chitchat unrelated to product, workflow, or user psychology\n- Interviewer instructions or transitions unless they reveal user confusion/friction\n\nExamples to SKIP:\n❌ \"It's really hot today\" - weather\n❌ \"Can I grab some water real quick?\" - procedural\n❌ \"That's fine, go ahead\" - generic acknowledgment\n❌ \"So, let's talk about...\" - interviewer transition (no signal)\n\nExamples to EXTRACT:\n✅ \"I wish the tool would...\" - pain/goal\n✅ \"I usually work around that by...\" - workaround/behavior\n✅ \"It's frustrating when...\" - pain with emotional signal\n✅ \"I use Notion because...\" - tool + rationale\n\nONLY extract turns with business or psychographic relevance.\n\n## EvidenceTurn\n- index: 0-based chronological index (strictly ascending) and equals its position in the stream.\n- **person_key**: REQUIRED. Exact match (character-for-character) to the `person_key` defined for that person in `people`. Never invent a new slug at the turn level. CRITICAL: Distinguish between interviewer and participant - if someone is asking questions, they're likely the interviewer; if answering, they're the participant.\n- gist: ≤12 words; no labels like \"Quote:\".\n- chunk: 2–5 sentences of the participant’s words.\n- verbatim: ≤15-word quote from the chunk.\n- **anchors.start_ms**: CRITICAL - ALWAYS use the `start` field from the corresponding SpeakerUtterance. This timing is already in milliseconds and is REQUIRED for video playback functionality.\n- anchors: include start_ms (REQUIRED), end_ms when available, speaker label, optional chapter_title.\n- confidence: low | medium | high. Map evidence strength: direct quote ≥ concrete behavior ≥ inferred belief.\n- **isQuestion**: Set to TRUE if this turn contains any question (explicit questions, requests for clarification, probes, etc.) regardless of speaker. FALSE or omit if no questions. Useful for filtering question-response patterns and conversation analysis.\n- empathy map: only when high-signal; 0–2 items per field; do not repeat gist/verbatim/facet values; leave empty if not useful.\n - why_it_matters: ≤10 words; express the consequence or importance (e.g., \"blocks timely status updates\").\n\n## FacetMention (extraction-only, no linking)\n- parent_index: points to the `EvidenceTurn.index` where the signal appeared.\n- **person_key**: REQUIRED. Must match the exact slug from `people` AND match the person_key of the parent EvidenceTurn. CRITICAL: Assign facets to the person who EXPRESSED the trait/behavior, not the person being discussed. If the interviewer asks \"What tools do you use?\", the participant's answer creates facets for the PARTICIPANT, not the interviewer.\n- kind_slug: one of goal | pain | behavior | tool | value | workflow | preference | demographic | context | artifact | emotion.\n- value: concrete, atomic (≤12 words). Prefer verb+object or noun+modifier. Include frequency/recency when stated (e.g., \"daily\", \"last week\"). Include trigger/condition and objective when helpful. For preference/value, compress subject + rationale into one field when possible: e.g., \"values integrated planning + calendar (tracks progress)\", \"prefers explicit topic mapping for workflow\", \"requires calendar integration to schedule study\".\n- quote: include when it strengthens auditability; ≤15 words.\n- confidence: one of 1, 0.75, 0.5, 0.25, 0.\n- Output one FacetMention per distinct signal in a turn; do not merge similar mentions across turns.\n\n## Scenes\n- Create a new scene when the topic/goal shifts meaningfully.\n- Each scene has `start_index`, `end_index`, and a short `topic` label.\n\n## Guardrails\n- Emit all items in ascending `index` / `parent_index` order.\n- Do not fall back to a generic person — if a turn's `person_key` cannot be matched to `people`, revisit your mapping rather than defaulting to the primary participant.\n- Do not output any catalog ids or proposals; linking occurs in a separate step.\n- Keep `value` and `verbatim` within word limits. Ban vague comparatives unless paired with a concrete subject/rationale. Each mention should be testable and specific (avoid grouping multiple subjects; emit one mention per subject).\n- When choosing empathy vs mention: prefer FacetMention as the authoritative signal; only add empathy items if they add non-duplicative skim value.\n- Prefer fewer, higher-quality turns over many weak ones; but do not drop distinct signals (emit mentions instead).\n- Output facet_mentions both nested in EvidenceTurn AND as a flattened top-level array (this enables phase-2 persona synthesis).\n\nSpeaker Transcripts (language={{ language }})\nEach utterance includes speaker label, text, and timing in milliseconds:\n{{ speaker_transcripts }}\n\nChapters (optional; may help anchoring)\n{{ chapters }}\n\n{% if facet_catalog and (facet_catalog.kinds|length > 0 or facet_catalog.facets|length > 0) %}\nFacet catalog (read-only; do not link in this pass)\n{{ facet_catalog }}\n{% endif %}\n\nOutput ONLY JSON conforming to {{ ctx.output_format }} (no prose/markdown). Ensure indices are contiguous from 0 and strictly ascending; each FacetMention.parent_index references an existing EvidenceTurn.index; omit empty/null fields.\n\"#\n}\n\n// Simple empathy test\ntest ExtractEvidenceFromTranscriptV2_EmpathyTest {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    transcript #\"\nINTERVIEWER: How do you feel about your current project management tool?\n\nPARTICIPANT: Honestly, it's really frustrating. I spend way too much time just trying to find where I put things. Like, I'll create a task and then I can't remember which project I assigned it to. It makes me feel disorganized and stressed out.\n\nINTERVIEWER: What do you do when that happens?\n\nPARTICIPANT: I usually end up searching through every project folder, which takes forever. Sometimes I just give up and create a duplicate task. I know it's not efficient, but I need to get my work done. I really wish there was a better way to organize everything automatically.\n\nINTERVIEWER: What would success look like for you?\n\nPARTICIPANT: I want to feel confident that I can find anything I need within seconds. When I'm in a meeting and someone asks about a project status, I want to pull it up instantly instead of saying 'let me get back to you on that.' That would make me feel so much more professional and in control.\n    \"#\n    chapters []\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n\n// Full dev test\ntest ExtractEvidenceFromTranscriptV2_Sample {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    transcript #\"\nKai K, College Freshman\nRick 6/11\nAudio transcripts from video-> Wav file -> Assembly.ai\n\nSPEAKER 1\nOkay, so um, so Kai, appreciate you getting. So just for clarification, what's your um, year, ah, in school. And what are you studying?\nSPEAKER 2\nI'm going to be starting my second year in college and I'm studying for a major of business administration.\nSPEAKER 1\nOkay, super. Um, and let's see, can you tell. So what we want to focus on is um, how students are studying and learning and doing their work for what we call like longer duration, uh, skills acquisition. So not like simply asking a question of the Internet of you know, what is this? Or how do you do that but more complex, in depth subjects where you might spend more time, um, and multiple sessions over it. So that's in particular what we're, what we're curious about. Um, but uh, maybe you can tell me a little bit about like reflecting of your last semester m to um, like what your day looks like.\nSPEAKER 2\nUm, okay, so my last two couple semesters I did a lot of in person classes. So my day consisted of just waking up breakfast and then I would head off to school. And then depending on the class I took during the day, for example I'd had a couple math classes. I would usually go to the library before and study up on just previous homeworks and then maybe after I would go to see a tutors because I, at Palomar I have a couple free tutors that I use. So I'd go there, study with some tutors and then I'd also take some individual times and like the little pods to write essays and focus on other classes.\nSPEAKER 1\nOkay, cool. What, what kind of information do you usually work with? Like what subjects?\nSPEAKER 2\nSubjects?\nSPEAKER 1\nYeah, subjects.\nSPEAKER 2\nRecently I took um, I did a couple film classes, I did speech class, a couple math classes, some calculus, algebra, and then I took an English critical thinking class as well.\nSPEAKER 1\nOkay, super. How do you usually start, um, diving into a new topic or subject?\nSPEAKER 2\nUm, when I start diving in usually from, if I'm given materials from my professors, I usually try and read as much of the material that they give me like books or examples or like lectures and examples from that is where I start the most with my research.\nSPEAKER 1\nOkay, so with the material that you've been given and then if you need to you go um, elsewhere. Um, yeah, anything with like study groups or um, apps or websites.\nSPEAKER 2\nUm, I mean sometimes groups. Because in my past I've had a couple classes where I use my math tutors and I meet with groups of people in the same class and we kind of bounce off each other with ideas for studying and stuff like that. But besides that I don't really use study groups that often.\nSPEAKER 1\nOkay, um, how about, like, you know, AI and, uh, things like that?\nSPEAKER 2\nYeah, I use a lot of A.I. just for, like, I use A.I. i would say majority of the time when I'm working through something, let's say I'm writing an essay and I've kind of, like, lost my train of thought or like, I'm kind of just missing something to connect my ideas together. I'll run something through AI and like, it'll help me connect my. What I wanted. What my evidence and what I wanted to say, to analyze it and helps me put it all together. And I also used it for, like, in math situations when I'd been struggling with the problem and I'd been, like, trying to solve it. I couldn't figure out the correct, like, format or equation. I would use that and have it show me the step by step of how to do it. And then I would apply that to other problems that were on my homework or my exams or things like that.\nSPEAKER 1\nOkay, so can you maybe tell me a little bit more about, like, the kind of the critical thinking or writing when you lost your train of thought? That sounds, um, interesting.\nSPEAKER 2\nYeah. So like, when I would use, like, for example, like, the last essay I wrote was about connecting multiple books that we read during my class to. Or, uh, it was supposed to be what was your favorite piece of material you read and what. For what reasons? And we just had to describe that with multiple subtopics of literary, uh, elements. And so I had to use a couple outside sources. So I took from, like, Skull and also books that I've read in class. And I had A.I. ah. Help me sometimes with connecting those outside sources to the book. Because I knew the book and I had the material, but I just didn't know really how to put them together in, like, an efficient way that made the most sense for me to use. So I had AI Kind of helped me understand how I can put this piece to this piece to make a whole piece to use for the evidence for the essay. So it kind of just helped me to put things together. And then from there I was able to revise my, um, sentences or paragraphs.\nSPEAKER 1\nOkay, super. So what. What kind of a prompt would you give it? Like, would you say, here's what I have so far. Help me fill in the blanks? Or how would you.\nSPEAKER 2\nYeah, I would say things along the lines of that. I would say, this is. This is what I have written from this paragraph so far, and I'm, um, happy. And then I would put A chunk of evidence that I needed to incorporate. I'd say copy and paste what I had so far and said, can you help me incorporate this next piece of evidence to make it flow smoothly into my paragraph? Something along the lines of that. And then it would give me, it would show what I'd already written and then another chunk that they added onto it and then I was able to revise from there.\nSPEAKER 1\nOkay, and then are you editing in the AI or are you copying and pasting into like Google Doc or something?\nSPEAKER 2\nI usually do, uh, Google Docs, so I get, I try and write my own stuff in Google Docs and then when I'm given the revised version, I open a separate Google Doc and I have them side by side so I can compare from what my work looks like to the example I'd say that AI's giving me so I can see them side by side and try and use the best parts of it together so I can make the best paragraph for myself.\nSPEAKER 1\nOh, okay. Is that, how does that work, work out for you? Is it easy or is it pretty, uh, is there any friction with that?\nSPEAKER 2\nUh, I haven't ran into too many problems about from that. Just being able to have the AI in a document that's I can edit and then also have mine open so I can see what my edits are looking like is pretty problemless. I haven't ran into any.\nSPEAKER 1\nOkay, so you can easily tell the difference between the documents?\nSPEAKER 2\nYeah, yeah, no, I haven't, never had any, haven't had any issues using AI to help me edit with anything.\nSPEAKER 1\nOkay, cool. Um, so what was like maybe the last time you worked with um, that type of a project? What was the, um, what was the subject and how did that, uh, how'd that go? Can you walk me through that a little bit more?\nSPEAKER 2\nYeah, sure. So the last time I'd say was that essay I was talking about is, uh, supposed to be a nine page or. Yeah, a nine page essay for my critical thinking and composition class. And the prompt was about my favorite book and using outside sources and stuff and. Sorry, can you say the question again? I got a little lost.\nSPEAKER 1\nYeah, no, just like, just walk me through the, the whole project. Yeah, yeah.\nSPEAKER 2\nSo once I had given my prompt, I started to do a rough draft. We did a rough draft in class or an outline I should say. And we were able to outline our paragraphs, created a thesis statement and then introduction sentences for each paragraph. Um, and then from there we were given feedback from our professor and then we were given time on our own to incorporate our body paragraphs to add on to those topic sentences from uh, two outside sources that we needed to find on our own and then a book of our choice that we read in the class. So then from there I just spent time revising like my. How making my topic sentence for the paragraphs correct and then putting the information that I found from the. Either the novel or outside source, depending on the paragraph or the subtopic, uh, that I was doing. And then I would start by in saying like, this is how this is from this like using the evidence. And then I would uh, analyze it using my own like, perspective of the book. And then I kind of just did that for the different subtopics and then finished it with a conclusion.\nSPEAKER 1\nOkay, cool. So is that. Were you. When did you start that? Um, it seems like you have to read there's some like, research or learning part.\nSPEAKER 2\nYeah.\nSPEAKER 1\nAnd then the writing part. Or is that. How did that go?\nSPEAKER 2\nSo yeah, we were. During the semester we had read various novels, so we just were able to pick a novel of our choice and then we were also told to find outside sources about that novel. So we spent some time looking online, going through scholarly articles to find something that would fit good into like how our um, the choice of our book and how the literary omens affect what making the book so good.\nSPEAKER 1\nHow did you like, when you were doing, going through that? It probably didn't just all happen in a day, right. There was probably days, multiple days or weeks, right?\nSPEAKER 2\nYeah, no, I for sure took multiple days to chunk it out and try and find. There's a lot of time on the Internet scrolling through to find the sites that I could, that I knew for sure because I had already had some ideas of what my paragraphs were going to be about. So I just mainly spending a lot of time trying to figure out sites that I could use that would fit good into the subtopics and it wouldn't all take one day. It took a lot of like, time and planning it all out.\nSPEAKER 1\nSo how, how did you like, take notes on the pieces of information that you were coming across and um, the thoughts you were having as you were going through that?\nSPEAKER 2\nI used a Google Doc. So I would read this, I would find the site and I would read and then I had a Google Doc open as well. And as if I found something interesting, like a good piece of evidence that I thought I could use, I could just copy and paste it into another Google Doc and then I would just press Enter and then I'd do a little bullet Point. And I'd say like, I could use this for this example of um, imagery and I could just like jot down a little bit of ideas and then I just start a new space underneath. Kind of just go through and say where I think I could use this information in my paragraphs.\nSPEAKER 1\nOkay, super. Um, are there parts of like that process or the tools that you really love or really hate?\nSPEAKER 2\nIn that process, I didn't find anything that I like truly hated. I'd say, I think that it was a pretty neutral thing. Like it wasn't difficult to ever find information and then just transferring it over into like a little uh, like evident sheet. I didn't have anything that gave me too much trouble or was too hard, but it also, I wasn't, I obviously didn't enjoy it. Like, it wasn't like something that was like, oh wow, this worked really good. It was kind of just drag and drop stuff.\nSPEAKER 1\nOkay, and what, when you were searching, what were you, Were you using Google Search or chat or like when you'd go to look for sources or did you. All the above.\nSPEAKER 2\nSo for the sources, I started out with Google and I couldn't really find anything that like met the requirements that my teacher wanted. So I just started to use um, Google Scholar and so I could find scholarly articles. And then what I would do is I would find a site and I'd read through it and I'd find the evidence. And then I also took it into chat and I would say, I ah, would copy the link and I would say I'm writing an essay on this. Do you think that this site and this information that I've taken would work? Would flow, get into a paragraph and then I would receive these back from chat.\nSPEAKER 1\nOkay, um, can you think of a time that you felt overwhelmed or uh, frustrated with the, the process?\nSPEAKER 2\nYeah, no, I've definitely went through some times of stress when I was trying to pile all my life information together. And sometimes like I would just hit like roadblocks or the evidence that I found. Like I thought it really was gonna work, but the way that I had approached the topic, it kind of changed what I was gonna say. So there's multiple times when I had like thought I had it all laid out perfectly and then my essay just kind of took a turn. Like I was like, yeah, you know, I don't really want to write about this part anymore. So I kind of like had to scratch the evidence, some of the evidence that I had, and go back and find more from those sources. So it definitely did get A little frustrating at symptoms.\nSPEAKER 1\nOkay. Um, but was that more like. Was that about the tooling, like the tools you're using, or more just the kind of. You think that's part of the process or. Um, I guess. Let me. Let me ask you a different question.\nSPEAKER 2\nYeah.\nSPEAKER 1\nWhat would the perfect solution look like for you? Forget about anything that you've seen me working on before or just given what you're doing now. Can you imagine a better way? Something that would make your life easier?\nSPEAKER 2\nYeah, I think that something that would make my life a lot easier is if I was able to throw my sight, the source that I was using into a program that would. And I could tell, like, what I wanted how. Or I could start and throwing it into there and then saying, I'm missing these pieces, like the evidence pieces. And I would like you to give me, uh, some ideas of what I could fill this in with. I already had my outline, but I could put it into a program that would give me, like. Because what I struggled with on mine was finding those pieces to put in there. So when I. If I had a program that would give me some pieces that would be a lot helpful, like in good formatting too, as well.\nSPEAKER 1\nUm, and what. In those pieces, what would they be, like? Um, points to support your thesis. Or like.\nSPEAKER 2\nYeah, I'd say points to support my introduction statements for each of the paragraphs. Like, something that would for sure, like, be concrete, um, evidence that I could rely on and not, like, have to go back because some, like, I looked at my sources and thought I could use it. And then I realized, okay, that's not really a good point that I wanted to use anymore. But if I had something that would give me something right away that I knew, then I could feel more confident in writing something about that.\nSPEAKER 1\nOkay, so, like, just getting started with, like, supporting points and telling you what's relevant or potentially relevant.\nSPEAKER 2\nYeah.\nSPEAKER 1\nYeah. Okay. Um. How much of your time do you think you spend doing this type of work?\nSPEAKER 2\nDuring this type of work, during the school semester, it's a lot more than now. Not obviously. I haven't been doing any school work this summer. I didn't take any summer classes. But throughout my first two semesters, I'd say I did a lot of work. Essays and stuff like that. And I used a lot. I've had a lot of help from AI to help format and stuff like that as well. As well as with the other classes too. I'd say I was using the programs Google Docs and Chat a lot during my first. My first year power.\nSPEAKER 1\nYeah. And like the most important, um, I guess the highest stak situations where you need to do this type of work would be what.\nSPEAKER 2\nO the highest stakes so far for me had been either my communication class or my critical thinking class were the highest stakes because for me like speaking class wasn't like I'm not a person who enjoys uh, public speaking so like having chat to help me like word my speeches correctly. So I was confident in what I was going to say. Helped a lot as well as with my writing. I feel like just chat gives me a lot of confidence and helps me like really gets the ball rolling when I'm starting my work.\nSPEAKER 1\nYeah. Okay, that's, that's interesting. So do you find you, you work solo or more in groups then how does that affect that?\nSPEAKER 2\nDefinitely more solo I'd say. And I think, I think personally I work better when I'm alone.\nSPEAKER 1\nMhm.\nSPEAKER 2\nIt's my take on that.\nSPEAKER 1\nCool. Um, yeah, so I think that's pretty much um, the bulk of what we wanted to ask. Um, but I guess this is like in terms of um, I guess maybe you can tell me a little bit more about time management and how you plan your day out or plan out working for a, you know, learnings content for a course. How do you approach that?\nSPEAKER 2\nYeah, for sure. So I try before I go to class, let's say I have class the next day or tomorrow the next day. I'd spend the day trying to get ahead on material that my teacher has given us. Like if we're supposed to be doing reading and reading for sure. And I'm making sure that I'm even a couple pages ahead and taking lots of notes and stuff like that. Just so I know that when I come to class I'm thinking fully prepared. Uh, and I try and manage my time well like I'll spend during the school year I was spending a lot of time like waking up, checking my email, checking any notifications I had on my Palomar account and then running through canvas and going through each of my classes to check, okay, when's homework due, when are readings due, what are my upcoming dates? And then I have a calendar that I use and I kind of just set up like this is do this, this is do that and I have time here and I work this day. So I use a calendar to kind of spread out my information that I know. So I know when I have free time to do stuff on my own or when I have time to. Okay, I need to do all my work now.\nSPEAKER 1\nUh, okay. Cool. Yeah. And you got, you have one job that you're working alongside when you're in school?\nSPEAKER 2\nYeah, just one job in a restaurant.\nSPEAKER 1\nAnd how, how much time do you spend a week in that.\nSPEAKER 2\nIn the restaurant? I'm only working, um, it's usually two to three days. So uh, it's around, I'd say 15 to 20 hours a week. So it's not super heavy, but.\nSPEAKER 1\nMhm. So you find it uh, easy enough to m. Set up your schedule like the way you're doing it now or um, does it change? Is it like more work when you get into a new class to like map it out or.\nSPEAKER 2\nYeah, I'd say, uh, that when I, when I start any class, it's kind of just like finding my bearings. Okay. This is how the teacher likes. This is their setup and this is what we're going to do weekly. So once I get like in the groove, like trying to get to a new class and get in my groove so I can, so I can understand what are my week to week's gonna look like so I can plan out my day to day in between and find out. Okay, I can do homework here, here and here. And then I'll be prepared for whenever this week's gonna throw at me.\nSPEAKER 1\nGot it. Super. Yeah. Okay, well that kind of concludes the interview at this point. Um, anything else you wanted to share or thought we should know?\nSPEAKER 2\nI think you covered it all. Had some questions I didn't think you're gonna ask, but yeah, I think you got it all.\nSPEAKER 1\nOkay, super. Um, so next I wanted to take a couple minutes and show you some um, concepts that we're working on, um, that you know, may or may not relate directly to what you were saying. But we're trying to um, work through some different ideas. Um, so let me, let me try and load this up and I'll share my screen and um. All right. Okay. So these are, these are just some concepts. M. I'm going to kind of walk through how we envision this potentially working and I'd love for you to just jump in and um, you know, ask questions or um, say hey, that's cool. Or that I wouldn't use that, that's, that's useless. Or you know, give a thumbs up, thumbs down, or ask further. So, so one of the ideas here is that we'd start um, in the beginning with allowing you to ask something. So you could type in a question or you um, could, um, let's see. Or you could upload some content. Right.\nSPEAKER 2\nAnd so yeah, I like that that's a good, um, adaptation because I feel if you don't have like, I feel for the most other AI sites that you, that are on the Internet already, you have to be signed in or have an account, some cost money, even just like upload images. And I feel like if I had the ability to upload stuff like that, it would make things a lot m. Easier than having to copy and paste or reword what I'm saying. So I like that. So.\nSPEAKER 1\nOkay, um, cool. And then after you, you upload something, we want to, you know, dive in deeper and ask you a couple questions so we can give you better, um, guidance. So what are you trying to do, like master a topic, write an essay, and then we want to ask you what do you already know about this subject? Um, okay, so to help gauge where to start and at what level. Right. And so what level of education should, should we be thinking about? Right. College. And you know, you could say, I know nothing. Or um, you know, you can add, add that in. And in terms of, as well onboarding, we, we want to ask you, like, well, how deep do you want to go? Right. Um, do you want to just an introductory level intermediate, or you want to go really deep and, and get expert on it? Right. Um, yeah. Is that clear what we're, we're doing there?\nSPEAKER 2\nYeah. No, I think that's really smart. I feel like other AIs are just giving you, if you're asking it a question, they're just giving you the answer at a level you don't even know. So it's kind of hard. Like for example, if someone's gonna have a math problem and they're in 10th grade for whatever, and then AI is gonna give them a way to solve it that they don't even know yet because they haven't learned, which when, if you use this program, you would have known because AI, ah, the AI would have said, okay, he's in 10th grade. He shouldn't be doing calculus to solve this problem. He should be doing algebra. So I think that's pretty cool to know what level you want the response in.\nSPEAKER 1\nYeah, super. Okay, so the next thing we going to ask you is, um, breadth versus depth. Um, we allow you to choose how many different topics in, in this, in the subject to cover and explore. So you can have like a really narrow, focused view, um, or pick on this scale of how broad and comprehensive um, you want to go. And there's just this little image here that um, I don't think all the images are exactly right, but um, I'm wondering if this is clear to you and you understand what it's talking about.\nSPEAKER 2\nYeah, no, I understand from the diagram, I understand that.\nSPEAKER 1\nCould you see yourself using this in some way, um, to con. Control the experience?\nSPEAKER 2\nYeah, no, I could see that working well in my, in my experience of schooling and using AI, I think this would work well.\nSPEAKER 1\nOkay. And then, um, the other, you know, this is kind of like question that we had asked before we dive into it is, you know, what mode do you want to work in right now? Um, you know, considering the other tools you have, this is a little different because we're giving you options to have more of a conversational dialogue, like use the AI as a chat partner, like where it'll converse with you or you can say, you know, I just need to do exam prep. So it's a, I want to have more of a, uh, quiz and flashcard type of approach to things. Tell, uh, me the key terms, uh, break things down. Uh, for me, um, versus some of the others are more, um, you know, analytical or creative in their nature.\nSPEAKER 2\nYeah.\nSPEAKER 1\nSo maybe just take a second and see if, you know, be curious if this makes sense to you.\nSPEAKER 2\nYeah, I know that makes total sense to me. I, I can understand that as well. When I, uh, sometimes when I need to use AI, I need to use it strictly for preparing for an exam, which obviously I would use exam prep. And I think that putting the options of the mode is like really important because you need, if you know what you're using AI for, like if you know exactly what you're coming in to get. I think that these modes make it easier for. To not get mixed up and stuff that isn't going to apply to you directly. So I think this is a great, another tool that works great.\nSPEAKER 1\nSuper. Okay, so those are like those four questions. And then, um, what we do is we. You then say, okay, create my learning plan. And what it will do is if you uploaded a document, it will analyze that. If you just give it a question, it'll analyze that and it will come up with learning objectives. So a series of things to learn in steps, kind of like a plan. Um, and then it will also map out each of the topics, um, into sub points. And so, um, does this screen, um, how does this speak to you? Do you, um.\nSPEAKER 2\nI, I like this. Again, I think this is interesting because if by applying a document you can. I didn't. I think it's interesting to have that the AI will create their own subtopics and also like the progress bar. So to keep track of what, how far you've come and things like that I also think would be like a good addition, if this was at all possible, is like going through the topics and then the ones that you've mastered or the ones that you're consistently getting correct, like slowly begin to drop out of your studying because you've already known them. Like the still questions will still pop up occasionally, but, uh, it won't be as heavily focused on that one section that you fully grasp.\nSPEAKER 1\nSuper great, great idea. Yeah. Um, okay, well let me dive into some of these here. And so, um, the topic map, again, this is, think of this as. This isn't exactly what it looks like, but you've seen other versions, right. Where the lines are connecting to give you the hierarchy. So that's kind of what's in there. Um, the learning plan is a newer thing. And so this is like taking the whole, all the whole topic map and then breaking it into chunks that you would then go through and work on. And so it starts here with, um. Well, I guess let me just ask you if you understand what's, what's in here or if you have any questions before I explain it.\nSPEAKER 2\nYeah, no, I think I get it. I think I understand.\nSPEAKER 1\nOkay. So when you finish certain things, you just simply cross them off. Right. And then that will update your progress bar.\nSPEAKER 2\nUm.\nSPEAKER 1\nUm, I'm curious your feedback on this. So there's something called the Bloom taxonomy, which kind of uh, measures how deep you're getting into a subject. And there's like six different levels. And starting with just remembering the facts and then being able to understand them, compare them to other things, make judgments, and then actually synthesize and create new ideas based on what you've just learned. And so that's what these little B1, B2, B4, that's what those things are. And then you see at the end you get down to B6 of creating.\nSPEAKER 2\nUh, so those are the levels of understanding that are, you can work for example, that first bullet, that first line that identified the major components of Earth's water cycle. So that's at a B1 right now, but it'll, it can increase up the scale to a B6.\nSPEAKER 1\nYeah. So the, the understanding the components of the water cycle would be like the first step in the journey, like up the mountain. Think of it that way. Like, think of it like a two dimensional space. There's a breadth of things and then there's like how, how deep you, you get into them. And so at the end here is you, it Wants you to design a water management plan. Um, and so that's actually creating. So it builds on the fact of all the stuff that you've remembered and learned before.\nSPEAKER 2\nYeah, yeah, I get that. I like that a lot.\nSPEAKER 1\nOkay, cool. And then, um, you could also have things in here like, you know, write a paper or, um, study, you know, study for a quiz. So think of it like a little task management.\nSPEAKER 2\nYeah.\nSPEAKER 1\nThing. And one thing that's not in here that I'm considering is integrating it with the calendar in some way, so to say. Um, okay, you've got a test on Friday, today is Wednesday. Um, let's break up your studying over the next two and a half days into these sections.\nSPEAKER 2\nYeah, no, I think that's a great idea. And personally, for me as a person who likes. I love. I like to have all my stuff laid out and understand how to chunk up my work efficiently. And I think that this breakdown is very good. And I would like. I would enjoy working with something like this. And then also to have it on my calendar as well would help me even more to lay out my days, which makes my life a lot easier personally. Uh-huh.\nSPEAKER 1\nOkay. So you actually use the calendar in your phone or like that?\nSPEAKER 2\nYeah, I have. Have paper calendars I write down stuff on.\nSPEAKER 1\nOkay.\nSPEAKER 2\nBut I do utilize my phone calendars.\nSPEAKER 1\nOkay. Um, so would even like showing it as a list of like, here's like the three things and be helpful. Could you imagine what else you would want that to look like?\nSPEAKER 2\nLike comparing the list.\nSPEAKER 1\nWell, how would. What would work best for you? What would your ideal be? Given that now, you know, I can maybe create these, um, these tasks for you. How would you ideally want to consume them and. And use them in your day?\nSPEAKER 2\nSo, yeah, I think that putting them on a calendar would be a good idea. And then from like having a time, like, you could also cut out personally, you could cut out a time period every day that you know that you're going to work on it. And then having like, maybe a link from. If you want to start the first step and then having clicking the link and it'll be able to pop up and show you where you should work on stuff like that. Like, having an open link to use would be a good idea. I think I would use that for sure.\nSPEAKER 1\nSuper. Okay, so like, if you clicked on one of these things and then you were taken to a page like this, so this would give you the information. And then what if you could then click, uh, on discuss and then you can actually have a chat with An AI mentor.\nSPEAKER 2\nYeah, that sounds really smart.\nSPEAKER 1\nAnd then you could take a practice quiz on that specific set of information in that topic.\nSPEAKER 2\nYeah. Test your knowledge at the end to see how far you've come. I like that too.\nSPEAKER 1\nOkay, cool. Um, and then you could see your progress of how far you've gotten.\nSPEAKER 2\nI like that mastery the progress a lot. Especially when it gives you the breakdown of those topics with their other topics. I think that's really cool. Cause that, uh, I like to see how far I've come in, what I've learned so far. And like, the breakdown is just looks really good.\nSPEAKER 1\nOkay, super. So, uh, that's. That's really all I wanted to show you and get, get your feedback on these different things.\nSPEAKER 2\nYeah. Sweet. No, I mean, it looks amazing compared to all the other AIs I've used this program from, like the way that it's mapping out topics and then the planning, especially if the calendar could be incorporated. And then the progress bar, it looks best like, compared to all the other AIs that I've used. And this looks like it'd be the most promising.\nSPEAKER 1\nSuper. Okay, curious. Do you. Do you pay for any of the other tools that you use?\nSPEAKER 2\nI do not. No, I don't pay for any of them. I just mainly utilize the free ones.\n    \"#\n    chapters [ { start_ms 0, end_ms 60000, title \"Onboarding\" } ]\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n",
  "extract_insights.baml": "enum Emotions {\n  Abandoned\n  Accepted\n  Aggressive\n  Amazed\n  Angry\n  Annoyed\n  Anxious\n  Apathetic\n  Appalled\n  Aroused\n  Ashamed\n  Astonished\n  Awe\n  Awful\n  Bad\n  Betrayed\n  Bitter\n  Bored\n  Busy\n  Cheeky\n  Confident\n  Confused\n  Content\n  Courageous\n  Creative\n  Critical\n  Curious\n  Depressed\n  Despair\n  Detestable\n  Disappointed\n  Disapproving\n  Disgusted\n  Disillusioned\n  Dismayed\n  Dismissive\n  Disrespected\n  Distant\n  Eager\n  Embarrassed\n  Empty\n  Energetic\n  Excited\n  Excluded\n  Exposed\n  Fearful\n  Fragile\n  Free\n  Frightened\n  Frustrated\n  Furious\n  Grief\n  Guilty\n  Happy\n  Helpless\n  Hesitant\n  Hopeful\n  Horrified\n  Hostile\n  Humiliated\n  Hurt\n  Inadequate\n  Indifferent\n  Indignant\n  Inferior\n  Infuriated\n  Inquisitive\n  Insecure\n  Insignificant\n  Inspired\n  Interested\n  Intimate\n  Isolated\n  Jealous\n  Joyful\n  Judgmental\n  Let_down\n  Lonely\n  Loving\n  Mad\n  Nauseated\n  Nervous\n  Numb\n  Optimistic\n  Out_of_control\n  Overwhelmed\n  Peaceful\n  Perplexed\n  Persecuted\n  Playful\n  Powerful\n  Powerless\n  Pressured\n  Proud\n  Provoked\n  Rejected\n  Remorseful\n  Repelled\n  Resentful\n  Respected\n  Revolted\n  Ridiculed\n  Rushed\n  Sad\n  Scared\n  Sensitive\n  Shocked\n  Skeptical\n  Sleepy\n  Startled\n  Stressed\n  Successful\n  Surprised\n  Thankful\n  Threatened\n  Tired\n  Trusting\n  Unfocussed\n  Valued\n  Victimized\n  Violated\n  Vulnerable\n  Weak\n  Withdrawn\n  Worried\n  Worthless\n}\n\n\nenum BBValues {\n    Accountability\n    Achievement\n    Adaptability\n    Adventure\n    Altruism\n    Ambition\n    Authenticity\n    Balance\n    Beauty\n    Being_the_best\n    Belonging\n    Career\n    Caring\n    Collaboration\n    Commitment\n    Community\n    Compassion\n    Competence\n    Confidence\n    Connection\n    Contentment\n    Contribution\n    Cooperation\n    Courage\n    Creativity\n    Curiosity\n    Dignity\n    Diversity\n    Environment\n    Efficiency\n    Equality\n    Ethics\n    Excellence\n    Fairness\n    Faith\n    Family\n    Financial_stability\n    Forgiveness\n    Freedom\n    Friendship\n    Fun\n    Future_generations\n    Generosity\n    Giving_back\n    Grace\n    Gratitude\n    Growth\n    Harmony\n    Health\n    Home\n    Honesty\n    Hope\n    Humility\n    Humor\n    Inclusion\n    Independence\n    Initiative\n    Integrity\n    Intuition\n    Job_security\n    Joy\n    Justice\n    Kindness\n    Knowledge\n    Leadership\n    Learning\n    Legacy\n    Leisure\n    Love\n    Loyalty\n    Making_a_difference\n    Nature\n    Openness\n    Optimism\n    Order\n    Parenting\n    Patience\n    Patriotism\n    Peace\n    Perseverance\n    Personal_fulfillment\n    Power\n    Pride\n    Recognition\n    Reliability\n    Resourcefulness\n    Respect\n    Responsibility\n    Risk_taking\n    Safety\n    Security\n    Self_discipline\n    Self_expression\n    Self_respect\n    Serenity\n    Service\n    Simplicity\n    Spirituality\n    Sportsmanship\n    Stewardship\n    Success\n    Teamwork\n    Thrift\n    Time\n    Tradition\n    Travel\n    Trust\n    Truth\n    Understanding\n    Uniqueness\n    Usefulness\n    Vision\n    Vulnerability\n    Wealth\n    Well_being\n    Wholeheartedness\n    Wisdom\n}\n\n\nclass ExtractedInsight {\n\t// While trying to do **GOAL/Desired_outcome**, people struggle with **pain** because **WHY: Details/context**.\n\n\tname string @description(\"Short Text description of the insight in up to 5 words\")\n\tpain string | null @description(\"Pain, discomfort, or friction the user experiences in doing a task\")\n\tdetails string | null @description(\"The why or cause of the pain. Details and background leading to or causing the pain. Multiple sentences or bullet points as needed.\")\n\tevidence string | null @description(\"A verbatim quote from the participant in their own words. Include time stamp at end in parentheses.\")\n\tdesiredOutcome string | null @description(\"Desired outcome or benefit the user wants to achieve\")\n\n\t// Research validation fields\n\tassumptionAlignment string | null @description(\"How this insight relates to existing assumptions: 'SUPPORTS', 'REFUTES', 'NEUTRAL', or 'UNEXPECTED'. Be explicit about which assumption it addresses.\")\n\tresearchQuestionAnswered string | null @description(\"Which specific research or decision question does this insight help answer? Be explicit about the connection.\")\n\tevidenceStrength string | null @description(\"Strength of supporting evidence: 'DIRECT_QUOTE', 'CLEAR_BEHAVIOR', 'IMPLIED', or 'WEAK'. How confident are we in this finding?\")\n\tproductImplication string | null @description(\"What does this mean for product decisions? How should this insight influence our roadmap or strategy?\")\n\tfollowUpQuestions string | null @description(\"What new questions does this insight raise? What should we investigate further?\")\n\n\temotionalResponse Emotions @description(\"describe the emotion the person feels about this using the Emotions enum.\")\n\tunderlyingMotivation string | null @description(\"why do they want to achieve this, or overcome the pain?\")\n\tvalues BBValues[] @description(\"Which values is the person expressing?\")\n\tcategory string @description(\"The topical theme or category of the insight to help us group similar insights\") @@dynamic\n\tjourneyStage string @description(\"User journey stage in the application or process of insight, e.g. Awareness, Onboarding, Planning, Learning, Assessing, Progress, Community, Support, Other\")\n\tjtbd string | null @description(\"The user story or **Job to be done** style phrasing of what the user wants to accomplish, eg When I … I want to … so I can …\")\n\tcontradictions string | null @description(\"Potential contradictions and themes explicitly or implicitly by omission, things that the participant doesn't say, e.g. given an opportunity to discuss A,B,C, they only discussed A. Does the user discuss opposing claims?\")\n\trelatedTags string[] @description(\"Related tags or keywords to the insight. Make tags conceptual, not UI feature names (e.g. social_accountability, not leaderboard)\")\n}\n\nclass InterviewMetadata {\n\ttitle string @description(\"Title of interview\")\n\tdate string | null\t@description(\"Date of interview in ISO format: YYYY-MM-DD, (e.g. 2024-07-23) or Null if unknown\")\n\tinterviewer string | null\t@description(\"Interviewer name, or null if not identifiable\")\n\tdurationMin int | null @description(\"Duration of interview in minutes\")\n}\n// Process\n// upload media (video, audio, etc.) create interview record points to media file\n// get file -> send to AssemblyAI to transcribe -> TEXT FILE -> add into interview record (string)\n// --> extract insights & metadata (about interview)\n// -> save interview wrapper, participant, insights :: Some DB Mapping\n\nclass Participant {\n\tname string | null\t@description(\"Participant name, or null if not identifiable from transcript\")\n\tpersona string | null\t@description(\"A more fine-grained personalization within the segment that captures the participant's specific experiences, behavior, and preferences. up to 3 words. Null if unclear.\")\n\tparticipantDescription string | null @description(\"A concise narrative: who they are, their workflow, top frustrations, aspirations, and any standout quotes that define them. <= 7 sentences. Null if insufficient information.\")\n\tfacetSummary string | null @description(\"Summarize the participant's key persona facets, motivations, and behavioral signals surfaced in the interview. <= 5 sentences. Null if insufficient information.\")\n\tsegment string? @description(\"Participant segment, eg. Teacher, Student, Parent, etc.\")\n\tcontactInfo string? @description(\"Participant contact information if given\")\n}\n\nclass InterviewExtraction {\n\tmetadata InterviewMetadata\n\tparticipant Participant\n\tinsights ExtractedInsight[]\n\trelevantAnswers string[] @description(\"List of participant responses that directly address the research objectives, business goals, and key decisions.\")\n\tobservationsAndNotes string @description(\"Concise participant description capturing their attitude, needs, and why they matter for the research objectives.\")\n\thighImpactThemes string[] @description(\"Interview key takeaways. List the 3 strongest takeaways and explicitly tie each to a decision or research question (e.g., 'Decision Q: Pricing — Customers balk at annual contracts')\")\n\topenQuestionsAndNextSteps string @description(\"What next steps should we take to validate our hypotheses or address our knowledge gaps? Pithy statements.\")\n}\n\n\nclass SetRecord {\n\tterm string @description(\"Short, descriptive name (1 - 5 words usually). These are usually tags or keywords, phases, stages, or themes.\")\n\tdefinition string @description(\"Succinct definition of the term.\")\n}\n\nclass Set {\n\tname string @description(\"Name of the set\")\n\tdescription string @description(\"A succinct description of the set and how it will be used.\")\n\tmembers SetRecord[] @description(\"A set of terms and definitions. These are usually tags or keywords, phases, stages, or themes that can be applied in various situations to force clarity.\")\n}\n\nfunction ExtractInsights(transcript: string, userCustomInstructions: string) -> InterviewExtraction {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    Extract targeted insights from this interview transcript that directly address research questions and validate/refute key assumptions.\n\n    Focus on extracting succinct takeaways that answer:\n    - How do the participant's responses support or challenge our core assumptions?\n    - What specific evidence validates or contradicts our hypotheses?\n    - Which research questions does this interview help answer and how?\n    - What unexpected findings emerged that we didn't anticipate?\n\n    For each insight, be specific about:\n    - Whether it SUPPORTS, REFUTES, or is NEUTRAL toward existing assumptions\n    - The strength of evidence (direct quote vs. implied behavior)\n    - How this finding impacts our understanding of the problem space\n    - What follow-up questions this raises for future research\n\n    Prioritize insights that:\n    1. Directly answer key research/decision questions\n    2. Challenge or validate core product assumptions\n    3. Reveal unexpected user behaviors or needs\n    4. Provide actionable direction for product decisions\n\n    ## Participant Profile Requirements\n    - Populate `participant.participantDescription` with a vivid, objective summary of who the participant is, their workflow, and why they matter for the project (<= 7 sentences).\n    - Populate `participant.facetSummary` with the most important persona facets, motivations, and behavioral signals that emerged. Connect facets to supporting evidence where possible.\n    - Ensure `relevantAnswers` contains verbatim or paraphrased responses that directly answer our research objectives, including timestamps when available.\n\n    ## Key Takeaway Formatting\n- `highImpactThemes` must contain up to three bullets that mention the specific decision or research question they serve (use the exact question text or a concise alias).\n- Write each takeaway as \"Question Label — conclusion\" so the relationship is unambiguous.\n- Do not restate raw facts; synthesize the implication relative to the question.\n- REQUIRED: Always generate at least 1 highImpactTheme, even if it's a general takeaway about the interview.\n\nCustom research focus:\n{{userCustomInstructions}}\n\nInterview transcript:\n{{ transcript }}\n\nOutput format:\n{{ ctx.output_format }}\n  \"#\n}\n\nfunction CreateSet(instructions: string) -> Set {\n\tclient \"CustomGPT4oMini\"\n\tprompt #\"\n\t\tCreate a set of terms with definitions, based on the following instructions.\n\t\tWhen creating the set, try to use simple terms and concise definitions that are easy to understand.\n\t\tTry not to repeat words if not needed. e.g instead of A stage, B stage, C stage. Just A, B, C.\n\n\t\tInstructions:\n\t\t{{ instructions }}\n\t\tOutput format:\n\t\t{{ ctx.output_format }}\n\t\"#\n}\n\nfunction GenerateKeyTakeawaysFromEvidence(evidence: EvidenceTurn[], userCustomInstructions: string) -> InterviewExtraction {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    Generate targeted insights and key takeaways from this structured interview evidence data.\n\n    Focus on extracting succinct takeaways that answer:\n    - How do the participant's responses support or challenge our core assumptions?\n    - What specific evidence validates or contradicts our hypotheses?\n    - Which research questions does this interview help answer and how?\n    - What unexpected findings emerged that we didn't anticipate?\n\n    For each insight, be specific about:\n    - Whether it SUPPORTS, REFUTES, or is NEUTRAL toward existing assumptions\n    - The strength of evidence (direct quote vs. implied behavior)\n    - How this finding impacts our understanding of the problem space\n    - What follow-up questions this raises for future research\n\n    Prioritize insights that:\n    1. Directly answer key research/decision questions\n    2. Challenge or validate core product assumptions\n    3. Reveal unexpected user behaviors or needs\n    4. Provide actionable direction for product decisions\n\n    ## Participant Profile Requirements\n    - Populate `participant.participantDescription` with a vivid, objective summary of who the participant is, their workflow, and why they matter for the project (<= 7 sentences).\n    - Populate `participant.facetSummary` with the most important persona facets, motivations, and behavioral signals that emerged. Connect facets to supporting evidence where possible.\n    - Ensure `relevantAnswers` contains verbatim or paraphrased responses that directly answer our research objectives, including timestamps when available.\n\n    ## Key Takeaway Formatting\n    - `highImpactThemes` must contain up to three bullets that mention the specific decision or research question they serve (use the exact question text or a concise alias).\n    - Write each takeaway as \"Question Label — conclusion\" so the relationship is unambiguous.\n    - Do not restate raw facts; synthesize the implication relative to the question.\n    - REQUIRED: Always generate at least 1 highImpactTheme, even if it's a general takeaway about the interview.\n\n    ## Evidence Analysis Guidelines\n    - Analyze patterns across multiple evidence units, not just individual quotes\n    - Look for contradictions or tensions in the data\n    - Identify themes that emerge from combining different types of evidence\n    - Consider the context and timing of responses (anchors)\n    - Weight evidence by modality (observations > stated preferences > behaviors)\n\n    Custom research focus:\n    {{userCustomInstructions}}\n\n    Structured Evidence Data:\n    {{ evidence }}\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest create_set_Personas {\n\tfunctions [CreateSet]\n\targs {\n\t\tinstructions #\"\n\t\t\tUp to 3 Suggested User Personas for an AI Learning Platform. We will use this to test our hypothesis of user problems with learning, organizing and studying.\n\t\t\tWe suspect many younger students have some kind of learning difference or accomodation, such as dyslexia, ADHD, Autism, etc..\n\t\t\tKeep it fun and personal.\n\t\t\"#\n\t}\n}\n\ntest create_set_JourneyStages {\n\tfunctions [CreateSet]\n\targs {\n\t\tinstructions #\"\n\t\t\tCreate a set of User Journey Stages for an AI Learning App.\n\n\t\t\"#\n\t}\n}\n\ntest extract_insights_Jerad {\n  functions [ExtractInsights]\n  args {\n\t\tuserCustomInstructions #\"\n\t\tGive me at least 4 insights that only a german scientist would notice.\n\t\t\"#\n    transcript #\"\n\t\t\tSpeaker B[0:00 - 0:01]: Hey, so today is June 11th, 2025 and I'm Rick and here speaking with Jerad, a friend and tutor.\n\n      Speaker A [0:01 - 1:34]: AI to like, augment technology and use it to. To show that someone's learned something rather than like, they're all afraid that people are going to use AI to avoid learning or avoid work. Um, so if, if AI can be part of the process, you know, as it is here with. With, um, you know, collecting knowledge and organizing knowledge, um, and then the next step would be like, what are you going to do with that knowledge you've collected and organized? And um. I think you're the one that talked about like, the. Whoa. Oral report. You know, that's. That's a really big one. Um, and just, uh, you know, if you went one step further, what if. What if you could actively exercise that information in form of like a debate? And that's what I really came to is like the, the probably most complicated or sophisticated way to use your. The knowledge that you organize through a tool like this would be to, you know, participate in a debate where you had to defend the knowledge that you organized. Because if you're just organizing it and repeating it, you know, that's is organizing. It's basically automated. Um, repeating it is memorizing it. But then. And it's kind of like your hierarchy too, you know, if, if you can debate it with someone else who maybe organized it and takes a different stance, um, now you have to really understand it to do that.\n\nSpeaker B [1:34 - 1:36]: Exactly. Yeah.\n\nSpeaker A [1:36 - 1:57]: Yeah. So, um, you know, I, I think what, what teachers would like to see is how, um, you could. You could, you know, design with that in. In mind. You know, how. How can this tool be.\n\nSpeaker B [1:58 - 1:58]: Um.\n\nSpeaker A [1:58 - 2:38]: So right now the tool lets them do what they want, right? You can make a report with it, you can get ready for your oral report, you can make, you know, your notes, stuff like that. But how can it help the teacher by saying, like, by preparing them for a debate, you know, um, or preparing them to, uh, to defend this information, um, or to exercise it. Um, and I don't know if that becomes, you know, um, a description, a feature or a perspective, you know, like, like, um, a way of viewing the information.\n\nSpeaker B [2:38 - 2:39]: Yeah, um.\n\nSpeaker A [2:40 - 5:05]: Uh, but I, I think that would really. And if you could get, you know, if you could build it around that exercise, all of a sudden that becomes something like a midterm. You know, it's like, hey, class, um, now. Now we're going to, you know, um, pull up this tool and, and get ready for our, you know, once a semester, um, you know, assignment in which we, you know, pick a topic and pick a perspective and you guys are going to go out, you Know, um, collect information, organize it and prepare yourself to participate in some kind of dialogue with the classroom or participate in a dialogue with a different student. Um, and yeah, I think that's. And also like, you know, as I'm m talking about, you know, dialogue, um, going so far as to be able to um, you know, generate, let's say like um, a ah, metaphor or something like that. Like when you teach, um, you use. You lean heavily on metaphors. And I think that was another part of the hierarchy we were talking about too. Um, you know, repeating information and then getting to the point where you can actually teach something. So that requires the student to understand the perspective of their peers, um, and put themselves back in their own shoes, you know, a week ago before they collected this information. And you know, since they went through the process of not knowing, uh, researching, collecting, organizing and now they're at the point where they can, you know, um, make their own opinion on something. And now then they go to teaching, um, they're going to have to uh, let's say, distribute the knowledge. They're going to have to, to give the information to someone else in a way that they can pick up on it without going through the same process that they went, you know, their, their students aren't going to. Or their peers aren't going to collect the information, study it, go through it like they just did. But if they can give it to them in the form of, you know, uh, an analogy or something that um, even better would be to incorporate what they had all learned in that same class.\n\nSpeaker B [5:06 - 5:07]: Um, yeah.\n\nSpeaker A [5:07 - 5:27]: Um, you know, now they're up there in place of the teacher giving a lecture. Um, so I, I think, yeah, it's, it's really comes down to dialogue. Whether that's a debate or whether that's you know, a giving a lecture. I um, think those are, you know, showing that. That top of the pyramid.\n\nSpeaker B [5:27 - 5:27]: Yeah.\n\nSpeaker A [5:28 - 6:11]: Um, again, I think we kind of right now the tools are, are aimed at, at the student or they're aimed at the person who's trying to learn and then do something with that knowledge. But if we could have it, um, it's still the same tool but pitched in a way where it's like, hey teachers, this is a great tool to help you, um, incorporate AI into your class while still, you know, um, giving the student an opportunity to learn. Yeah, um, it's going to be part of, part of work. You know, it's, it's, you know, it's letting them practice that. So m. Yeah.\n\nSpeaker B [6:12 - 6:52]: Interesting. Now I think that's Because I had shown you a little bit before, and that seems like it sparked, uh, this conversation a little bit. Um, what's new to me is the metaphor and the peer education kind of like, hey, you have one student teaching another student, which I think is indeed novel. Um, at least from my perspective. Could you. Would you mind, like, resetting me, like, on your. Because you're tutoring one on one now, right? Is that correct or.\n\nSpeaker A [6:52 - 8:12]: Yeah, so I, I do some tutoring, but now I mostly work with other tutors and kind of program directors. So right now, like, I'll sit down with a tutor, um, we'll look over, like, videos of them tutoring, and I'll help them be a little more effective. Um, I'll help them with exercises, and sometimes I'll help them with theory. Like here's, you know, theory of learning and teaching and stuff like that. Um, and then on the program, you know, direction and development side, um, we create programs that are designed to help our students. Uh, I'm in the high school department, so basically we're focused on, you know, success in high school. Um, we also do some social, emotional, learning. And then like, the key, the big one, is to get into college. So like, right now we're doing a program on, um, college applications and essays. And I'm not why I did get this when someone wasn't there and they needed someone to fill in. But I'm. I'm basically developing the program. I'm putting resources together, lesson plans, and then I'll meet with tutors once every two weeks just to kind of, uh, again, review videos, talk to them about what's going on.\n\nSpeaker B [8:12 - 8:18]: Oh, wow. Okay. And is this a private company that you work for or.\n\nSpeaker A [8:18 - 8:30]: Uh, yeah, it's a nonprofit. Um, it's a private company. They've been around for, uh, 35 years. I've been there for three years.\n\nSpeaker B [8:31 - 8:37]: Okay, what can, what's it called? I'm curious.\n\nSpeaker A [8:37 - 9:32]: It's called, uh, E.P.A.T. east Palo Alto Tutoring and Tennis. And their philosophy is that, um, just epat.org will show e P A T T. Um, their philosophy is that, um, you know, mental fitness and physical fitness are related. And in that area, there was a pro tennis player a while ago, um, made some money playing tennis. And then he created like an endowment, um, to help students. You know, uh, there's. There's a lot of, you know, um, unserved, uh, students there, um, like lower income communities. And he wanted to create this place for them to, you know, pursue education while, you know, and, and then incorporating the part of, of uh, just being socially active and playing a sport, you know, hanging out with other students.\n\nSpeaker B [9:35 - 9:45]: Yeah. Yeah. Okay, that's, that's coming back to me now. Yeah, that's cool. And the juxtaposition of East Palo Alto and Palo Alto proper.\n\nSpeaker A [9:45 - 10:18]: Yeah, and Palo Alto. Yeah. And so a lot of the, their parents are the ones that are, you know, working, uh, the, the worker, the service class to the Palo Alto group. And I mean, anytime you get a lot of, you know, hyper focused, um, you know, high income areas, you're going to have some low income, dense areas kind of thing where it's like a small area that, you know, is this able to service a lot of people that take care of more spread out area of money.\n\nSpeaker B [10:18 - 10:46]: Yeah, it makes sense. Like, and so do you find like that these students, um, you know, they obviously have like a range of challenges, but like, how would you, how would you, would you be able to prioritize them or say, like, they're mostly like cognitive or they like time management or a mix or emotional.\n\nSpeaker A [10:46 - 14:09]: Yeah, a lot of them just, they're not exposed to other ways of how the world works. You know, they're, they're just basically what they see as with most students. And um, a lot of what they see is just, you know, their parents in the service community. Like I, my first student I worked with, we did an exercise on, you know, how education is the path to anywhere that you want to go. You know, I say, here you are now, you know, you know where you are. You can look around, um, and imagine where you want to be. Imagine, you know, do you want a family? Where do you want to live? What kind of life do you want? And we're going to find a path from here to there through education and academia. And I said, okay, you know, what kind of, you know, if you could do anything, what would you do? And she was like, uh, I don't know. And he came up with, you know, I want to be landscaper. All right? And I was like, let's, let's try and get creative. Let's think of something crazy come back to me. And then when he came back, he's like, what about a baker? And it turns out that his mother was a baker and his father was a landscaper. And he couldn't even think of, of a different career to get into or something that he might want to try out. Um, they just, they don't have access to worldviews. Like, you know, uh, I feel like we do where it's like, oh, what about this. What about that? I think that we're also raised like, you can do anything you want, you can do this, you can do that. The way that they're raised, know, unfortunately, is what you have to do in order to survive. You know, we're like, hey, I can do anything I want, I can thrive. And you know, they're a high school student that ah, can't even go to school because they have to stay home and take care of their younger sister or brother, you know, because their parents have to go to work, uh, or they have to do homework late at night because they, they sleep on a couch. And there's multiple families in the home so they can't work in the daytime because there's a lot of families in the living room. Um, it's, it's these challenging situations that, you know, kind of force them to physically live some way. And then by doing that they're limiting their mental perspective on what they can do because they're used to being limited. You know, it's like, well, what can I do? You know, rather than thinking, um, what do I want to do? Is what can I do? And that's where I see or I, you know, experience that, that limitation. And so, um, you know, that's where we get to eventually is, is opening them up to like, you know, there's all these ways of living that, that ah, you can get to, um, but to increase the probability of you reaching that dream or that ideal life, um, it's, it's a lot more probable you'll get there if you start looking at it now, you know, like, uh, you can rent, you can end up. Which often happens in a situation that, oh, this is great, you know, but if you're going to wait on chance you can end up somewhere else too. Um, so if, if you want to be a doctor when you're a kid, it's a lot easier to get there than if you want to become a doctor when you're in college, you know.\n\nSpeaker B [14:11 - 14:16]: Yeah. And you're working mostly with high school age students now.\n\nSpeaker A [14:17 - 15:03]: So, um, sometimes I'll pick up like a junior high student and then this fall I'm going to do an elementary school student just to see what it's like. But, um, I, I've always worked, even before I was here, I've always worked with, you know, either college students or high school students, um, just because I can. The conversations I'm interested in are conversations like this, are conversations that involve potential. Um, they involve kind of this like, you know, bootstrap Mentality where it's like, how can I get somewhere or achieve something great with what I have on hand? Um, those are the conversations I like to have. And high school and you know, early college is a great place to have, have those conversations.\n\nSpeaker B [15:06 - 15:10]: Yeah, well, those are, that's where they're really forced to make these bigger decisions.\n\nSpeaker A [15:11 - 15:11]: Mhm.\n\nSpeaker B [15:12 - 15:14]: If they have those opportunities.\n\nSpeaker A [15:14 - 15:54]: Yeah, yeah, yeah. When I work with my junior high students, it's more about discipline and attention. You know, it's like, hey, sit down and we're going to work on this and we can't think about anything else. We got to think about this, uh, juxtaposed to high school where it's like, what I'm doing has to do with what I'm going to be doing and what I'm going to be doing has to do with where I want to be. So you have, you know, where you want to be. You know, you got to figure out what do I got to get to doing. And then to get there you got to say, what do I need to focus on now? So it's, you know, it becomes a little more complicated. M which requires more, more planning, um, you know, more sophistication.\n\nSpeaker B [15:54 - 15:55]: Yeah.\n\nSpeaker A [15:55 - 16:05]: You know, uh, that's when it requires a conversation. You know, when you're younger, it's more like you're instructed to do something, you know. So that's discipline.\n\nSpeaker B [16:05 - 16:18]: Yeah, yeah. Can you tell me a little bit more about how these students, um, you know, on the planning side that you just mentioned, how do they go about do that, doing that? What does that look like for them?\n\nSpeaker A [16:19 - 20:00]: Okay, so let's see. I, I, it's really a mentorship program. Um, so we uh, work with Stanford a lot. Um, we're usually looking for college students at Stanford to pair up with our high school students. And that's where I come in. I'll talk with the Stanford students, I'll see their experience, their interests. Um, I know all my high school students and I'll try and pair these people up in ways that, you know, uh, makes sense for where the student is interested in where their strengths and weaknesses are sense from like a cultural or like, uh, somewhere where the student's gonna have respect for that college student. Because in high school you get to this point where, um, you know, there's, there's two things. One is like, you think you know a lot or you think you know it all, you don't need help from someone else. But what I see more with our students is, um, they've become so accustomed to, um, not succeeding or like they've gotten F's in a class for so long or on assignments that they're very timid and they're afraid to ask for help either because they don't know what they need help in. It's just like I'm. I went to class, I was so confused. I don't even know what questions to ask or because they're similarly ashamed that the tutor's going to ask them a question that they don't know the answer to and they don't want to seem foolish. So you kind of have this balance of someone who is successful in a way the student's interested in, but also that the student can feel comfortable with. Um, ah. And connect with. Um, and then let's see the planning and then the exercises this the they're gonna do. That's where my program, um, you know, program comes into where it's like I'm, I'm creating either exercises for the tutor to do with the student. Like right now we have a worksheet where they're writing up any extracurricular activities, any experience interests, and then they're going to turn that into a resume. Um, and then they're going to work next week on uh, essay prompts. So just like practice essays for college applications. Um, and then when it's more in school, it's a lot about, it's about theory and stuff like that. Like, um, there's this thing we call like the 5050 rule where you want to try and get your student to speak as a much as you are, because the student is in a classroom, in classrooms all day getting lectured to. Um. And so a tutoring session shouldn't be about lecture. It should be more about conversation and, and practicing. Um, and so we try and get the, the students to talk as much as they can because since we have college tutors, usually they're pretty interested in the subjects that they're teaching. So they can just keep going and keep going and pour it out. But the student doesn't really need another lecture. They need someone that can meet them where they are. And this is where those metaphors come in a lot, you know, where the student has to talk about how they see things and then the tutor has to kind of put themselves in that, in that mindset and say, okay, how can I use um, words that they're familiar with or concepts they're familiar with to get them from where they are to where we need them to be?\n\nSpeaker B [20:02 - 20:25]: Yeah, no, that makes a lot of sense. That's where it comes into like the importance of the dialogue that you're talking about. So all this social, this social financial, like family unit stuff, um, is a big stage for backdrop for how you approaching and working with the students.\n\nSpeaker A [20:28 - 21:29]: Exactly. Yeah. And that, that often takes a meeting before it starts with me and, and the, the tutors just to talk about a few things so they understand where their student is coming from. Because um, they'll, I've seen them. Well, I've, I've lost a couple tutors walking into sessions and they're like, you know, I'm trying to work with my students but they're just, you know, not responsive. I feel like I'm wasting my time. And they leave and they don't understand, you know, that their student is, you know, he's been through a lot of, you know, like, you know, semi traumatic experiences of trying to do something really hard. And then it turns out that what he was doing wasn't what the requirement was. And so it just kind of really, um, you know, makes them kind of suppress their own uh, I don't know, enthusiasm to try and succeed or try and be creative with, with their um, schoolwork. Mhm.\n\nSpeaker B [21:32 - 21:34]: Got it. Okay.\n\nSpeaker A [21:34 - 23:38]: Yeah. And the, and the meeting students where they are part that the tutor has to do, that's something unique to tutoring. Um, and that's really how education started. You know, like the first school was, you know, I guess like Plato was, was doing stuff too, but you know, Aristotle was like the original tutor. And that's kind of how education used to be. It was like one person, um, teaching another person. They didn't have classrooms. And what's great about that is when you're, when you talk to someone, you know who they are. And humans have empathy so we can understand that person. And that's how communication works. If we didn't have empathy, I would just be spitting numbers and it would be computers talking to each other. You know, and if computers don't have a shared syntax or a shared language, they can't speak to each other. You know, the communication doesn't work. And we through empathy can create that syntax on the spot. You know, uh, we can come up with our own, you know, like lexicon or whatever it is and, and share information with each other. In school they basically have to like find the average, like this is how I can reach this perspective, is how I'm going to reach the most amount of students. Um, tutoring is, they've already got that, you know, generalized perspective. Now I have to see where they actually are and give them a specialized perspective. And usually a student going to tutoring didn't really pick up on that generalized perspective. We have a lot of like, um, iep, which is like, it's called individualized Education program, I think. And if they just, they need to learn something a certain way, you know, they, they just have a different way of acquiring information, uh, which was, you know, ah, a lot of my experience, you know, I, I failed through school until I, you know, got a little bit older and I realized that I had to find my own way to, to, you know, acquire knowledge in a useful way, you know.\n\nSpeaker B [23:38 - 23:39]: Yeah.\n\nSpeaker A [23:39 - 24:13]: Um, but I, I almost wonder how, how a tool could provide that individualized perspective, you know, because, um, I'm guessing, you know, the way that AI collects a lot of information and organizes it is based off how information is usually organized online, uh, or usually organized in textbooks or whatever. Whatever they collect from. So that's, that's just another idea of, you know, how can information be.\n\nSpeaker B [24:14 - 24:16]: Hey Jen, do you want me to put my headphones on?\n\nSpeaker A [24:16 - 24:35]: Or it's like, like you had the, the knowledge graph, you know, or there's the bullet points or there's index cards. So, um, all those different ways to organize and view the knowledge can definitely reach different students in more effective or less effective ways.\n\nSpeaker B [24:39 - 24:45]: Yes, yes indeed. I've actually, um, just time check. How much time do you have?\n\nSpeaker A [24:46 - 24:55]: Um, I've got about maybe 10 minutes. Okay, thanks for checking. Yeah, I wasn't watching. I start talking about this stuff and I'll get into it all day long.\n\nSpeaker B [24:55 - 25:01]: I know, I know. Um, let, let me do. Are you, you on your computer right now?\n\nSpeaker A [25:01 - 25:02]: Yeah. Yeah.\n\nSpeaker B [25:02 - 25:10]: Okay, let me, let me share a screen because I want to jump um, for it and we might not have enough time for this right now.\n\nSpeaker A [25:11 - 25:11]: Yeah.\n\nSpeaker B [25:11 - 25:34]: Um, but. Okay. Mhm.\n\nSpeaker A [25:54 - 26:39]: Mhm. Okay, I can see your screen. Ask anything.\n\nSpeaker B [26:39 - 27:29]: Okay, super. Um, and I don't think we'll be able to get through the whole thing right now, but this will probably take a little bit longer. But I feel like what the conversation is leading to and what we've come up with is a new set of concepts. Um, kind of like trying to get deeper into m. The more holistic situation of a student, not just here's some information. So let me walk you through this and what I'd like to do is show you a screen and then have you respond to it and say, okay, do you understand what it's asking you to do? Does it make sense? And we'll just kind of go through m that got it. And you just tell me when you're out of time and then maybe we can pick up again later some other time.\n\nSpeaker A [27:30 - 27:30]: All right, perfect.\n\nSpeaker B [27:30 - 27:35]: All right, so let's start with this screen.\n\nSpeaker A [27:40 - 27:43]: Um, you're, let's see, asking me to.\n\nSpeaker B [27:43 - 28:01]: Oh, okay, so there's two options, right? Like, it's like, this is like the onboarding part of. Okay, I want to learn something. I could either type in a question or I can upload some content. And there's two different ways to start.\n\nSpeaker A [28:02 - 29:06]: Yeah, that's, that's, that's how I saw it. I see it as, um, you know, almost. Yeah, yeah, I see it. Yeah. I walk up, ask, um, me something and then the. What would you like to learn? I think is actually kind of important here. I mean, if I was directed here by, by someone who had used this for a certain, like, they're like, hey, if you want to do that, do this, you know. But if I was exploring on my own, like, hey, like, what's a good tool for doing something? Blah, blah, blah. If I saw this without the what would you like to learn? I wouldn't be, I wouldn't think it's, it's so like, you know, based on like, you know, learning something versus like an Ask Jeeves type thing. Like, um, getting. Ah, so learning something versus like being directed somewhere. Like as there's asking for directions and then there's, you know, like, hey, how do I get to like Big Ben to talk in London? And then there's like, hey, what is big? Like what's the history behind it? So what would you like to learn? I think is actually pretty important.\n\nSpeaker B [29:06 - 29:09]: Okay, so maybe even elevate that over the asking.\n\nSpeaker A [29:10 - 29:22]: Oh yeah, that's a good, that is a, that's a good question. That's a good thought. Yeah. To put what would you like to learn? And then, you know, if you need the subtext like ask here or something like that, or that's kind of in your, uh.\n\nSpeaker B [29:23 - 29:45]: Interesting. Okay, super. All right. And then if you. I'll just explain this part. So this is a mock up right now. It doesn't entirely work, but if you were, if you had like course material or an, you know, a reading assignment or something, you could put it in here all and that would, and then the next, if you click next, you'd get to here.\n\nSpeaker A [29:53 - 30:40]: Yeah, this, this, this feels a lot, Yeah, I, I feel a lot more like what we're talking about, you know, what do you want to learn? Um, mhm. Okay, so I, I'm, I, I Feel like, what do you want to learn? I'm feeling a lot more the, the first picture because the, the learning goal. Um, I get, I feel a little confused on that. So let's see, like right now, um, I want to learn about, um, certain drawing techniques, you know, and I would look at this. Okay, what do I learn? I want to learn about a certain drawing technique. Um, and my goal would be. I just feel like there's something in between here.\n\nSpeaker B [30:41 - 30:41]: Yeah.\n\nSpeaker A [30:41 - 31:02]: Okay, what do I want to learn? And then your learning goal. I feel like this is where someone explains to you, hey, so what do you want to learn? I want to learn this. All right, so in order to learn, you got to create a goal or create this. Um, it's, this is tough because I also don't want too much here. Um, what do you want to learn to find your learning goal.\n\nSpeaker B [31:04 - 31:13]: So it's feeling a little vague, right? Like maybe some better examples. Like, maybe like be able to be able to write an essay about the.\n\nSpeaker A [31:13 - 32:08]: Topic or well, also if, if it's a lot less. Um, so right here it says, what do you want to learn? Once I read underneath. So again, I look at it, I just, I, I read the black text. What do you want to learn? Learning gold, your background. But then once I looked again at, ah, at the, um, the lighter text. What do you want to learn? Define your learning goal and we'll create a personalized learning path. Um, it's, you know, I, I, I would want to do some more looking at this, but it would, what do you want to learn? Um, something that explains that, um, you know, by creating a goal, that it's a lot easier to, to organize the information for you. Or the first part about learning is defining where you want to go. Um, uh, it seems more, more human.\n\nSpeaker B [32:09 - 32:09]: Yeah. Yeah.\n\nSpeaker A [32:11 - 32:19]: Hey, what do you want to learn? Oh, I want to learn how to water. You know, I want, I want to learn how to, to draw with pastel.\n\nSpeaker B [32:19 - 32:20]: That.\n\nSpeaker A [32:20 - 33:16]: Okay, well, the first step of learning is, you know, to create a goal or to, you know, what, what is that first step? Something like that. I think it's, yeah. So to start to get you there, let's set a goal, you know, and I be like, okay, so to get to drawing with pastels, I need a goal. I'd like to, you know, know, do a portrait. Ah, with pastels. Yeah. I, it's, and it depends on the environment. Like, if I'm doing this during a classroom exercise, uh, I feel like you're being walked through it. But if I'm Doing this on my own and I'm just using this tool. I feel like the, the, the smaller text could be a little more, um, helpful with understanding why I'm doing it or what I'm doing rather than in telling me what to do.\n\nSpeaker B [33:17 - 33:20]: Um, yeah, the why. The why.\n\nSpeaker A [33:20 - 33:21]: Yeah, the why. The why.\n\nSpeaker B [33:21 - 33:22]: Okay.\n\nSpeaker A [33:22 - 33:22]: Yeah.\n\nSpeaker B [33:24 - 33:25]: Okay, that's good. There's some good insight.\n\nSpeaker A [33:26 - 33:53]: Yeah. Because, because it starts like a conversation, right? It starts like, hey, what do you want to learn? And then it turns into direction and, and I don't know, I don't want to like jump too far, but it could be towards that whole like giving an instruction versus having someone meet you there, like a tutor. And since this is like a one to one thing, it's a person to a tool, maybe it should be a little more meeting you.\n\nSpeaker B [33:55 - 34:04]: Yes. Yeah, well, that, that's, that's definitely the sense we're trying to capture. Um, yeah, but okay, this is also.\n\nSpeaker A [34:04 - 34:55]: Very concise, which is good too, because, like, you don't want a paragraph of text saying like, you know, according to this theory of learning, it's better for you to create goals and we can go step by step. You definitely want to keep it short like this. And if this is the second time I'm using the tool, this is perfect. You know, so we also got to think about, are we, um, using this tool all the time? In which case this is perfectly designed for that. Probably because you're working on this all the time. Um, and then maybe the first time you go through it, there might be a tutorial or something like that that explains I, you know, by setting goals, this and that. So it, there's, there's a good argument for having a tutorial. I mean, yes, even the most simple apps have a tutorial. So, yeah, um, that's. If we're going to assume there's a tutorial. This is great.\n\nSpeaker B [34:56 - 35:00]: Okay, that is the, that is the, the goal to have a tutorial.\n\nSpeaker A [35:00 - 35:04]: Uh, yeah, so let's, let's work on, on the tutorial. Let's, let's work with that assumption.\n\nSpeaker B [35:04 - 35:04]: Yeah.\n\nSpeaker A [35:04 - 35:07]: And yeah, this is perfect. This is exactly super.\n\nSpeaker B [35:08 - 35:43]: And then we're asking for your background and I think we could probably reword this, but the, the goal is like, get these students to, and make some kind of a commitment, investment and say, well, I don't know much about water management, but, you know, uh, I know it comes, we get water from Colorado river or something somehow. Right? So now they, they have a starting point as opposed to like, so to your point earlier, they're starting to produce, you know, information instead of just consume it.\n\nSpeaker A [35:43 - 35:43]: Yeah.\n\nSpeaker B [35:44 - 35:44]: And then we can.\n\nSpeaker A [35:44 - 36:17]: And what really quick. What provides more value to. To your, you know, back end? Someone saying, like, um. Like, let's say I know a little bit about the water, like, where the water comes from. Or is it better to say, like, how does a city get its water from the state? Like, is it better for them to ask small questions here? Like, if the big question or the big idea is learning goal, does the background part. Do they want to know small questions or they want to know, uh, small facts?\n\nSpeaker B [36:19 - 36:46]: I think for the background, I was intending it to be small facts so that we could say, okay, great, since you know, about the Colorado river, you know, let's start with that to get them invested, maybe, um, as a touch point to find some commonality so they're not immediately getting overwhelmed with a whole bunch of new stuff. But like, a little bit of. Here's what you know. And let's tell you something in addition to that.\n\nSpeaker A [36:46 - 37:07]: Um, that's. That's what I get out of this. I get small facts. That's. That's the. And your background is actually, it's, you know, I can't think of two words that are. That are better right now. Like, okay, yeah, even what do you know? Doesn't. That sounds like I'm writing a paper. Your background sounds pretty like. I. I see the. The desire for something more accurate, but it's pretty good.\n\nSpeaker B [37:08 - 37:17]: Okay. Yeah. We. And we can. And all this is like, up for debate and change and all that. Like, I'm not invested.\n\nSpeaker A [37:17 - 38:54]: I'll keep. And I'll keep thinking too. Yeah. So, uh, I see. Yeah. I, I think of this almost like, um, how much information do I want to get and how complicated is it going to be? I guess how complicated is it going to be is kind of, uh. The first thing that was the first thought and the second thought was how much. So if I just want something quick and something easy, it would. It would be inner. Uh, it'd be introductory. Introductory. But if I wanted a little more information, like, you know, um, I'm not an expert on the water, but let's say like, um, waves. Uh, introductory level would say like, storms create waves that, you know, wind that blows waves to shore. Intermediate would say, um, you know, something like changes in temperature, uh, create weather, which blows waves to shore. And then as you get further up, it would be like, you know, sun sends energy to the earth that heats up different areas at different rates. And that change and the difference between those changes in temperature creates storms and weather, which then creates waves. So I, I see it not just as a complexity but also as an amount thing. So I don't know if those are separate or if that's kind of put together here.\n\nSpeaker B [38:54 - 39:13]: Interesting. Um, this was a little bit more, uh, I think what you're addressing is what's on the next page. Um, but this is, um, more. You see these levels down here? These are actually correlating to the Bloom taxonomy levels.\n\nSpeaker A [39:13 - 39:14]: Okay.\n\nSpeaker B [39:14 - 39:15]: And so that was.\n\nSpeaker A [39:16 - 39:21]: Oh, that's nice. Yeah, I didn't, I didn't see you clicking through that. The. Yeah, apply, analyze that.\n\nSpeaker B [39:22 - 40:59]: So that, that's what I had started with. Um, and so let me jump to the next page because I'm trying to figure out the best way to organize this. Um, and so here it gets a little bit, this gets a little more complicated. Right. Um, which might be overwhelming for students, but now we get into a phase of like, tell me, um, how much of this do you want to get into? And so this might be an alternate way of dealing with it. What I was thinking is the user could look, uh, at this and maybe draw a circle around how much. Or they could say, all right, they could add a plus. They could say, give me more on this area, less on this. Maybe even kind of prune a tree, if you will, of content to direct, uh, the AI on the topics it wants to cover. Mhm. The idea is maybe you would interact with this tree. You could add topics here and maybe remove some m. You know, so that was kind of like the idea and it would show you. Okay, well this is pretty focused on one side of the knowledge or it's pretty balanced. And I'm not even sure that's super. Uh, this bottom part is something the student need, average student needs to see. Um, so it's all very exploratory.\n\nSpeaker A [41:01 - 44:06]: Yeah, this, that's interesting because. And, and this is tough because I have a bias. I, um, I don't know where I, I from, what I remember. So like I have a really strong bias against like network graphs and node structures. Um, and, and I spent a lot of time with them because, um, when I study cognitive science, it's a lot of, you know, network information. Um, the mind as an embedded system and machine learning is really big on these. And I, um, think still now, but for you know, the early, like 2010 to 2020, there was a lot of products like this too. You know, creating your notes into nodes like this. And I think from someone who thinks like a systems Perspective like me. And I'm guessing you node graphs are great. Like I, you know, I was the same way. Oh, so cool. But, um, in, in, um. I don't know if this is like, studies or what. It just seems like it hasn't really hit like there was that node, um, or graph note app for a while that was. I was taking off and it just seems like a lot of these kind of flare out. Um, and when I look at this, as soon as. And here's the thing, it required you to click on those things. I love the bottom piece, but what I love about it is how it changes. I love that when you're adding or subtracting from it that it's giving me. Ah, yeah, an adapting summary. I really, really like that. And I can't think of another way to add or subtract without that graph, you know, so it's, it's tough. Like, um, you know, and maybe, maybe having a graph as an interface rather than as the organizational piece, you know, because, like, um, we had like tools where there's like note cards in place of all of those nodes. Right. And it takes up a lot of space for the amount of information that it holds versus, like a bullet chart. Bullet chart. I love bullet charts. Like, it's just like, like look at how people write their notes by hand. Anyways. People do bullets. Boom, boom, boom, boom. People on computers, we love to put them in these, these graphs. But when we do it by hand, we're usually doing that. I know there's like brainstorming, and I think that's where a lot of this kind of like, how do I get a brainstorm and put it on a computer? Um, um, but. And I see this bottom piece kind of like that bullet point. You know, it's like, let's look at the depths. Boom, boom, boom. You know, let's look at the topics. Boom, boom, boom. Let's look at how balanced it is and what the learning style is. Like. I, that is how I want to read information. So that's great. How I want to interact with the information. Um, yeah, like I said, I can't think of a better way than the node one, but I am a little, um, I have, I just have a personal issue, I guess, with, with uh, information graphs and, and, or like node graphs like that. But I've never used them as an interface. So, um, I, I would want to play with this.\n\nSpeaker B [44:06 - 44:06]: Yeah.\n\nSpeaker A [44:06 - 44:10]: So, you know, in a couple weeks, you know, when you're back, I want to touch this.\n\nSpeaker B [44:11 - 44:11]: Okay.\n\nSpeaker A [44:12 - 44:36]: Um, and yeah, it's it's hard for me to think too deeply into it, but um, it makes sense once you touch it, you know, and I'm sure once you know about it. I, um, do wonder how you would know what these topics are. You know, if I'm, if I'm reading this on my, my laptop, like I guess you'd have to put just like a one word description for, for each of these nodes or.\n\nSpeaker B [44:37 - 44:47]: Yeah. The way. So this isn't perfect representation of like we instead of circles. So just the prototyping tool I'm using, it came up with circles. But what.\n\nSpeaker A [44:47 - 44:49]: I've got like two minutes.\n\nSpeaker B [44:49 - 44:50]: Okay.\n\nSpeaker A [44:50 - 44:53]: So if you want to keep talking about this, let me know.\n\nSpeaker B [44:53 - 45:04]: Yeah, let me just, uh. There's one. Yeah. It would look different than this. It would look different than this where there'd be like two to three words and it's ah, more of a box.\n\nSpeaker A [45:05 - 45:11]: But we'll have to create like a more accurate representation or a more accurate situation.\n\nSpeaker B [45:12 - 45:21]: Exactly. Yeah. Yeah. This is, this is total mock up. But after that the final step is you go, okay, now pick the mode you want to interact with the tool.\n\nSpeaker A [45:23 - 46:12]: Yeah, just, just looking at the left column, mode. Exam prep, mentor chart, think tank, Creative Explorer. I love it. You know that, that makes me feel like right away I look at this and go, wow, I'm saving so much time. Like, and that's what students are trying to do, right? That's what anyone's trying to do is what, you know, um, you know, manage my most, uh, sacred resource of time. Like, wow, great. Boom, boom, boom. And it also feels personal. You know, that's the one on one. And, and I'm gonna, I think I'm just gonna to champion that perspective. You know, the tutor's role like this. I'm gonna think of this tool not as a teacher, but as a tutor. You know, someone who's going to reach you where you are and build that bridge to where you want to go. Um, so I re. I love the left column. I'm gonna look at those.\n\nSpeaker B [46:12 - 46:54]: Super. And just the last thing I'll show you and we can come back and talk about it later. Um, is that, that was the. Tell me what you want to achieve and we'll create. Now what's happening is the system's going to create a learning plan and you're going to. And now you're in the interface for the app and we can kind of go through this at another time because I know you got to run, but you would actually jump into the learning here and Go through things and you'd have a chance to discuss, um, and then you could practice with quizzes. But this is where the learning would happen. And we'd show you the learning plan here of. Here's the things you need to do to get through here.\n\nSpeaker A [46:55 - 47:15]: Um, so I. I also want to play with the idea of putting that, um. Um, you know, um, what is it? Like exam test prep? Like, what. What are you trying to do with this towards the beginning, you know, even before. What do you want to learn?\n\nSpeaker B [47:15 - 47:16]: Yeah, I.\n\nSpeaker A [47:16 - 47:58]: Or at least next to it. Um, it's. It's an interesting thought that I think. I think the difference on putting that somewhere, uh, comes into, uh, in the enthusiasm level. Um, just because, like, when I saw it, I'm like, wow, this is cool. If that was, you know, the first thing that I saw that, whoa, this is great. Let me use this tool versus, like, what do you want to learn? Um, you know, like I said, there's. What do you want to learn? There's Google, you know, there's, uh, Wikipedia. There's all these things I can type in something. You haven't really set yourself apart, you know, at least from my eyes. My eyes don't notice difference.\n\nSpeaker B [47:58 - 47:59]: Difference.\n\nSpeaker A [48:00 - 48:09]: Um, but when I see that exam, whatever, all these different things, my eyes are seeing something. They're seeing a tool that they haven't seen before.\n\nSpeaker B [48:10 - 48:12]: Uh, that's good point.\n\nSpeaker A [48:13 - 48:45]: Yeah. It's like, if we were going to test that out, the question would be, how much more excited are you to use this tool? You know, how much more interested are you in this tool based on these two different ways of starting it, rather than like, which one do you think is going to get you where you want to go? I think the question is how much more interested in using the tool are you? Because that's what that's going to manipulate. True M. All right, well, I gotta. I gotta get to church.\n\nSpeaker B [48:45 - 48:46]: Yeah.\n\nSpeaker A [48:46 - 48:50]: Really cool talking to you. Uh, we can. We can just keep talking more and more.\n\nSpeaker B [48:50 - 48:51]: Yeah, let's do it.\n\nSpeaker A [48:52 - 49:29]: Um, I'll keep thinking about it, especially this summer. It's pretty interesting because I'm, you know, working with these tutors on trying to get students so it's not so much like, hey, I need help with this homework assignment. It's like, hey, how can I get you to, um, do like, some bigger stuff, you know, working on college essay prompts, um, know, exploring ideas and, you know, ultimately, you know, building a life of, uh, fulfillment. You know, that's. That's kind of my thing is how do I build a fulfilling life for the students or how do I help them? Give them the tools they need.\n\nSpeaker B [49:29 - 49:31]: Awesome. All right, Jed, I'll let you run.\n\nSpeaker A [49:32 - 49:32]: All right?\n\nSpeaker B [49:33 - 49:36]: Okay. Take care. Thank you.\n\n    \"#\n  }\n}\n",
  "extract_persona.baml": "class Persona1 {\n  // Demographics\n  name string @description(\"Persona name: up to 3 words\")\n  description string | null @description(\"Persona Archetype description: 3-7 sentences summarizing behavior, pain, motivations, and preferences\")\n  age string | null @description(\"Most common age or age range, e.g. '25-34'\")\n  gender string | null @description(\"Most common gender for this persona\")\n  location string | null @description(\"Most common location(s) for this persona\")\n  education string | null @description(\"Most common education level(s)\")\n  occupation string | null @description(\"Most common occupation(s)\")\n  income string | null @description(\"Most common income range or level\")\n  languages string | null @description(\"Most common languages spoken\")\n  segment string | null @description(\"Segment or group this persona belongs to\")\n  role string | null @description(\"Role or job title\")\n  color_hex string | null @description(\"Hex color for persona visualization\")\n  image_url string | null @description(\"URL to persona avatar/profile image\")\n\n  // Psychographics\n  motivations string[] | null @description(\"Key motivations for this persona\")\n  values string[] | null @description(\"Core values for this persona\")\n  frustrations string[] | null @description(\"Top frustrations or pain points\")\n  preferences string | null @description(\"Notable preferences\")\n  learning_style string | null @description(\"Preferred learning style\")\n  tech_comfort_level string | null @description(\"Comfort level with technology\")\n\n  // Behavior\n  frequency_of_purchase string | null @description(\"How often this persona purchases relevant products/services\")\n  frequency_of_use string | null @description(\"How often this persona uses relevant products/services\")\n  key_tasks string[] | null @description(\"Key tasks this persona performs\")\n  tools_used string[] | null @description(\"Tools or products commonly used by this persona\")\n  primary_goal string | null @description(\"Primary goal for this persona\")\n  secondary_goals string[] | null @description(\"Secondary goals for this persona\")\n  sources string[] | null @description(\"Main sources of information or influence\")\n  quotes string[] | null @description(\"Representative quotes from this persona\")\n  percentage float | null @description(\"Estimated percentage of users represented by this persona\")\n}\n\n// baml_src/personas.baml\n// Rolling persona refinement with single‑interview safeguards\n\nclass Persona {\n  // === IDENTITY & CORE ===\n  name string @description(\"Persona name: up to 4 words. Plain, memorable, captures essence. Example: The Reluctant Power User, Last-minute shopper\")\n  name_and_tagline string @description(\"2–4 words + optional quoted tagline. Plain, memorable, captures essence. Example: The Reluctant Power User — 'Wants outcomes, hates setup'.\")\n  description string | null @description(\"Persona Archetype description: 3-7 sentences summarizing behavior, pain, motivations, and preferences\")\n  role_context string @description(\"Role/life stage/situation as it relates to the product problem. Example: 'HS junior juggling AP classes' or 'Ops lead at 20‑person startup'.\")\n\n  // === DEMOGRAPHICS ===\n  age string | null @description(\"Most common age or age range, e.g. '25-34'\")\n  gender string | null @description(\"Most common gender for this persona\")\n  location string | null @description(\"Most common location(s) for this persona\")\n  education string | null @description(\"Most common education level(s)\")\n  occupation string | null @description(\"Most common occupation(s)\")\n  income string | null @description(\"Most common income range or level\")\n  languages string | null @description(\"Most common languages spoken\")\n  segment string | null @description(\"Segment or group this persona belongs to\")\n  role string | null @description(\"Role or job title\")\n\n  // === VISUAL IDENTITY ===\n  color_hex string | null @description(\"Hex color for persona visualization\")\n  image_url string | null @description(\"URL to persona avatar/profile image\")\n  percentage float | null @description(\"Estimated percentage of users represented by this persona\")\n\n  // === GOALS & MOTIVATIONS ===\n  goals string[] @description(\"3–5 user outcomes (not features). Example: 'Finish assignments faster'; 'Reduce rework'.\")\n  primary_goal string | null @description(\"Primary goal for this persona\")\n  secondary_goals string[] | null @description(\"Secondary goals for this persona\")\n  motivations string[] | null @description(\"Key motivations for this persona\")\n  values string[] | null @description(\"Core values for this persona\")\n  success_definition string @description(\"Crisp success statement in this domain. Example: 'Submits work a day early without anxiety'.\")\n\n  // === BEHAVIORS & PATTERNS ===\n  behaviors_habits string[] @description(\"Observable patterns (work/learn/decide/communicate) + tools/channels/frequency. Keep concrete & falsifiable. Example: 'Checks app daily; prefers SMS'.\")\n  key_tasks string[] | null @description(\"Key tasks this persona performs\")\n  tools_used string[] | null @description(\"Tools or products commonly used by this persona\")\n  frequency_of_purchase string | null @description(\"How often this persona purchases relevant products/services\")\n  frequency_of_use string | null @description(\"How often this persona uses relevant products/services\")\n  triggers_decision_drivers string[] @description(\"What causes action + how choices are made. Example: 'Deadline pressure; peer proof'.\")\n\n  // === PAIN POINTS & CHALLENGES ===\n  pain_points string[] @description(\"Top 3–5 blockers or unmet needs that are actionable for product/design. Example: 'Lack of visibility'; 'Difficulty with setup'.\")\n  frustrations string[] | null @description(\"Top frustrations or pain points\")\n\n  // === PREFERENCES & STYLE ===\n  preferences string | null @description(\"Notable preferences\")\n  learning_style string | null @description(\"Preferred learning style\")\n  tech_comfort_level string | null @description(\"Comfort level with technology\")\n\n  // === EVIDENCE & INSIGHTS ===\n  key_quotes string[] @description(\"1–3 verbatim interview quotes (lightly cleaned). Real language only.\")\n  sources string[] | null @description(\"Main sources of information or influence\")\n  differentiators string[]\n    @description(\"≥3 concrete, behavior/motivation‑based ways this persona differs from others.\")\n    @assert(min_three_diffs, {{ this|length >= 3 }})\n\n  // === RESEARCH METADATA ===\n  confidence string @description(\"Overall confidence: use one of 'Low', 'Medium', 'High'. If evidence_count < 2, MUST be 'Low'.\")\n  evidence_count int @description(\"Distinct interviews supporting this persona. Usually 1 in single‑interview mode.\")\n  hypothesis_notes string @description(\"Brief, falsifiable assumptions awaiting validation. Do not restate facts.\")\n  key_open_questions string[] @description(\"3–5 questions that would confirm/refute this persona in the next interview.\")\n}\n\nclass PersonaSet {\n  personas Persona[]\n    @description(\"Prefer 3–5 active personas; never exceed 5 without explicit authorization.\")\n    @assert(cap_5, {{ this|length <= 5 }})\n\n  version string @description(\"Version vX.Y: X=merges/splits/framework changes; Y=incremental tweaks.\")\n\n  change_log string @description(\"What changed & why: added/removed/merged personas; major field edits; cite evidence counts (e.g., '≥2 interviews').\")\n\n  // When any persona has evidence_count < 2, produce a single contrast persona to probe next.\n  contrast_persona Persona? @description(\"A deliberately different, testable counter‑hypothesis at the opposite end of the salient spectrum. Required if any persona has evidence_count < 2.\")\n}\n\n\n//// Pass 0 — Ingest & Normalize\n\nclass NoteSnippet {\n  tag string @description(\"One of: FACT | QUOTE | GOAL | PAIN | BEHAVIOR | TRIGGER | SUCCESS | IRRELEVANT\")\n  text string @description(\"Cleaned snippet text; QUOTE must be verbatim with minor fixes only.\")\n  speaker string? @description(\"Optional speaker label (e.g., 'User', 'Interviewer', name).\")\n  timestamp string? @description(\"Optional timestamp from source, e.g., '00:13:21'.\")\n}\n\nclass InterviewDoc {\n  source string @description(\"Brief identifier for the interview (file, session id, or date).\")\n  snippets NoteSnippet[] @description(\"Structured, de‑duplicated snippets. Exclude pleasantries and off‑topic content.\")\n}\n\nfunction NormalizeNotes(raw_notes: string) -> InterviewDoc {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Normalize raw interview notes into labeled, concise snippets for UX research.\n\n    Rules:\n    - Keep only domain-relevant content.\n    - Label each snippet with one of: FACT | QUOTE | GOAL | PAIN | BEHAVIOR | TRIGGER | SUCCESS | IRRELEVANT.\n    - QUOTE must be verbatim (light punctuation/grammar fixes allowed).\n    - Merge duplicates; prefer the strongest phrasing.\n    - Preserve any timestamps/speakers if present in the text.\n    - Exclude IRRELEVANT snippets from the final output.\n\n    {{ _.role(\"user\") }}\n    RAW_NOTES:\n    {{ raw_notes }}\n\n    Produce {{ ctx.output_format }} with snippets excluding IRRELEVANT.\n  \"#\n}\n\n//// Pass 1 — Evidence Extract (no synthesis)\n\nclass EvidenceSet {\n  facts string[] @description(\"Objective observations derived from FACT and BEHAVIOR.\")\n  goals string[] @description(\"User outcomes from GOAL only; no features.\")\n  pains string[] @description(\"Actionable problems from PAIN.\")\n  behaviors string[] @description(\"Observable patterns/tools/frequency from BEHAVIOR.\")\n  triggers string[] @description(\"Action triggers + choice drivers from TRIGGER.\")\n  success string[] @description(\"Definitions of success from SUCCESS.\")\n  quotes string[] @description(\"1–5 verbatim quotes representative of the above.\")\n}\n\nfunction ExtractEvidence(doc: InterviewDoc) -> EvidenceSet {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Extract only verifiable evidence from a normalized interview doc.\n    Do NOT invent or generalize beyond provided snippets.\n\n    Rules:\n    - Each output item must map to one or more input snippets.\n    - Use QUOTE text verbatim (light cleanup allowed).\n    - Ignore demographics unless causally tied to use/decisions.\n    - Prefer fewer, stronger items over many weak ones.\n\n    {{ _.role(\"user\") }}\n    INTERVIEW_DOC:\n    {{ doc }}\n\n    Return {{ ctx.output_format }}.\n  \"#\n}\n\n//// Pass 2 — Spectrum Detection\n\nclass Spectrum {\n  axis string @description(\"Primary axis of variation to test next, formatted as 'X ↔ Y', e.g., 'Autonomy ↔ Guidance'.\")\n  rationale string @description(\"Why this axis matters for product decisions (onboarding, content, help, messaging).\")\n  supporting_evidence string[] @description(\"Bullets referencing facts/quotes that point to this axis.\")\n  alternatives string[] @description(\"Up to 2 runner-up axes considered (same 'X ↔ Y' format) with a 1‑line reason each.\")\n}\n\nfunction FindSpectrum(evidence: EvidenceSet) -> Spectrum {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Select the strongest behavioral/motivational spectrum to anchor a contrast persona.\n\n    Candidate axes (examples; choose the most decision-impacting):\n    - Autonomy ↔ Guidance\n    - Planner ↔ Sprinter\n    - Depth ↔ Speed\n    - Social proof ↔ Solo\n    - Exploration ↔ Checklists\n\n    Rules:\n    - Pick ONE primary axis that most changes the product/design choices now.\n    - Provide concise rationale and cite the most relevant evidence items.\n    - List up to 2 alternatives only if close contenders.\n\n    {{ _.role(\"user\") }}\n    EVIDENCE_SET:\n    {{ evidence }}\n\n    Return {{ ctx.output_format }} with a single primary axis.\n  \"#\n}\n\n//// Pass 3 — Draft Provisional Persona (N=1 discipline)\n\nfunction DraftProvisionalPersona(evidence: EvidenceSet, spectrum: Spectrum) -> Persona {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Draft a provisional persona from evidence only (no invention).\n    Single‑interview discipline: confidence must be \"Low\" and evidence_count = 1.\n\n    Rules:\n    - Populate fields ONLY with content grounded in the EvidenceSet (facts, goals, pains, behaviors, triggers, success, quotes).\n    - Use 1–3 verbatim quotes (light cleanup allowed). If none fit, leave key_quotes empty.\n    - Provide ≥3 differentiators (behavior/motivation‑based), tied to the chosen spectrum: {{ spectrum.axis }}.\n    - Do NOT include demographics unless causally relevant to use/decisions.\n    - Fill hypothesis_notes with crisp, falsifiable assumptions (what you would expect to hold if this persona is real).\n    - Provide 3–5 key_open_questions that will confirm/refute this persona next interview.\n    - Set confidence = \"Low\" and evidence_count = 1.\n\n    {{ _.role(\"user\") }}\n    EVIDENCE_SET:\n    {{ evidence }}\n\n    PRIMARY_SPECTRUM:\n    {{ spectrum }}\n\n    Produce {{ ctx.output_format }}.\n  \"#\n}\n\n//// Pass 4 — Draft Contrast Persona (counter‑hypothesis at opposite spectrum end)\n\nfunction DraftContrastPersona(provisional: Persona, spectrum: Spectrum) -> Persona {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Create ONE contrast persona positioned at the opposite end of the primary spectrum.\n    This is a counter‑hypothesis used to disambiguate in the next interview.\n\n    Rules:\n    - Place this persona at the OPPOSITE end of {{ spectrum.axis }} relative to the provisional persona.\n    - Provide ≥3 differentiators that DO NOT overlap with the provisional’s differentiators.\n    - Keep it lean: include only fields necessary to design a test (but return a valid Persona object).\n    - Do NOT invent quotes; key_quotes can be empty.\n    - Set confidence = \"Low\" and evidence_count = 1.\n    - key_open_questions should focus on disambiguating THIS contrast from the provisional.\n\n    {{ _.role(\"user\") }}\n    PROVISIONAL_PERSONA:\n    {{ provisional }}\n\n    PRIMARY_SPECTRUM:\n    {{ spectrum }}\n\n    Produce {{ ctx.output_format }}.\n  \"#\n}\n\n\nfunction RefinePersonas(existing_persona_set: PersonaSet, new_interview_notes: string) -> PersonaSet {\n  client \"openai/gpt-5-mini\"\n\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a UX researcher updating a living persona set from new interview notes.\n    Return ONLY a valid PersonaSet JSON per the schema; no extra commentary.\n\n    Hard rules:\n    1) Evidence threshold: Add/change traits only if supported by ≥2 independent interview findings.\n    2) Max differentiation: Each persona must include ≥3 behavior/motivation differentiators.\n    3) Merge overlap: If two personas share >70% core needs/motivations, MERGE and keep strongest diffs.\n    4) Count cap: Keep ≤5 personas unless explicitly authorized.\n    5) Spectrum strategy: When patterns form a continuum (e.g., DIY ↔ Guided), place personas at distinct ends; add one middle only if necessary.\n    6) Demographics: Include only when they causally affect use/decisions; otherwise omit.\n    7) Actionability filter: Omit details that won’t change product, design, or messaging decisions.\n    8) Versioning: Bump version (vX.Y). Major bump (X) for merges/splits/framework changes; minor bump (Y) for incremental tweaks.\n    9) Change log: Summarize additions/removals/merges and key edits with brief evidence references (e.g., “3/5 interviews mention …”).\n\n    Single‑interview mode:\n    - If any resulting persona has evidence_count < 2:\n      * Set confidence=\"Low\" for that persona.\n      * Provide exactly one contrast_persona at the opposite end of the primary behavioral/motivational spectrum.\n      * Populate hypothesis_notes with crisp, falsifiable assumptions.\n      * Provide 3–5 key_open_questions to disambiguate in the next interview.\n      * Prefer leaving fields empty over guessing beyond notes/first‑party telemetry.\n\n    {{ _.role(\"user\") }}\n    CURRENT_SET:\n    {{ existing_persona_set }}\n\n    NEW_INTERVIEW_NOTES:\n    {{ new_interview_notes }}\n\n    Produce the updated persona set strictly as per the schema below.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\nfunction ExtractPersona(people: string, insights: string, interviews: string, evidence: string) -> Persona {\n  client \"CustomGPT5Mini\"\n  prompt #\"\n    You are an expert UX researcher. Given the following people records and their insights, generate a detailed persona profile.\n\n    1. Create a UX persona that represents the people records and insights.\n       - Use up to 3 words for a catchy name.\n       - Write a 3-7 sentence description summarizing behavior, pain, motivations, and preferences.\n    2. For each of the following fields, aggregate and summarize the most common or representative value(s) from the data:\n       - age, gender, location, education, occupation, income, languages, segment, role, color_hex, image_url\n       - motivations, values, frustrations, preferences, learning_style, tech_comfort_level\n       - frequency_of_purchase, frequency_of_use, key_tasks, tools_used, primary_goal, secondary_goals, sources, quotes, percentage\n    3. For array fields, provide 2-5 representative items. For string fields, provide the most common or relevant value.\n    4. Use direct quotes from the data where possible for the 'quotes' field.\n    5. If a field is not present in the data, return null.\n\n\t\tInterview records:\n\t\t{{ interviews }}\n\n\t\tEvidence records:\n\t\t{{ evidence }}\n\n    People records:\n    {{ people }}\n\n    Insights:\n    {{ insights }}\n\n\t  Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GeneratePersonas(interviews: string | null, people: string | null, insights: string | null, evidence: string | null) -> Persona[] {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    You are an expert UX researcher and strategist. Below are a mixture of transcribed conversations, interviews, notes, and insights.\n\t\tYour task is to generate 4 personas based on the data.\n\n\t\t1. Find each distinct persona in the data, summarizing each as a Persona object in a descriptive manner to help us identify other people like them.\n    - For each persona, fill out all fields in the Persona schema, using the most representative or common values.\n    - For array fields, provide 2-5 representative items. For string fields, provide the most common or relevant value.\n    - Use direct quotes from the data where possible for the 'quotes' field.\n    - If a field is not present in the data, return null.\n\n    2. Generate a up to 3 additional personas that are not present but would be expected in this context, based on gaps or patterns in the data. Mark these as 'projected' in the description.\n\n\t\tDo not group people into personas that are too different from each other.\n\n\t\tDO Not generate personas that are too similar to each other.\n\n\t\tInterview records:\n\t\t{{ interviews }}\n\n\t\tEvidence records:\n\t\t{{ evidence }}\n\n    People records:\n    {{ people }}\n\n    Insights:\n    {{ insights }}\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// New intelligent persona assignment decision\nclass PersonaAssignmentDecision {\n  action string @description(\"Either 'assign_existing' or 'create_new'\")\n  persona_id string | null @description(\"ID of existing persona if action is 'assign_existing', null if creating new\")\n  persona_name string | null @description(\"Name of existing persona if assigning, or proposed name for new persona\")\n  confidence_score float @description(\"Confidence in this decision from 0.0 to 1.0\")\n  reasoning string @description(\"Detailed explanation of why this decision was made\")\n  new_persona_data Persona | null @description(\"Complete persona data if action is 'create_new', null otherwise\")\n}\n\nfunction AssignPersonaToInterview(\n  interview_transcript: string,\n  participant_info: string,\n  existing_personas: string\n) -> PersonaAssignmentDecision {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    You are an expert UX researcher tasked with intelligently assigning an interview participant to either an existing persona or creating a new one.\n\n    DECISION CRITERIA:\n    1. ASSIGN TO EXISTING if the participant shows >70% alignment with an existing persona in:\n       - Core motivations and goals\n       - Key behaviors and patterns\n       - Primary pain points and frustrations\n       - Decision-making triggers\n       - Tech comfort level and preferences\n\n    2. CREATE NEW if the participant represents a distinct archetype that:\n       - Has fundamentally different motivations or goals\n       - Shows unique behavioral patterns not captured by existing personas\n       - Has different pain points or success definitions\n       - Represents a new segment or user type\n\n    ANALYSIS PROCESS:\n    1. Extract key characteristics from the interview transcript and participant info\n    2. Compare against each existing persona systematically\n    3. Calculate alignment percentage for each existing persona\n    4. If highest alignment is >70%, assign to that persona\n    5. If all alignments are <70%, create a new persona\n\n    INTERVIEW TRANSCRIPT:\n    {{ interview_transcript }}\n\n    PARTICIPANT INFO:\n    {{ participant_info }}\n\n    EXISTING PERSONAS:\n    {{ existing_personas }}\n\n    Return a PersonaAssignmentDecision with:\n    - Clear action (assign_existing or create_new)\n    - Persona ID/name if assigning to existing\n    - Confidence score (0.0-1.0)\n    - Detailed reasoning for the decision\n    - Complete new persona data if creating new (following the Persona schema)\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.207.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "goal_lens_extraction.baml": "// Goal-Oriented Lens Extraction\n//\n// Answers specific research goals, decision questions, and unknowns defined in project setup\n\n// ============================================================================\n// Core Goal Classes\n// ============================================================================\n\nclass GoalAnswer {\n  goal_statement string @description(\"The original research goal or question\")\n  answer_summary string @description(\"Direct answer to this goal/question\")\n  confidence string @description(\"Confidence: 'high', 'medium', 'low', 'inconclusive'\")\n  supporting_findings string[] @description(\"Key findings that support this answer\")\n  counterpoints string[] @description(\"Any evidence that contradicts or qualifies the answer\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this answer\")\n}\n\nclass DecisionInsight {\n  decision_question string @description(\"The decision question from project setup\")\n  recommendation string @description(\"Recommended decision based on interview evidence\")\n  rationale string @description(\"Why this recommendation based on evidence\")\n  risks string[] @description(\"Risks or caveats to consider\")\n  confidence string @description(\"Confidence: 'high', 'medium', 'low'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this recommendation\")\n}\n\nclass UnknownResolution {\n  unknown_statement string @description(\"The unknown or uncertainty from project setup\")\n  status string @description(\"Status: 'resolved', 'partially_resolved', 'still_unknown'\")\n  findings string? @description(\"What we learned about this unknown\")\n  remaining_uncertainty string? @description(\"What's still unclear\")\n  suggested_follow_up string? @description(\"How to further explore this\")\n  evidence_ids string[] @description(\"IDs of evidence related to this unknown\")\n}\n\nclass TargetFitAssessment {\n  criterion_type string @description(\"Type: 'org' for organization, 'role' for role/title\")\n  criterion_value string @description(\"The specific org type or role from target criteria\")\n  fit_assessment string @description(\"Fit: 'strong_fit', 'moderate_fit', 'weak_fit', 'not_fit'\")\n  reasoning string @description(\"Why this is/isn't a good fit based on interview\")\n  signals string[] @description(\"Specific signals that indicate fit or lack thereof\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this assessment\")\n}\n\nclass ResearchLearning {\n  learning_statement string @description(\"What we learned from this interview\")\n  relevance_to_goals string @description(\"How this relates to research goals\")\n  actionability string @description(\"What action this suggests\")\n  priority string @description(\"Priority: 'high', 'medium', 'low'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this learning\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass GoalLensExtraction {\n  goal_answers GoalAnswer[] @description(\"Answers to research goals\")\n  decision_insights DecisionInsight[] @description(\"Insights for decision questions\")\n  unknown_resolutions UnknownResolution[] @description(\"Resolution of unknowns/uncertainties\")\n  target_fit TargetFitAssessment[] @description(\"Assessment of fit with target orgs/roles\")\n  research_learnings ResearchLearning[] @description(\"Key learnings relevant to goals\")\n  goal_completion_score float @description(\"Overall score: how well did this interview address goals? (0.0 to 1.0)\")\n  recommended_follow_ups string[] @description(\"Follow-up questions or interviews recommended\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractGoalLens(\n  evidence_json: string,\n  interview_context: string,\n  project_goals: string,\n  decision_questions: string,\n  unknowns: string,\n  target_orgs: string,\n  target_roles: string\n) -> GoalLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are analyzing interview evidence against specific research goals and decision criteria defined for this project.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Project Research Goals\n    {{ project_goals }}\n\n    ## Decision Questions to Answer\n    {{ decision_questions }}\n\n    ## Unknowns/Uncertainties to Resolve\n    {{ unknowns }}\n\n    ## Target Organization Types\n    {{ target_orgs }}\n\n    ## Target Roles/Titles\n    {{ target_roles }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Your task is to directly answer the research goals and decision questions based on the interview evidence.\n\n    ### Goal Answers\n    - For each research goal, provide a direct answer\n    - Summarize key findings that address this goal\n    - Note confidence level based on strength of evidence\n    - Include any counterpoints or qualifications\n\n    ### Decision Insights\n    - For each decision question, provide a recommendation\n    - Explain the rationale based on interview evidence\n    - Note risks or caveats\n    - Assess confidence in the recommendation\n\n    ### Unknown Resolutions\n    - For each unknown/uncertainty, assess if it was resolved\n    - What did we learn?\n    - What's still unclear?\n    - Suggest how to further explore unresolved unknowns\n\n    ### Target Fit Assessment\n    - Assess how well the interviewee fits target org/role criteria\n    - Note specific signals from the interview\n    - Consider: do they exhibit the characteristics we're looking for?\n    - This helps determine if we should interview more people like them\n\n    ### Research Learnings\n    - Key learnings that are relevant to research goals\n    - Prioritize learnings by actionability\n    - Connect learnings back to goals\n\n    ### Goal Completion Score\n    - Calculate how well this interview addressed the research goals\n    - 1.0 = fully addressed all goals, 0.0 = addressed none\n    - Consider coverage and depth\n\n    ### Recommended Follow-Ups\n    - What follow-up questions emerged?\n    - What should we explore in future interviews?\n    - Who else should we talk to?\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "opportunity_advisor.baml": "// AI Advisor for Opportunity Progression\n// Analyzes opportunity context and provides actionable recommendations\n\nclass DealAdvisorRecommendation {\n  status_assessment string @description(\"One-line assessment of current deal status and momentum\")\n  recommendations string[] @description(\"2-3 specific, actionable recommendations for moving the deal forward. Each should be concrete and time-bound.\")\n  risks string[] @description(\"1-2 key risks or blockers that could derail the deal\")\n  confidence string @description(\"Confidence level: high, medium, or low\")\n}\n\nfunction AnalyzeOpportunity(\n  opportunity_title: string,\n  stage: string?,\n  amount: string?,\n  close_date: string?,\n  product_description: string?,\n  notes: string?,\n  stakeholders: string, // JSON string of stakeholder data\n  next_steps: string, // JSON string of next steps\n  linked_interviews: string, // JSON string of interview titles and dates\n) -> DealAdvisorRecommendation {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert sales strategist analyzing an opportunity to provide actionable guidance.\n\n    OPPORTUNITY CONTEXT:\n    - Title: {{ opportunity_title }}\n    {% if stage %}- Stage: {{ stage }}{% endif %}\n    {% if amount %}- Deal Value: ${{ amount }}{% endif %}\n    {% if close_date %}- Expected Close: {{ close_date }}{% endif %}\n    {% if product_description %}- Product: {{ product_description }}{% endif %}\n    {% if notes %}- Notes: {{ notes }}{% endif %}\n\n    STAKEHOLDER MATRIX:\n    {{ stakeholders }}\n\n    NEXT STEPS:\n    {{ next_steps }}\n\n    {% if linked_interviews %}\n    RECENT INTERVIEWS:\n    {{ linked_interviews }}\n    {% endif %}\n\n    YOUR TASK:\n    Analyze this opportunity and provide strategic guidance on how to advance it toward close.\n\n    Focus on:\n    1. STAKEHOLDER COVERAGE: Are we engaging the right people? Do we have access to decision makers?\n    2. MOMENTUM: Are next steps clear, owned, and time-bound? Is there forward progress?\n    3. QUALIFICATION: Is this a real opportunity? Do we understand their buying process?\n    4. RISKS: What could prevent this from closing? What's missing?\n\n    CRITICAL REQUIREMENTS:\n    - Status assessment should be ONE sentence that captures the current state and momentum\n    - Recommendations should be 2-3 SPECIFIC, ACTIONABLE items with clear next steps\n    - Each recommendation should indicate WHO should do WHAT by WHEN (or suggest timing)\n    - Risks should be 1-2 concrete blockers or red flags, not generic concerns\n    - Be direct and prescriptive - this is for the sales team to take action on\n    - Don't hedge or be vague - commit to a perspective based on the data\n\n    EXAMPLES OF GOOD RECOMMENDATIONS:\n    - \"Schedule a technical deep-dive with Engineering VP within 2 weeks to validate feasibility\"\n    - \"Request introduction to CFO by June 15th to discuss budget approval process\"\n    - \"Send ROI analysis to Champion by EOW to arm them for internal advocacy\"\n\n    EXAMPLES OF BAD RECOMMENDATIONS:\n    - \"Continue building relationships\" (too vague)\n    - \"Stay in touch\" (no action or timing)\n    - \"Be patient\" (not actionable)\n\n    Return a structured response with:\n    - status_assessment: one clear sentence\n    - recommendations: array of 2-3 specific actions\n    - risks: array of 1-2 concrete blockers\n    - confidence: \"high\", \"medium\", or \"low\" based on data quality and deal momentum\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "pain_matrix_insights.baml": "// Pain Matrix Insights Generation\n\nclass PainMatrixInsightsInput {\n  total_pains int @description(\"Total number of pain themes identified\")\n  total_groups int @description(\"Total number of user segments/groups\")\n  total_evidence int @description(\"Total evidence items analyzed\")\n  high_impact_cells int @description(\"Number of high-impact pain×segment combinations (impact ≥2.0)\")\n\n  top_pains TopPainCell[] @description(\"Top 5-10 pain×segment combinations by impact score\")\n}\n\nclass TopPainCell {\n  pain_name string @description(\"Name of the pain theme\")\n  user_group string @description(\"Name of the user segment\")\n  impact_score float @description(\"Impact score (person_count × intensity × willingness_to_pay)\")\n  frequency float @description(\"Frequency as decimal (0.0-1.0)\")\n  intensity string @description(\"Intensity level: low, medium, high, critical\")\n  willingness_to_pay string @description(\"WTP level: low, medium, high\")\n  person_count int @description(\"Number of people affected\")\n  evidence_count int @description(\"Number of evidence items\")\n  sample_quote string | null @description(\"Sample verbatim quote from evidence\")\n}\n\nclass PainMatrixInsights {\n  summary string @description(\"1-2 sentence summary of the biggest opportunity (most impactful pain). Be specific with numbers.\")\n  top_3_actions string[] @description(\"Exactly 3 bullet points: what to build/fix first, based on impact scores. Format: '[Pain] for [segment]: [score] impact'\")\n}\n\nfunction GeneratePainMatrixInsights(\n  matrix_data: PainMatrixInsightsInput\n) -> PainMatrixInsights {\n  client CustomGPT4oMini\n  prompt #\"\n    Analyze this pain matrix and provide actionable insights.\n\n    Data:\n    - {{ matrix_data.total_pains }} pains, {{ matrix_data.total_groups }} segments, {{ matrix_data.total_evidence }} evidence items\n    - {{ matrix_data.high_impact_cells }} high-impact cells (≥1.0)\n\n    Top pains by impact:\n    {{ matrix_data.top_pains }}\n\n    Rules:\n    - Be direct. No corporate speak.\n    - If sample size is small (< 30 evidence items) or segments have < 3 people, call it out as low confidence and recommend more interviews\n    - Use actual pain names and segment names from the data\n    - Include impact scores (1 decimal) in your recommendations\n    - Focus on the top 3 highest-impact opportunities\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "person_facet_lens.baml": "// Summarize a person's facet clusters into short takeaways for lens UI\n\nclass FacetSignalInput {\n  label string @description(\"Human-readable facet label or alias\")\n  source string | null @description(\"Where this facet came from: transcript-derived, manual, survey, etc.\")\n  confidence float | null @description(\"0-1 confidence about this facet\")\n}\n\nclass FacetGroupInput {\n  kind_slug string @description(\"Facet kind, e.g., demographic, task, workflow, pain, goal, value\")\n  kind_label string | null @description(\"Pretty label for the kind\")\n  facets FacetSignalInput[] @description(\"Distinct facets belonging to this kind\")\n}\n\nclass PersonLensMetadata {\n  person_id string @description(\"People table id\")\n  name string | null @description(\"Display name\")\n  title string | null @description(\"Job title/role label\")\n  company string | null @description(\"Company or organization\")\n  segment string | null @description(\"Segment or cohort label\")\n  persona string | null @description(\"Assigned persona name, if any\")\n  quick_facts string[] @description(\"Short factual strings to seed context (role, segment, company, etc.)\")\n}\n\nclass LensEvidenceHighlight {\n  gist string @description(\"<=200 char gist or quote; keep literal wording from source\")\n  interview_title string | null @description(\"Interview title or label\")\n  interview_date string | null @description(\"ISO timestamp of evidence interview\")\n  journey_stage string | null @description(\"Journey stage, if present\")\n  topic string | null @description(\"Tagged topic name\")\n  support string | null @description(\"supports | refutes | neutral\")\n}\n\nclass PersonFacetLensRequest {\n  person PersonLensMetadata @description(\"Person context for anchoring tone\")\n  facet_groups FacetGroupInput[] @description(\"All facet groups to summarize\")\n  evidence_highlights LensEvidenceHighlight[] @description(\"Optional evidence snippets to ground claims\")\n}\n\nclass FacetGroupSummary {\n  kind_slug string @description(\"Facet group being summarized\")\n  summary string @description(\"Concise summary capturing key points; can include multiple items if important, avoid fluff\")\n}\n\nclass PersonFacetLensResponse {\n  summaries FacetGroupSummary[]\n}\n\nfunction SummarizePersonFacetLens(payload: PersonFacetLensRequest) -> PersonFacetLensResponse {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a research summarizer. For each facet group, write a concise summary capturing the most important signals.\n    Style: Similar to pain/gain statements - punchy, concrete, action-oriented, NO FLUFF.\n\n    Rules:\n    - Capture ALL key points, even if it means multiple items (e.g., \"Struggles with data integration • Needs real-time sync • Limited by legacy APIs\")\n    - Use bullet separators (•) for multiple distinct points\n    - Lead with concrete specifics: actions, pains, goals, workflows, constraints\n    - Skip generic qualifiers and filler words\n    - Use evidence to ground claims but stay tight\n    - Never invent details. If thin, write what you know factually\n    - Length: Whatever it takes to capture important signals without fluff (typically 10-40 words)\n    - Each group should feel complete, not artificially truncated\n\n    {{ _.role(\"user\") }}\n    PERSON CONTEXT:\n    {{ payload.person }}\n\n    FACET GROUPS:\n    {{ payload.facet_groups }}\n\n    EVIDENCE HIGHLIGHTS:\n    {{ payload.evidence_highlights }}\n\n    Respond with {{ ctx.output_format }} containing summaries for every facet group.\n  \"#\n}\n",
  "person_profile_summary.baml": "// Generate concise participant descriptions from facet + scale data\n\nclass PersonFacetInput {\n  label string @description(\"Facet label or alias that should be echoed in the summary when relevant\")\n  kind_slug string @description(\"Facet kind slug such as demographic, task, workflow, preference, pain, goal, or value\")\n  source string | null @description(\"Source of the facet (e.g., transcript-derived, manual)\")\n  confidence float | null @description(\"0-1 confidence of the facet\")\n}\n\nclass PersonScaleInput {\n  kind_slug string @description(\"Scale identifier, e.g., adoption_stage, urgency, satisfaction\")\n  score float | null @description(\"Numeric scale score if available\")\n  band string | null @description(\"Qualitative band derived from the score (e.g., high, medium, low)\")\n  source string | null @description(\"Source of the scale reading\")\n  confidence float | null @description(\"0-1 confidence in this measurement\")\n}\n\nclass PersonEvidenceHighlight {\n  gist string @description(\"<=200 character gist or quote taken directly from interview evidence. No embellishment.\")\n  interview_title string | null @description(\"Interview title or internal label for context\")\n  interview_date string | null @description(\"ISO timestamp for when the interview occurred\")\n  journey_stage string | null @description(\"Journey stage noted on the evidence, if any\")\n  topic string | null @description(\"Tagged topic for the evidence snippet\")\n  support string | null @description(\"Support classification: supports | refutes | neutral\")\n}\n\nclass PersonProfileInput {\n  person_id string @description(\"Database ID for the person record\")\n  name string | null @description(\"Preferred name\")\n  title string | null @description(\"Job title or role label\")\n  role string | null @description(\"Functional role if distinct from title\")\n  company string | null @description(\"Company or organization\")\n  segment string | null @description(\"Segment or cohort label\")\n  persona string | null @description(\"Assigned persona name, if any\")\n  quick_facts string[] @description(\"Short factual statements derived from demographics or metadata\")\n  facets PersonFacetInput[] @description(\"Distinct persona facets for the participant\")\n  scales PersonScaleInput[] @description(\"Quantitative scale signals such as adoption, urgency, or satisfaction\")\n  evidence_highlights PersonEvidenceHighlight[] @description(\"Up to 6 concise interview gists that add color to the profile\")\n}\n\nclass PersonDescriptionSummary {\n  summary string @description(\"Describe the type of person in 3-5 short sentences. Each sentence should convey a concrete behavioral, motivational, or contextual point without fluff. Just the facts, as clearly as possible.\")\n}\n\nfunction SummarizePersonProfile(profile: PersonProfileInput) -> PersonDescriptionSummary {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a product researcher summarizing a single participant using curated persona facets.\n    Produce 3-5 crisp sentences that capture the most decision-relevant facts:\n    - Reference the strongest facets (tasks, pains, motivations, workflows, constraints).\n    - Tie in scale bands or scores when they clarify urgency or maturity.\n    - Fold quick_facts into the first sentence for fast context (role, segment, company, persona).\n    - Weave in 1-2 evidence_highlights so each summary has a concrete anecdote or quote; keep them short and attribute context (stage, topic, or interview title) when possible.\n    - Avoid flowery language, filler, and assumptions not supported by the data.\n    - Prefer concrete verbs/nouns over adjectives. Mention only what appears in the input.\n\n    {{ _.role(\"user\") }}\n    PARTICIPANT PROFILE:\n    {{ profile }}\n\n    Respond with {{ ctx.output_format }}.\n  \"#\n}\n",
  "persona_advisor.baml": "// Generate persona story reports that mirror the Opportunity AI Advisor structure.\n\nclass PersonaAdvisorFacetInput {\n  label string @description(\"Facet label or alias that should be echoed in the persona copy\")\n  kind_slug string @description(\"Facet kind such as motivation, value, pain, goal, habit, constraint, preference\")\n  confidence float | null @description(\"Normalized 0-1 confidence score\")\n  source string | null @description(\"Source of the signal, e.g., transcript, survey, manual\")\n}\n\nclass PersonaAdvisorScaleInput {\n  kind_slug string @description(\"Scale slug such as adoption_stage, urgency, satisfaction, readiness\")\n  score float | null @description(\"Numeric score, if available\")\n  band string | null @description(\"Qualitative band like high, medium, low, early, late\")\n  source string | null @description(\"Where the scale comes from\")\n  confidence float | null @description(\"0-1 confidence for this measurement\")\n}\n\nclass PersonaAdvisorThemeInput {\n  title string @description(\"Theme or insight title\")\n  description string | null @description(\"Brief summary or details of the insight\")\n  pain string | null @description(\"Pain description captured by the theme\")\n  desired_outcome string | null @description(\"Desired outcome or benefit\")\n  emotional_response string | null @description(\"Emotional language attached to the insight, if any\")\n  journey_stage string | null @description(\"Journey stage such as discovery, evaluation, use\")\n  category string | null @description(\"Business or product category label\")\n  evidence string[] | null @description(\"Supporting evidence snippets or quotes\")\n  persona_count int | null @description(\"How many personas reference this theme\")\n  priority int | null @description(\"Priority score for ordering the theme\")\n}\n\nclass ResearchInsightInput {\n  title string\n  summary string\n  source string | null\n  evidence string[] | null\n}\n\nclass PersonaAdvisorPersonaInput {\n  name string\n  tagline string | null\n  description string | null\n  quick_facts string[]\n  people_count int\n  percent float | null\n  motivations string[] | null\n  frustrations string[] | null\n  values string[] | null\n  goals string[] | null\n  primary_goal string | null\n  secondary_goals string[] | null\n  preferences string | null\n  tech_comfort_level string | null\n  key_tasks string[] | null\n  tools_used string[] | null\n  quotes string[] | null\n  facets PersonaAdvisorFacetInput[]\n  scales PersonaAdvisorScaleInput[]\n  themes PersonaAdvisorThemeInput[]\n}\n\nclass PersonaAdvisorContext {\n  project_name string\n  project_description string | null\n  personas PersonaAdvisorPersonaInput[]\n  research_insights ResearchInsightInput[]\n  shared_themes PersonaAdvisorThemeInput[]\n  total_personas int\n  total_people int\n}\n\nclass PersonaAdvisorReport {\n  markdown string\n}\n\nfunction GeneratePersonaAdvisorReport(context: PersonaAdvisorContext) -> PersonaAdvisorReport {\n  client CustomGPT4o\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a senior research partner embedded with a product team. Your job is to translate persona data into a crisp, structured markdown report that mirrors the example structure below.\n\n    {{ _.role(\"user\") }}\n    Use the data below to synthesize Persona narratives, shared insights, feature priorities, and positioning guidance.\n\n    PROJECT CONTEXT:\n    - name: {{ context.project_name }}\n    {% if context.project_description %}- description: {{ context.project_description }}{% endif %}\n\n    PERSONAS:\n    {{ context.personas }}\n\n    SHARED THEMES:\n    {{ context.shared_themes }}\n\n    RESEARCH INSIGHTS:\n    {{ context.research_insights }}\n\n    TOTAL PERSONAS: {{ context.total_personas }}\n    TOTAL PARTICIPANTS: {{ context.total_people }}\n\n    REPORT FORMAT (match this structure as closely as possible; use markdown headings, bullet lists, and tables):\n\n    Persona #1 The Name\n    \"Optional representative quote.\"\n\n    Who They Are: <1 short paragraph that references quick facts, the description, and any relevant scale bands.\n\n    Pain Points:\n    - ... (extract 3-4 pains from frustrations, facets, scales, or theme pain strings)\n\n    Motivations:\n    - ... (use motivations, values, and facets that read as drivers)\n\n    What They Love in the product:\n    - ... (tie to themes or positive facets, mention desired outcomes or emotional language)\n\n    User Quotes for recent interviews:\n    - \"Quote 1\"\n    - \"Quote 2\"\n\n    Repeat the persona block for each persona, numbering them in order.\n\n    💡Shared Insights Across Personas - What they both want\n    Shared Values:\n    - ... (use common values or motivation language across personas)\n    Top Feature Priorities:\n    - ... (draw from the shared themes and persona facets)\n    Positioning Guidance:\n    - \"Two supporting positioning lines that reframe the product narrative\"\n\n    🎯 Key Themes to Prioritize in Product & Messaging\n    Priority | Theme | Why It Matters\n    --- | --- | ---\n    High | Theme name | Tie in pain, desired outcome, or emotional response (include persona_count when helpful)\n    Medium | ...\n\n    🧩 Summary: Overlap in Features & Values\n    [Summarize 3 rows in table form or short bullets about reliability, reflection, meaning, privacy, etc.]\n\n    ---\n\n    Research Insights: The Performative Nature of Social Media\n    1. Title of research insight\n    Summary and evidence (cite source)\n\n    Problem Framing\n    <1-2 paragraphs that spotlight the shared tensions revealed by the data and tie back to your product narrative>\n\n    Pull quotes from context.quotes when possible and cite research_insights evidence when you can. Mention scale bands when they explain urgency or readiness. Frame the report around privacy, emotion, and meaningful capture, but do not invent data that is not present. If a section cannot be supported by the data, explain that it is speculative.\n\n    Return only valid markdown in the report string and nothing else.\n\n    Respond with {{ ctx.output_format }}.\n  \"#\n}\n",
  "product_lens_extraction.baml": "// Product Lens Extraction (JTBD + Feature Discovery)\n//\n// Extracts Jobs-to-be-Done, feature requests, product gaps, and competitive insights\n\n// ============================================================================\n// Core JTBD Classes\n// ============================================================================\n\nclass JobToBeDone {\n  job_description string @description(\"The core 'job' the user is trying to accomplish\")\n  situation string? @description(\"The situation or context when this job arises\")\n  desired_outcome string @description(\"What success looks like for this job\")\n  current_solution string? @description(\"How they currently try to accomplish this job\")\n  frustrations string[] @description(\"What frustrates them about current solutions\")\n  importance string @description(\"Importance level: 'critical', 'high', 'medium', or 'low'\")\n  satisfaction string @description(\"Current satisfaction: 'very_unsatisfied', 'unsatisfied', 'neutral', 'satisfied'\")\n  frequency string @description(\"How often: 'daily', 'weekly', 'monthly', 'occasionally', 'rarely'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this JTBD\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass FeatureRequest {\n  feature_name string @description(\"Name or short description of the requested feature\")\n  description string @description(\"Detailed description of what the feature should do\")\n  use_case string @description(\"The specific use case or problem this solves\")\n  priority string @description(\"User-indicated priority: 'must_have', 'should_have', 'nice_to_have'\")\n  related_job_description string? @description(\"Which job-to-be-done this feature helps with\")\n  competitive_alternative string? @description(\"Existing product/feature they compare this to\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this request\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass ProductGap {\n  gap_description string @description(\"Description of the missing capability or unmet need\")\n  impact string @description(\"Impact of this gap: 'blocking', 'significant', 'moderate', 'minor'\")\n  affected_workflow string? @description(\"Which workflow or process is affected\")\n  workaround string? @description(\"Current workaround if any\")\n  competitive_advantage string? @description(\"Competitor that has solved this\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this gap\")\n}\n\nclass CompetitiveInsight {\n  competitor_name string @description(\"Name of competitive product mentioned\")\n  context string @description(\"Context in which competitor was mentioned\")\n  comparison_type string @description(\"Type: 'positive' (they like it), 'negative' (they don't), 'neutral' (just mentioned)\")\n  specific_features string[] @description(\"Specific features mentioned\")\n  switching_consideration bool @description(\"Are they considering switching to/from this competitor?\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this insight\")\n}\n\nclass FeaturePrioritization {\n  feature_theme string @description(\"High-level feature theme or category\")\n  user_segments string[] @description(\"Which user segments care about this\")\n  evidence_count int @description(\"Number of evidence items supporting this\")\n  urgency_score float @description(\"Urgency score based on frequency and importance (0.0 to 1.0)\")\n  recommended_action string @description(\"Recommended next step for this feature\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass ProductLensExtraction {\n  jobs JobToBeDone[] @description(\"Jobs-to-be-Done identified in conversation\")\n  feature_requests FeatureRequest[] @description(\"Explicit feature requests\")\n  product_gaps ProductGap[] @description(\"Identified gaps in current product\")\n  competitive_insights CompetitiveInsight[] @description(\"Mentions of competitors or alternatives\")\n  feature_priorities FeaturePrioritization[] @description(\"Prioritized feature themes\")\n  key_insights string[] @description(\"Top 3-5 strategic product insights\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractProductLens(\n  evidence_json: string,\n  interview_context: string\n) -> ProductLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert product manager analyzing customer interview evidence to identify Jobs-to-be-Done (JTBD), feature requests, and product gaps.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence and extract comprehensive product insights:\n\n    ### Jobs-to-be-Done (JTBD)\n    - Identify the core \"jobs\" users are trying to accomplish\n    - Look for statements about goals, objectives, tasks they need to complete\n    - Capture the situation/context when this job arises\n    - Note their desired outcome and how they currently try to solve it\n    - Rate importance, satisfaction, and frequency based on evidence\n    - JTBD should be outcome-focused, not solution-focused\n\n    ### Feature Requests\n    - Explicit asks for specific features or capabilities\n    - \"I wish it could...\", \"It would be great if...\", \"I need to be able to...\"\n    - Capture the use case and why they need it\n    - Infer priority from their language (must have vs nice to have)\n    - Note any competitive alternatives they mention\n\n    ### Product Gaps\n    - Unmet needs or missing capabilities\n    - Workflows that are broken or inefficient\n    - Pain points that indicate missing features\n    - Note the impact and any workarounds they're using\n\n    ### Competitive Insights\n    - Mentions of other products, tools, or solutions\n    - What they like/dislike about alternatives\n    - Features they wish you had from competitors\n    - Switching considerations\n\n    ### Feature Prioritization\n    - Group related feature requests into themes\n    - Calculate urgency based on frequency and importance\n    - Provide actionable recommendations\n\n    ### Key Insights\n    - 3-5 strategic product insights for the product team\n    - Focus on high-impact opportunities\n    - Connect insights to business value\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "project_name_description.baml": "// Generate a concise project name and a two-sentence description\n\nclass ProjectNameDescription {\n  name string @description(\"3–5 word, concise project name without company names or PII\")\n  description string @description(\"Exactly 2 sentences summarizing goal, audience, and focus\")\n}\n\nfunction GenerateProjectNameDescription(\n  signup_data: string\n) -> ProjectNameDescription {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a product research strategist. Create a crisp project name and a short description\n    from messy signup inputs.\n\n    RULES:\n    - Name: 3–5 words. Title case. Avoid vague buzzwords.\n    - Description: Exactly 2 sentences. First: the goal and who it's for.\n      Second: the focus/constraints (e.g., channels or artifacts like recordings/notes).\n    - Prefer clarity over flair. Do not invent details. If info is missing, keep it generic.\n\n    INPUT:\n    signup_data (JSON):\n    {{ signup_data }}\n\n    OUTPUT FORMAT:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "project_template_fill.baml": "// Project Template Fill\n// General LLM contract to map signup_data and optional hints to\n// a concrete project template filled with helpful, specific defaults.\n\nclass ProjectTemplateOut {\n  template_key string @description(\"Identifier of the template, e.g. 'understand_customer_needs'\")\n  target_orgs string[]\n  target_roles string[]\n  research_goal string\n  research_goal_details string\n  decision_questions string[]\n  assumptions string[]\n  unknowns string[]\n  custom_instructions string\n}\n\n// This function should be general enough to fill any template in the future\n// using the template_key. For now, we primarily support 'understand_customer_needs'.\nfunction FillProjectTemplate(\n  template_key: string,\n  signup_data: string,\n  project_name: string\n) -> ProjectTemplateOut {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a senior UX research strategist. Convert messy signup inputs into a\n    clean, opinionated project setup tailored to the given template.\n\n    Templates (current + future):\n    - understand_customer_needs — Focus on jobs-to-be-done, outcomes, pains, contexts.\n    - improve_ecommerce_conversion — Focus on funnel blockers, intent, decision criteria. (future)\n    - consulting_stakeholder_interviews — Focus on stakeholder goals, risks, alignment. (future)\n\n    RULES:\n    - Be concrete, specific, and helpful. Prefer actionable phrasing over vague terms.\n    - Use the user's signup_data when relevant. If data is missing, fill with strong defaults\n      for the template.\n    - Keep target_orgs and target_roles concise and representative of the likely audience.\n    - decision_questions: 3–6 sharp questions the team must decide.\n    - assumptions: 3–6 current beliefs to test.\n    - unknowns: 3–6 gaps that would change decisions.\n    - custom_instructions: short guidance for downstream AI (tone, biases to avoid, focus).\n    - Never include PII. Do not invent company names.\n\n    INPUTS:\n    - template_key: {{ template_key }}\n    - project_name: {{ project_name }}\n    - signup_data (JSON string):\n    {{ signup_data }}\n\n    OUTPUT FORMAT:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "question_evaluation.baml": "// Question Quality Evaluation - evaluates custom questions for research best practices\n\nclass QuestionIssue {\n  type \"leading\" | \"closed_ended\" | \"too_vague\" | \"compound\" | \"biased\" | \"jargon\" | \"assume_knowledge\"\n  description string @description(\"Brief explanation of the issue\")\n  severity \"high\" | \"medium\" | \"low\" @description(\"How problematic this issue is\")\n}\n\nclass QuestionImprovement {\n  original_question string\n  suggested_rewrite string @description(\"Improved version of the question\")\n  explanation string @description(\"Why this version is better\")\n}\n\nclass QuestionEvaluation {\n  overall_quality \"green\" | \"yellow\" | \"red\" @description(\"Traffic light indicator of question quality\")\n  score int @description(\"0-100 quality score\")\n  strengths string[] @description(\"What makes this question effective\")\n  issues QuestionIssue[] @description(\"Problems identified with the question\")\n  improvement QuestionImprovement? @description(\"Suggested improvement if needed\")\n  recommendation \"proceed\" | \"revise\" @description(\"Should user proceed or revise the question\")\n  quick_feedback string @description(\"One-sentence summary of the assessment\")\n}\n\nfunction EvaluateInterviewQuestion(\n  question: string,\n  research_context: string\n) -> QuestionEvaluation {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher evaluating the quality of an interview question for exploratory research.\n\n    QUESTION TO EVALUATE:\n    \"{{ question }}\"\n\n    RESEARCH CONTEXT:\n    {{ research_context }}\n\n    EVALUATION CRITERIA (be encouraging, practical, and not nit‑picky):\n    \n    1. OPEN-ENDED: Encourage detailed, story-based responses (primary goal in exploratory).\n    2. NON-LEADING: Avoid suggestive or binary phrasing.\n    3. CLEAR & SPECIFIC: One topic, understandable in plain language.\n    4. CONVERSATIONAL: Friendly, natural tone.\n    5. ACTIONABLE: Likely to produce useful insights about the goal.\n\n    COMMON ISSUES TO FLAG (but don’t over-penalize if the question is broadly open‑ended):\n\n    HIGH SEVERITY:\n    - Leading questions that bias responses (\"Don't you think X is better?\")\n    - Yes/no or closed-ended questions\n    - Multiple questions in one (compound questions)\n    - Assumes knowledge the interviewee may not have\n\n    MEDIUM SEVERITY:\n    - Too vague or broad (\"Tell me about your experience\")\n    - Contains jargon or technical terms inappropriate for audience\n    - Potentially sensitive or awkward phrasing\n\n    LOW SEVERITY:\n    - Could be more conversational\n    - Minor clarity improvements possible\n\n    QUALITY SCORING (be lenient for exploratory mode):\n    - GREEN (75-100): Open-ended, non-leading, and broadly clear/conversational — proceed as-is\n    - YELLOW (55-74): Good direction; offer a small rewrite to be more specific/clear\n    - RED (0-54): Only if clearly leading, yes/no, or compound; provide a simple rewrite\n\n    PROVIDE (keep feedback calm, consistent, and practical):\n    1. Overall quality rating (green/yellow/red)\n    2. Numeric score (0-100)\n    3. Specific strengths of the question\n    4. Any issues found with severity levels\n    5. Suggested improvement if yellow/red — a single clear rewrite; prefer “Tell me about…”/“Walk me through…” patterns with a concrete example\n    6. Clear recommendation (proceed/revise)\n    7. One-sentence quick feedback (casual tone; avoid moving goalposts)\n\n    Be encouraging but honest. Focus on what makes questions effective for generating rich insights.\n    If the user’s latest version already addresses prior feedback, do not suggest a different change. Prefer stability and clarity.\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Batch evaluation for multiple questions\nclass BatchEvaluationResult {\n  evaluations QuestionEvaluation[]\n  overall_summary string @description(\"Summary of the question set quality\")\n  top_priorities string[] @description(\"Most important improvements to make\")\n}\n\nfunction EvaluateQuestionSet(\n  questions: string[],\n  research_context: string\n) -> BatchEvaluationResult {\n  client CustomGPT4oMini\n  prompt #\"\n    You are evaluating a set of interview questions for research quality.\n\n    QUESTIONS TO EVALUATE:\n    {% for question in questions %}\n    {{ loop.index }}. \"{{ question }}\"\n    {% endfor %}\n\n    RESEARCH CONTEXT:\n    {{ research_context }}\n\n    Evaluate each question individually using the same criteria as single question evaluation, then provide:\n    \n    1. Individual evaluation for each question\n    2. Overall summary of the question set's strengths and weaknesses\n    3. Top 2-3 priorities for improvement across the entire set\n\n    Look for issues like:\n    - Too many similar questions (redundancy)\n    - Missing important question types (no behavioral questions, etc.)\n    - Inconsistent tone or style\n    - Overall flow and progression\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "research_analysis.baml": "// Research Question Analysis - matches insights to user's research goals\n\nclass ResearchQuestion {\n  question string\n  priority int @description(#\" 1 - 3 with 1 being highest \"#)\n}\n\nclass ResearchGoal {\n  goal string\n  icp string // Target customer profile\n  role string // User segment\n  questions ResearchQuestion[]\n}\n\nclass InsightMatch {\n  question string\n  insights_found string[] // Insight names/summaries that answer this question\n  confidence int @description(#\" 1 - 3 with 1 being highest \"#)\n  answer_summary string // Clear, concise answer based on insights\n  evidence string[] // Supporting quotes/evidence from insights\n}\n\nclass GapAnalysis {\n  unanswered_questions string[]\n  partially_answered_questions string[]\n  follow_up_recommendations string[]\n  suggested_interview_topics string[]\n}\n\nclass ProjectAnalysis {\n  research_goal ResearchGoal\n  question_answers InsightMatch[]\n  gap_analysis GapAnalysis\n  key_discoveries string[] // Unexpected insights not related to original questions\n  confidence_score int // 0-100 overall confidence in findings\n  next_steps string[]\n}\n\nclass EvidenceItem {\n  id string\n  verbatim string\n  support \"supports\" | \"refutes\" | \"neutral\"\n  interview_id string?\n  context_summary string?\n}\n\nclass QuestionContext {\n  id string\n  kind \"decision\" | \"research\"\n  decision_question_id string?\n  text string\n  rationale string?\n}\n\nclass EvidenceQuestionLink {\n  question_id string\n  question_kind \"decision\" | \"research\"\n  decision_question_id string?\n  relationship \"supports\" | \"refutes\" | \"neutral\"\n  confidence float\n  answer_summary string\n  rationale string\n  next_steps string?\n}\n\nclass ResearchQuestionAnswer {\n  research_question_id string\n  findings string[] @description(\"2-5 specific findings from evidence, each a clear statement\")\n  evidence_ids string[] @description(\"IDs of evidence that support these findings\")\n  confidence float\n  reasoning string @description(\"Brief explanation of how evidence supports these findings\")\n}\n\nclass DecisionQuestionAnswer {\n  decision_question_id string\n  strategic_insight string @description(\"High-level strategic answer synthesized from research findings\")\n  supporting_findings string[] @description(\"Key findings from research questions that inform this decision\")\n  research_question_ids string[] @description(\"IDs of research questions that contributed to this answer\")\n  confidence float\n  reasoning string @description(\"How the research findings lead to this strategic insight\")\n  recommended_actions string[] @description(\"Specific next steps based on this insight\")\n}\n\nclass EvidenceLinkResult {\n  evidence_id string\n  links EvidenceQuestionLink[]\n}\n\nclass QuestionAnalysisSummary {\n  question_id string\n  question_kind \"decision\" | \"research\"\n  decision_question_id string?\n  confidence float\n  summary string\n  goal_achievement_summary string?\n  next_steps string?\n}\n\nclass EvidenceAnalysisResponse {\n  evidence_results EvidenceLinkResult[]\n  research_question_answers ResearchQuestionAnswer[] @description(\"Evidence-based findings for each research question\")\n  decision_question_answers DecisionQuestionAnswer[] @description(\"Strategic insights synthesized from research findings\")\n  global_goal_summary string?\n  recommended_actions string[]\n}\n\nfunction AnalyzeProjectInsights(\n  research_goal: string,\n  insights_data: string,\n  interview_summary: string,\n  custom_instructions: string\n) -> ProjectAnalysis {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing research findings against stated research goals and questions.\n\n    RESEARCH GOAL:\n    {{ research_goal }}\n\n    EXTRACTED INSIGHTS:\n    {{ insights_data }}\n\n    INTERVIEW SUMMARY:\n    {{ interview_summary }}\n\n    TASK: Analyze how well the insights answer each research question:\n\n    If we have custom_instructions, use them, otherwise follow the guidlines below.\n\n    CUSTOM_INSTRUCTIONS:\n    {{ custom_instructions }}\n\n    GUIDELINES:\n\n    1. For each question, produce a concise, actionable answer:\n       - insights_found: names/summaries of insights that directly or indirectly answer it (2-4 items if available)\n       - confidence: NUMERIC 1-3 where 1 = high, 2 = medium, 3 = low (no words)\n       - answer_summary: 1-2 sentence synthesis that a PM can act on; no preamble\n       - evidence: 1-3 short quotes or paraphrased snippets from interviews/insights. Prefer direct quotes. Keep each to <140 chars.\n\n    2. Gap Analysis (be specific and scoped to the research goal):\n       - Which questions remain unanswered or only partially answered\n       - What follow-up research is needed\n       - Suggest specific interview topics to fill gaps\n\n    3. Key Discoveries:\n       - Important insights that emerged beyond the original questions\n       - Unexpected findings that could redirect research focus\n\n    4. Next Steps:\n       - Concrete recommendations for the researcher\n       - Priority areas for additional interviews\n       - Suggested changes to research approach if needed\n\n    QUALITY BAR:\n    - Provide concise, evidence-backed answers with explicit numeric confidence (1-3).\n    - Include 1-3 relevant evidence quotes per answer, and reference related insights.\n    - Be specific, honest, and grounded in the provided data.\n    - Avoid generic or boilerplate phrasing, and do not repeat the question.\n    - Prefer concrete, falsifiable statements.\n\n\t    \tOutput format:\n    \t{{ ctx.output_format }}\n  \"#\n}\n\nfunction LinkEvidenceToResearchStructure(\n  evidence: EvidenceItem[],\n  questions: QuestionContext[],\n  custom_instructions: string\n) -> EvidenceAnalysisResponse {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert research analyst linking raw evidence to structured research questions and decisions.\n\n    EVIDENCE ITEMS (array of JSON objects with id, verbatim, support, interview_id, context_summary when available):\n    {{ evidence }}\n\n    QUESTION CONTEXT (each includes id, kind=decision/research, text, optional decision_question_id when kind='research'):\n    {{ questions }}\n\n    CUSTOM INSTRUCTIONS (optional, may be empty):\n    {{ custom_instructions }}\n\n    TASK REQUIREMENTS:\n\n    PHASE 1 - EVIDENCE TO RESEARCH QUESTIONS:\n    1. For each evidence item, link it to relevant RESEARCH questions only (not decision questions):\n       - Provide relationship (supports/refutes/neutral) and confidence 0.0 – 1.0\n       - Summarize what this evidence tells us (<= 2 sentences)\n       - Include rationale referencing key phrases from evidence (<= 220 chars)\n       - Suggest next steps when helpful\n\n    PHASE 2 - RESEARCH QUESTION ANSWERS:\n    2. For each research question, synthesize all linked evidence into findings:\n       - Generate 2-5 specific, evidence-based findings (clear statements, not questions)\n       - List evidence IDs that support each finding\n       - Provide overall confidence based on evidence strength and agreement\n       - Explain reasoning: how the evidence supports these findings\n       - Example finding: \"Users are willing to pay for interview assistance tools (5 mentions across 3 interviews)\"\n\n    PHASE 3 - DECISION QUESTION SYNTHESIS:\n    3. For each decision question, synthesize insights from its research questions:\n       - Create ONE strategic insight that answers the decision (not a list of evidence)\n       - Extract key findings from research questions that inform this decision\n       - List research question IDs that contributed\n       - Provide confidence based on research question coverage\n       - Explain reasoning: how research findings lead to this strategic answer\n       - Recommend 2-4 specific actions based on this insight\n       - Example insight: \"Adopt freemium model with premium interview features\" (NOT \"Users mentioned tools\" - that's RQ-level)\n\n    4. Provide project-wide guidance:\n       - global_goal_summary: overall progress toward research goal\n       - recommended_actions: 2-4 high-level actions for the project team\n\n    OUTPUT RULES:\n    - Return valid JSON matching EvidenceAnalysisResponse exactly.\n    - Omit evidence items that do not meaningfully map to questions (empty links array is acceptable).\n    - Keep confidence within [0.0, 1.0].\n    - Ensure every evidence link references question ids that exist in QUESTION CONTEXT.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Executive summary optimized for status screens\nclass ExecutiveSummary {\n  answered_insights string[] @description(\"Key findings that directly answer user's research questions, leading with pithy finding and then cause if known. Include 1-2 surprises if present.'\")\n  // unanticipated_discoveries string[] @description(\"Surprising findings not related to original questions'\")\n  critical_unknowns string[] @description(\"Important questions that remain unanswered or areas where evidence is insufficient\")\n  completion_percentage int @description(\"0-100 estimate of how much of the original research goal has been addressed\")\n  confidence int @description(\"1-3 with 1 being highest confidence in findings\")\n  next_action string @description(\"Single most important next 1-2 steps to advance the research\")\n}\n\nfunction GenerateExecutiveSummary(\n  research_goal: string,\n  insights_content: string,\n  interview_content: string,\n  custom_instructions: string\n) -> ExecutiveSummary {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing research findings to create an executive summary of goals and questions answered, with what level of confidence;\n\t\twhat's still unkonwn, and recommend next steps. Keep it pithy without preamble or fluff. Can be partial sentences.\n\n    RESEARCH GOAL:\n    {{ research_goal }}\n\n    INSIGHTS:\n    {{ insights_content }}\n\n    INTERVIEWS:\n    {{ interview_content }}\n\n    CUSTOM INSTRUCTIONS (if provided):\n    {{ custom_instructions }}\n\n    ANALYSIS REQUIREMENTS:\n\n    1. ANSWERED INSIGHTS (2-4 items):\n       - Major insights learned relative to research goal (group and summarizesimilar insights)\n       - Prioritize insights with strong evidence from multiple sources\n\t\t\t - Example: \"Users prefer mobile over desktop for quick tasks, because 8/10 interviews mentioned switching to phones when in a hurry\"\n\t\t\t - Call out truly surprising, UNANTICIPATED INSIGHTS if they exist and are relevant to the goal.\n       - Example: \"Price is less important than expected, because users consistently mentioned convenience over cost in decision-making\"\n       - Include only discoveries with solid evidence\n\n    3. REMAINING UNKNOWNS (1-3 items):\n       - Important questions that remain unanswered or areas with insufficient evidence\n       - Format as clear questions or knowledge gaps without any preample or fluff; partial sentences bullet style ok.\n       - Example: \"How users behave during peak usage times\" or \"Whether pricing sensitivity varies by user segment\"\n\n\t\t4. Recommendations:\n       - 1-2 recommendations that address the biggest gap or highest-value opportunity\n       - Be specific and actionable\n\n    5. COMPLETION PERCENTAGE:\n       - Estimate how much of the research goal has been addressed (0-100)\n       - Consider both breadth (topics covered) and depth (evidence quality)\n\n\n    QUALITY GUIDELINES:\n    - Use concrete evidence from the data, not assumptions\n    - Avoid jargon - write for business stakeholders\n    - Be honest about limitations and gaps\n    - Prioritize actionable insights over interesting but irrelevant findings\n\n\t\tOutput format:\n\t\t{{ ctx.output_format }}\n  \"#\n}\n\n// // Smart Research Question Generation for Onboarding\n// class SuggestedQuestion {\n//   question string\n//   rationale string // Why this question is important for their research\n//   interview_type \"user_interview\" | \"stakeholder_interview\" | \"expert_interview\"\n//   priority int @description(#\" 1 - 3 with 1 being highest \"#)\n// }\n\n// class ResearchQuestionSuggestions {\n//   core_questions SuggestedQuestion[] // 3-4 essential questions\n//   behavioral_questions SuggestedQuestion[] // Understanding user behavior\n//   pain_point_questions SuggestedQuestion[] // Identifying problems\n//   solution_questions SuggestedQuestion[] // Validating solutions\n//   context_questions SuggestedQuestion[] // Understanding environment/constraints\n// }\n\n// function GenerateResearchQuestions(\n// \ttarget_org: string,\n// \ttarget_roles: string,\n// \tresearch_goal: string,\n// \tresearch_goal_details: string,\n// \tassumptions: string,\n// \tunknowns: string,\n// \tcustom_instructions: string\n// ) -> ResearchQuestionSuggestions {\n//   client CustomGPT4o\n//   prompt #\"\n//     You are an expert UX researcher helping someone design interview questions.\n\n//     CONTEXT:\n//     - Target Audience: {{ target_org }}\n//     - User Role/Segment: {{ target_roles }}\n//     - Research Goal: {{ research_goal }}\n// \t\t- Research Goal Details: {{ research_goal_details }}\n// \t\t- Assumptions: {{ assumptions }}\n// \t\t- Unknowns: {{ unknowns }}\n\n// \t\tIf we have custom_instructions, use them, otherwise follow the guidlines below.\n\n// \t\tCUSTOM_INSTRUCTIONS:\n\n//     {{ custom_instructions }}\n\n//     GUIDELINES:\n\n//     Generate specific, actionable interview questions organized by category.\n\n//     1. Questions should be open-ended and behavior-focused\n//     2. Avoid leading questions or yes/no questions\n//     3. Include follow-up prompts in the question\n//     4. Make questions specific to their ICP and goal\n//     5. Prioritize questions that will reveal real user needs and pain points\n\n//     CATEGORIES:\n\n//     Core Questions (3-4 must-ask questions):\n//     - Essential questions that directly address their research goal\n//     - Should uncover key insights about user behavior and needs\n\n//     Behavioral Questions:\n//     - How users currently solve problems\n//     - Workflow and process understanding\n//     - Decision-making factors\n\n//     Pain Point Questions:\n//     - Current frustrations and challenges\n//     - Gaps in existing solutions\n//     - Cost of current approaches\n\n//     Solution Questions (if applicable):\n//     - Validation of potential solutions\n//     - Feature importance and prioritization\n//     - Willingness to pay or adopt\n\n//     Context Questions:\n//     - Environmental factors\n//     - Constraints and limitations\n//     - Stakeholder influences\n\n//     For each question provide:\n//     - The specific question text\n//     - Why it's important for their research (rationale)\n//     - What type of interview it's best for\n//     - Priority level\n\n// \t\tMake questions helpful, unique, conversational and natural, as if asking a friend.\n//     Avoid jargon and make them appropriate for the target audience.\n\n// \t\tOutput format:\n// \t\t{{ ctx.output_format }}\n//   \"#\n// }\n\n// ---------- Core data classes ----------\nclass Category {\n  id string @description(\"Stable string ID for the category (e.g., 'goals', 'pain', 'workflow', 'context', 'constraints', 'willingness-to-pay'). Use lowercase kebab/camel; must be unique within this QuestionSet.\")\n  label string @description(\"Human-readable category name shown in the UI (e.g., 'Goals & Outcomes').\")\n  weight float? @description(\"Optional multiplier (>=0.5 to <=1.5 typical) that boosts selection priority for this category. default = 1.0\")\n}\n\nclass Scores {\n  goalMatch float @description(\"0..1. How strongly this question aligns with the user's stated goals. Higher = more aligned.\")\n  novelty float @description(\"0..1. How different this question is from previously shown/asked items. Higher = more novel.\")\n  importance float @description(\"0..1. Domain importance for understanding needs vs potential. Weight this highest.\")\n  uncertainty float? @description(\"0..1. Confidence gap. Higher = exploring unknowns; helps diversify when uncertainty is high.\")\n}\n\nclass Source {\n\n}\n\nclass Question {\n  id string @description(\"CRITICAL: Unique string identifier (uuid/ulid-like). Must be globally unique across this entire QuestionSet. Generate using crypto.randomUUID() or similar. Never reuse IDs.\")\n  text string @description(\"The complete, conversational question text as you would ask a person. Include natural follow-ups when helpful.\")\n  categoryId string @description(\"Category.id this question belongs to. Must match a Category in this QuestionSet.\")\n  rationale string? @description(\"One short sentence on why this question matters for needs/potential.\")\n  tags string[]? @description(\"Optional short tags for filtering (e.g., 'pricing', 'workflow', 'adoption').\")\n  scores Scores @description(\"Scoring object. Provide values in [0,1] per field; the app computes a composite.\")\n  estimatedMinutes float @description(\"Realistic time estimate in minutes for this question (1-5 minutes typical). Consider question complexity, follow-ups, and discussion depth.\")\n  status \"proposed\" | \"shown\" | \"rejected\" | \"asked\" | \"answered\" @description(\"Lifecycle state. New questions must start as 'proposed'.\")\n  source \"llm\" | \"curated\" | \"custom\" @description(\"Origin of the question. Use 'llm' for generated items by default.\")\n  displayOrder int? @description(\"Optional UI order hint. Leave unset; the app may assign.\")\n  externalRef string? @description(\"Optional reference to a template/library identifier for provenance.\")\n}\n\nclass HistoryItem {\n  questionId string @description(\"The Question.id this event relates to.\")\n  action \"shown\" | \"rejected\" | \"asked\" | \"answered\" @description(\"What happened to the question at the given timestamp.\")\n  ts string @description(\"ISO-8601 timestamp of the event (e.g., '2025-08-27T04:15:00Z').\")\n  interviewId string? @description(\"Optional interview identifier to tie this event to a specific interview.\")\n}\n\nclass QuestionPolicy {\n  totalPerRound int @description(\"Maximum number of questions to surface in the next round.\")\n  perCategoryMin int? @description(\"Minimum number to include from each category for coverage. Use 0–2 typically.\")\n  perCategoryMax int? @description(\"Maximum number allowed from any single category to avoid flooding.\")\n  dedupeWindowRounds int? @description(\"How many previous rounds to consider for avoiding repeats. Use 1–3.\")\n  balanceBy string[]? @description(\"Balancing dimensions. Usually include 'category' and optionally 'novelty' or 'importance'.\")\n}\n\nclass QuestionSet {\n  sessionId string @description(\"Stable session identifier provided by the caller; reuse across rounds for the same user/research flow.\")\n  policy QuestionPolicy @description(\"Selection policy used by the app when choosing the next round.\")\n  categories Category[] @description(\"The complete list of categories available for this session. Keep to < 8.\")\n  questions Question[] @description(\"Pool of proposed questions. Start all as 'proposed'. Do not include duplicates.\")\n  history HistoryItem[] @description(\"Past events for this session. If the caller provides prior history, do not alter it; only append in the app.\")\n  round int @description(\"Current round number (1-based). Echo back the caller-provided value.\")\n}\n\n// ---------- Research Structure Classes ----------\nclass DecisionQuestionItem {\n  id string @description(\"Unique identifier for this decision question.\")\n  text string @description(\"The key business decision to be made (e.g., 'Should we build feature X?').\")\n  rationale string? @description(\"Why this decision matters for the business.\")\n}\n\nclass ResearchQuestionItem {\n  id string @description(\"Unique identifier for this research question.\")\n  text string @description(\"Specific research question to investigate (e.g., 'How do users currently solve problem Y?').\")\n  rationale string? @description(\"Why this research question helps answer the decision question.\")\n  decision_question_id string @description(\"ID of the decision question this research question supports.\")\n}\n\nclass InterviewPromptItem {\n  id string @description(\"Unique identifier for this interview prompt.\")\n  text string @description(\"Natural, conversational question to ask in interviews.\")\n  research_question_id string @description(\"ID of the research question this prompt investigates.\")\n}\n\nclass ResearchStructure {\n  decision_questions DecisionQuestionItem[] @description(\"High-level business decisions to be made.\")\n  research_questions ResearchQuestionItem[] @description(\"Specific research questions that support the decisions.\")\n  interview_prompts InterviewPromptItem[] @description(\"Natural interview questions that gather evidence.\")\n}\n\n// ---------- Legacy compatibility (kept) ----------\nclass SuggestedQuestion {\n  question string @description(\"Plain-text question wording.\")\n  rationale string @description(\"Why this question is important for research.\")\n  interview_type \"user_interview\" | \"stakeholder_interview\" | \"expert_interview\" @description(\"Primary interview type this question suits best.\")\n  priority int @description(\"1..3 (1 = highest). Indicate urgency/importance for early rounds.\")\n}\n\nclass ResearchQuestionSuggestions {\n  core_questions SuggestedQuestion[] @description(\"3–4 must-ask questions aligned to the research goal.\")\n  behavioral_questions SuggestedQuestion[] @description(\"Questions to understand current workflows/behaviors.\")\n  pain_point_questions SuggestedQuestion[] @description(\"Questions that surface current problems and friction.\")\n  solution_questions SuggestedQuestion[] @description(\"Questions to validate potential solutions and value.\")\n  context_questions SuggestedQuestion[] @description(\"Questions to capture environment, constraints, stakeholders.\")\n}\n\n// ---------- Inputs ----------\nclass GenerateInputs {\n  customer_problem string? @description(\"The business/customer problem being solved or addressed.\")\n  target_org string? @description(\"Target organization context (industry, size, market).\")\n  target_roles string? @description(\"Primary user roles/segments to interview (comma-separated or natural language).\")\n  offerings string? @description(\"Products and services offered to customers.\")\n  competitors string? @description(\"Other products or solutions customers are using or considering.\")\n  research_goal string @description(\"Short statement of the overarching research goal.\")\n  research_goal_details string? @description(\"Specific details and hypotheses relevant to this study.\")\n  assumptions string? @description(\"Key assumptions the team currently holds.\")\n  unknowns string? @description(\"Open questions and uncertainties to investigate.\")\n  custom_instructions string? @description(\"Optional caller-provided guidance that overrides defaults.\")\n  research_mode string? @description(\"Study mode. Expected: 'exploratory', 'validation', or 'user_testing'.\")\n  session_id string @description(\"Session identifier to embed into the returned QuestionSet.sessionId.\")\n  round int @description(\"1-based round number provided by the caller.\")\n  total_per_round int? @description(\"Default 25: number of questions to show per round.\")\n  per_category_min int? @description(\"Default 3: minimum per category.\")\n  per_category_max int? @description(\"Default 5: maximum per category.\")\n  interview_time_limit int? @description(\"Default 30: Expected interview time in minutes, use this to guide the selection of must ask questions.\")\n}\n\n// ---------- Research Structure Generation ----------\nfunction GenerateResearchStructure(\n  inputs: GenerateInputs\n) -> ResearchStructure {\n  client CustomGPT4o\n  prompt #\"\n  You are a research strategist helping to structure a user research study. Generate a complete research structure with decision questions, research questions, and interview prompts.\n\n  BUSINESS CONTEXT:\n  CUSTOMER PROBLEM: {{ inputs.customer_problem }}\n  OFFERINGS: {{ inputs.offerings }}\n  COMPETITORS: {{ inputs.competitors }}\n  TARGET ORGS: {{ inputs.target_org }}\n  TARGET ROLES: {{ inputs.target_roles }}\n\n  RESEARCH CONTEXT:\n  RESEARCH GOAL: {{ inputs.research_goal }}\n  DETAILS: {{ inputs.research_goal_details }}\n  RESEARCH MODE: {{ inputs.research_mode or \"exploratory\" }}\n  ASSUMPTIONS: {{ inputs.assumptions }}\n  UNKNOWNS: {{ inputs.unknowns }}\n\n  TASK: Create a structured research plan with three levels:\n\n  1. DECISION QUESTIONS (2-3 items):\n     - High-level business decisions that need to be made\n     - Should be strategic and actionable\n     - Examples: \"Should we build feature X?\", \"Which user segment should we prioritize?\"\n     - Each needs a unique ID and clear rationale\n\n  2. RESEARCH QUESTIONS (2-4 per decision question):\n     - Specific questions that help answer each decision question\n     - Should be investigative and focused\n     - Examples: \"How do users currently solve problem Y?\", \"What are the main barriers to adoption?\"\n     - Each needs a unique ID, rationale, and links to a decision question\n\n  3. INTERVIEW PROMPTS (2-3 per research question):\n     - Natural, conversational questions to ask in interviews\n     - Should be open-ended and behavior-focused\n     - Examples: \"Tell me about the last time you...\", \"What's most frustrating about...\"\n     - Each needs a unique ID and links to a research question\n\n  GUIDELINES:\n  - Make interview prompts conversational and natural, like you're talking to a friend\n  - Focus on understanding user behavior, pain points, and needs\n  - Avoid leading questions or yes/no questions\n  - Generate unique IDs for all items (use crypto.randomUUID() style)\n  - Ensure all items have proper relationships (research questions link to decision questions, etc.)\n\n  QUESTION DIVERSITY - Create a balanced mix covering:\n  - Background/Context: Current situation, existing solutions (especially competitors), tools being used\n  - Goals & Outcomes: What they're trying to achieve, success metrics, desired outcomes\n  - Pain Points: Frustrations with current solutions (including competitors), unmet needs, blockers\n  - Workflow & Behavior: Day-to-day processes, specific scenarios, decision-making patterns\n  - Constraints & Barriers: Budget limitations, technical constraints, organizational challenges\n  - Value & Willingness to Pay: What they'd pay for, ROI expectations, budget allocation\n  - Demographics/Firmographics: Company size, industry, role details, team structure\n\n  - If the research mode is \"validation\":\n      * Create exactly four research questions aligned to validation gates: Pain Exists, Awareness, Quantified Impact, Taking Action.\n      * Use deterministic IDs for those research questions: \"pain_exists\", \"awareness\", \"quantified\", \"acting\".\n      * Craft decision questions that frame the business need for validating assumptions.\n      * For each validation research question, include 2-3 interview prompts that directly probe evidence for that gate; including pain awareness, acting on it, Willingness to pay.\n      * When research mode is not \"validation\", follow the general exploratory guidance and choose research question counts based on context.\n  - If research mode is \"user_testing\", emphasise prompts seeking to understand if the user is aware of what is possible and expected ofthem. What actions do they want to take and why? How easy to understand and how usable is it.\n\n  QUALITY REQUIREMENTS:\n  - Decision questions should be strategic and business-focused\n  - Research questions should be specific and investigative\n  - Interview prompts should be natural and open-ended\n  - All text should be clear, concise, and actionable\n\n  Return the complete structure with all relationships properly linked.\n\n  {{ ctx.output_format }}\n  \"#\n}\n\n// ---------- Main generation function ----------\nfunction GenerateQuestionSet(\n  inputs: GenerateInputs\n) -> QuestionSet {\n  client CustomGPT4o\n  prompt #\"\n  You are creating natural conversation starters for informal interviews. Think like a curious friend who wants to understand someone's work and life, not a corporate consultant.\n\n  CRITICAL: Follow these CUSTOM INSTRUCTIONS above all else:\n  {{ inputs.custom_instructions }}\n\n  IMPORTANT: If the custom instructions above conflict with any context below, ALWAYS prioritize the custom instructions. The custom instructions define the true goal and scope of this research.\n\n\tYou will generate a larger set than can be asked in the available time, and prioritize the most important questions based on importance, goalMatch, and novelty.\n\n\tIMPORTANT: For each question, provide a realistic estimatedMinutes value (2-7 minutes typical):\n\t- Simple yes/no or factual questions: 1-2 minutes\n\t- Open-ended exploratory questions: 3-4 minutes\n\t- Complex scenario or deep-dive questions: 5-6 minutes\n\t- Consider follow-up discussion time in your estimate\n\n\tTotal available time: {{ inputs.interview_time_limit }} minutes.\n\tGenerate 25% more questions than can fit to give the interviewer options and backups.\n\n  BACKGROUND CONTEXT (use only if it aligns with custom instructions above):\n  - Customer Problem: {{ inputs.customer_problem }}\n  - Offerings: {{ inputs.offerings }}\n  - Competitors: {{ inputs.competitors }}\n  - Target Org: {{ inputs.target_org }}\n  - Roles/Segments: {{ inputs.target_roles }}\n  - Research Goal: {{ inputs.research_goal }}\n  - Goal Details: {{ inputs.research_goal_details }}\n  - Assumptions: {{ inputs.assumptions }}\n  - Unknowns: {{ inputs.unknowns }}\n\n  RESEARCH MODE: {{ inputs.research_mode or \"exploratory\" }}\n  MODE-SPECIFIC GUIDANCE:\n    - If research mode is \"validation\":\n        * Prioritise questions that surface evidence for the four validation gates (Pain Exists, Awareness, Quantified Impact, Acting/Next Steps).\n        * Ensure categories favour these gates (e.g., use categoryId values of \"pain\", \"awareness\", \"quantified\", \"acting\" when relevant).\n        * Keep prompts crisp and outcome-focused so answers can be mapped to go/no-go decisions.\n    - If research mode is \"user_testing\":\n        * Focus categories on usability, comprehension, task completion, and adoption.\n    - Otherwise keep a balanced exploratory mix across context, goals, pain, workflow, constraints, willingness, and demographics.\n\n  IMPORTANT: Pay special attention to the TARGET ROLES/SEGMENTS above. Create questions that are:\n  1) Highly specific to their daily work, creative processes, and unique challenges\n  2) Focused on their actual tools, platforms, and workflows they use\n  3) Addressing their specific pain points in their creative field\n  4) Understanding their community, audience, and collaboration patterns\n  5) Exploring their business model, income streams, and professional needs\n\n  EXAMPLES of GOOD conversational questions:\n  - \"I'm curious - when you're stuck on a design, what do you actually do? Like, do you take a walk, scroll Instagram, call a friend?\"\n  - \"What's the most annoying thing clients do? I bet you have some stories...\"\n  - \"Show me your workspace - what's the one tool or app you can't live without?\"\n  - \"When was the last time you collaborated with another artist? How did that come about?\"\n  - \"What's your biggest creative struggle right now? The thing that keeps you up at night?\"\n  - \"Where do you actually find your best ideas? I'm always curious about this.\"\n\n  EXAMPLES of BAD formal/corporate questions to AVOID:\n  - \"What challenges do you face in your creative process?\" (too formal)\n  - \"How do you align your content with your organizational mission?\" (corporate speak)\n  - \"What are your primary goals when creating content?\" (consultant-speak)\n  - \"What platforms do you use for inspiration and how do they influence your creative process?\" (too wordy/formal)\n\n  TONE & LANGUAGE REQUIREMENTS:\n  - Write questions like you're having coffee with a friend who does this work\n  - Use casual, natural language - avoid formal research-speak\n  - Be genuinely curious, not corporate or consultant-like\n  - Include contractions, casual phrases, personal touches\n  - Ask about real, specific situations they've experienced\n  - Show you understand their world (tools, platforms, community, struggles)\n\n  GUIDELINES:\n    1) Questions must be conversational, open-ended, and genuinely curious.\n    2) Include natural follow-ups in the question text when helpful.\n    3) Tailor specifically to the roles/segments - get into the weeds of their actual work.\n    4) Ask about specific situations, tools, processes they encounter daily.\n    5) Focus on real stories, concrete examples, day-to-day reality.\n    6) Provide balanced coverage across categories:\n       context, goals, pain, workflow, motivation, constraints, willingness, demographics.\n    7) Provide scores in [0,1]: importance (highest signal), goalMatch, novelty.\n    8) New questions must have status 'proposed'.\n    9) CRITICAL: Use completely unique string IDs for questions (uuid/ulid-like). Never reuse IDs. Each question must have a globally unique identifier.\n    10) Sound like a human talking to another human, not a researcher conducting an interview.\n    11) Do NOT use placeholders or template tokens like [relevant process], <thing>, {something}. If specifics are missing, write a complete, neutral phrase without brackets. The final question text must not contain '[' or ']'.\n\n  LENGTH & CLARITY CONSTRAINTS (strict):\n  - Keep each question short and crisp: 8–18 words (target ~12–16 words), max 140 characters.\n  - Do NOT list or restate roles/organizations in the question text; address the interviewee as \"you\".\n  - No long enumerations, comma chains, or multiple clauses; one clear idea per question.\n  - Avoid jargon and qualifiers; prefer simple, conversational phrasing.\n  - Never stitch together multiple audiences (e.g., \"Special Education Teacher, CIO, Clinical Psychologist...\"). Pick a single perspective implicitly via \"you\".\n\n  OUTPUT SHAPE\n  Return only valid JSON matching QuestionSet:\n  {\n    \"sessionId\": string,\n    \"policy\": {\n      \"totalPerRound\": number,\n      \"perCategoryMin\": number,\n      \"perCategoryMax\": number,\n      \"dedupeWindowRounds\": number,\n      \"balanceBy\": [\"category\",\"novelty\"]\n    },\n    \"categories\": Category[],\n    \"questions\": Question[],\n    \"history\": [],\n    \"round\": number\n  }\n\n  DEFAULTS\n  - policy.totalPerRound = {{ inputs.total_per_round }} or twice as many as interview_time_limit permits.\n  - policy.perCategoryMin = {{ inputs.per_category_min }}\n  - policy.perCategoryMax = {{ inputs.per_category_max }}\n  - policy.dedupeWindowRounds = 2\n  - policy.balanceBy = [\"category\",\"novelty\"]\n\n  HARD CONSTRAINTS\n  - No placeholders or bracketed variables in any question text.\n  - Max 140 characters per question. If longer, rewrite to fit while preserving meaning.\n\n  Return JSON only:\n  {{ ctx.output_format }}\n  \"#\n}\n\n// Follow-up question generation for dive deeper functionality\nclass FollowUpQuestionScores {\n  importance float @description(\"0.0-1.0 how important this follow-up is\")\n  goalMatch float @description(\"0.0-1.0 how well it matches research goals\")\n  novelty float @description(\"0.0-1.0 how novel/unique this angle is\")\n}\n\nclass FollowUpQuestion {\n  id string @description(\"Unique identifier for the follow-up question\")\n  text string @description(\"The follow-up question text\")\n  rationale string @description(\"Why this follow-up question is valuable\")\n  estimatedMinutes int @description(\"Estimated time in minutes to ask this question\")\n  categoryId string @description(\"Category like 'context', 'pain', 'workflow', etc.\")\n  scores FollowUpQuestionScores @description(\"Scoring metrics for this question\")\n}\n\nclass FollowUpSet {\n  originalQuestion string @description(\"The question we're diving deeper on\")\n  followUps FollowUpQuestion[] @description(\"2-4 follow-up questions\")\n}\n\nfunction GenerateFollowUpQuestions(\n  original_question: string,\n  research_context: string,\n  target_roles: string,\n  custom_instructions: string\n) -> FollowUpSet {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher generating follow-up questions to dive deeper into a specific topic.\n\n    ORIGINAL QUESTION: {{ original_question }}\n\n    RESEARCH CONTEXT: {{ research_context }}\n    TARGET ROLES: {{ target_roles }}\n\n    CUSTOM INSTRUCTIONS (follow these strictly):\n    {{ custom_instructions }}\n\n    TASK: Generate 2-4 thoughtful follow-up questions that dive deeper into the original question. These should:\n\n    1. Explore different angles of the original question\n    2. Uncover underlying motivations, pain points, or workflows\n    3. Ask for specific examples or stories\n    4. Probe for emotional responses or deeper context\n\n    QUALITY GUIDELINES:\n    - Make questions conversational and natural\n    - Avoid yes/no questions - prefer open-ended\n    - Ask for specific examples: \"Can you walk me through...\" or \"Tell me about a time when...\"\n    - Probe for emotions: \"How did that make you feel?\" or \"What was most frustrating about...\"\n    - Explore impact: \"What would happen if...\" or \"How does this affect your...\"\n    - Be specific to the target audience ({{ target_roles }})\n\n    CATEGORIES to use:\n    - context: Background and situational questions\n    - pain: Problems, frustrations, challenges\n    - workflow: Process, behavior, how things work\n    - goals: Motivations, desired outcomes\n    - constraints: Limitations, barriers\n    - willingness: Adoption, willingness to change\n    - demographics: Role, tenure, team size, seniority, geography, org size, etc.\n\n    SCORING:\n    - importance: 0.7-1.0 (these are follow-ups to important questions)\n    - goalMatch: 0.6-0.9 (should align well with research goals)\n    - novelty: 0.4-0.8 (varies by how unique the angle is)\n\n    ESTIMATED TIME:\n    - Simple clarification: 2-3 minutes\n    - Story/example requests: 4-5 minutes\n    - Complex scenario discussion: 5-6 minutes\n\n    KEEP THEM BRIEF:\n    - 6–16 words (max 120 characters) per follow-up.\n    - No role/organization lists; address the person as \"you\".\n\n    Return exactly {{ ctx.output_format }}\n  \"#\n}\n\ntest GenerateQuestionSet_Custom_Instructions2 {\n  functions [GenerateQuestionSet]\n  args {\n\t\tinputs {\n    target_org \"Regional nonprofit hospital network (6 clinics, 450-bed hospital)\",\n    target_roles \"Patients (outpatient), Front-desk staff, Nurses, Primary-care physicians\",\n    research_goal \"Improve patient intake and follow-up experience\",\n    research_goal_details \"Reduce waiting time, clarify instructions, and raise follow-up adherence for chronic care patients (diabetes, hypertension).\",\n    assumptions \"Patients miss follow-ups due to confusing discharge instructions; staff tools are fragmented.\",\n    unknowns \"Which steps create the most confusion? How do staff prioritize time? What would increase adherence?\",\n    custom_instructions \"Favor plain language for patients 8th-grade reading level; include at least 2 questions about accessibility and language.\",\n    session_id \"proj_health_001\",\n    round 1,\n    total_per_round 8,\n    per_category_min 1,\n    per_category_max 4\n\t}\n  }\n}\n",
  "research_analysis.tests.baml": "test GenerateQuestionSet_Pizza_Needs {\n  functions [GenerateQuestionSet]\n  args {\n\t\ttarget_org \"mom and pop pizza shops\"\n\t\ttarget_roles \"small business owners\"\n\t\tresearch_goal \"understand operational needs\"\n\t\tresearch_goal_details \"Identify key pain points and operational challenges facing small pizza shop owners\"\n\t\tassumptions \"Pizza shops struggle with staffing and inventory management\"\n\t\tunknowns \"What specific operational challenges cause the most impact on profitability\"\n\t\tcustom_instructions \"\"\n\t\tsession_id \"test_pizza_001\"\n\t\tround 1\n\t\ttotal_per_round 8\n\t\tper_category_min 1\n\t\tper_category_max 3\n\t\tinterview_time_limit 30\n  }\n} \n\ntest GenerateQuestionSet_Salon_Scheduling {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Independent salons and neighborhood barbershops\"\n    target_roles \"Salon owners, Barbers, Front-desk staff\"\n    research_goal \"Improve appointment scheduling and reduce no‑shows\"\n    research_goal_details \"Explore booking flow, reminders, walk‑ins vs. appointments, and peak‑time bottlenecks\"\n    assumptions \"SMS reminders reduce no‑shows; most rescheduling happens within 24 hours\"\n    unknowns \"Where do booking mistakes happen? Which reminders actually get noticed? How do walk‑ins impact schedule?\"\n    custom_instructions \"Avoid placeholders; keep questions conversational and specific to salons and barbers.\"\n    session_id \"test_salon_sched_001\"\n    round 1\n    total_per_round 8\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 30\n  } }\n}\n\ntest GenerateQuestionSet_Journaling_Moms {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Consumer mobile apps (wellness & journaling)\"\n    target_roles \"Moms of young kids, Caregivers\"\n    research_goal \"Understand journaling habits, constraints, and motivations for busy moms\"\n    research_goal_details \"When/where they journal, prompts that help, barriers (time/energy), privacy needs, notifications\"\n    assumptions \"Short prompts lower friction; voice capture helps when hands are busy\"\n    unknowns \"Which moments are most journal‑worthy? What keeps streaks going? What feels intrusive?\"\n    custom_instructions \"Friendly tone. No template brackets. Prefer ‘Tell me about…’ and ‘Walk me through…’ when helpful.\"\n    session_id \"test_journaling_moms_001\"\n    round 1\n    total_per_round 10\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 45\n  } }\n}\n\ntest GenerateQuestionSet_SaaS_Willingness {\n  functions [GenerateQuestionSet]\n  args { inputs {\n\t\ttarget_org \"HealthCareVibe\"\n\t\ttarget_roles \"Founding CEO, CTO, CMO\"\n\t\tresearch_goal \"willingness to adopt our healthcare technology\"\n\t\tresearch_goal_details \"We are a healthcare technology company and are looking to understand the willingness of healthcare providers to adopt our platform.\"\n\t\tassumptions \"Healthcare providers are willing to adopt our technology but may have concerns about integrating our platform into their existing systems.\"\n\t\tunknowns \"We are unsure how healthcare providers will perceive our technology and how much they will be willing to pay for it.\"\n\t\tcustom_instructions \"Please generate a list of 5-10 questions to interview healthcare providers about their willingness to adopt our technology. Include questions about their concerns about integrating our platform, their perception of our technology, and their willingness to pay for our services. Please also include questions about their current technology stack and how they currently manage their patient data.\"\n\t\tsession_id \"test_healthcare_001\"\n\t\tround 1\n\t\ttotal_per_round 10\n\t\tper_category_min 1\n\t\tper_category_max 3\n\t\tinterview_time_limit 30\n  }\n\t}\n}\n\ntest GenerateQuestionSet_Custom_Instructions {\n  functions [GenerateQuestionSet]\n  args {\n    target_org \"Regional nonprofit hospital network (6 clinics, 450-bed hospital)\"\n    target_roles \"Patients (outpatient), Front-desk staff, Nurses, Primary-care physicians\"\n    research_goal \"Improve patient intake and follow-up experience\"\n    research_goal_details \"Reduce waiting time, clarify instructions, and raise follow-up adherence for chronic care patients (diabetes, hypertension).\"\n    assumptions \"Patients miss follow-ups due to confusing discharge instructions; staff tools are fragmented.\"\n    unknowns \"Which steps create the most confusion? How do staff prioritize time? What would increase adherence?\"\n    custom_instructions \"Favor plain language for patients 8th-grade reading level; include at least 2 questions about accessibility and language.\"\n    session_id \"proj_health_001\"\n    round 1\n    total_per_round 8\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 45\n  }\n}\n\ntest GenerateQuestionSet_Validation_Mode {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Early-stage SaaS startups\"\n    target_roles \"Founders, Heads of Product\"\n    research_goal \"Validate whether the onboarding problem is painful enough to pay for\"\n    research_goal_details \"Focus on evidence for the four validation gates: pain, awareness, quantified impact, acting.\"\n    assumptions \"Teams are losing trial users during onboarding and already track the impact manually.\"\n    unknowns \"How do they measure churn today? What action do they take when onboarding fails?\"\n    custom_instructions \"Keep prompts short and conversational.\"\n    research_mode \"validation\"\n    session_id \"validation_sample_001\"\n    round 1\n    total_per_round 12\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 30\n  } }\n}\n\ntest GenerateExecutiveSummary_Pizza_Basic {\n  functions [GenerateExecutiveSummary]\n  args {\n    research_goal \"understand operational challenges for pizza shop owners\"\n    insights_content #\"\"\"\nPizza shop owners face three major operational challenges:\n\n1. **Staff Scheduling**: Manual scheduling takes 3-5 hours weekly\n2. **Inventory Waste**: 15-20% food waste due to poor forecasting\n3. **Technology Overwhelm**: Current POS systems too complex\n\nKey findings from 2 interviews with pizza shop owners.\n\"\"\"#\n    interview_content #\"\"\"\nTony (Pizza Palace, 8 years):\n- Biggest challenge: finding reliable part-time staff\n- Uses spreadsheets for everything\n- Rush hour wait time complaints\n\nMaria (Mama Mia's, 15 years):\n- Family business struggling with rising costs\n- Paper schedules, constant sick callouts\n- Would pay for time-saving solutions\n\"\"#,\n\t\t\t\t\tcustom_instructions \"\"\n\t\t\t\t}\n\n}\n",
  "research_lens_extraction.baml": "// Research Lens Extraction (Usability + Validation)\n//\n// Extracts usability findings, hypothesis validation, user journey insights, and research learnings\n\n// ============================================================================\n// Core Research Classes\n// ============================================================================\n\nclass UsabilityFinding {\n  finding_description string @description(\"Description of the usability issue or observation\")\n  severity string @description(\"Severity: 'critical', 'major', 'minor', 'enhancement'\")\n  affected_feature string? @description(\"Specific feature or workflow affected\")\n  user_behavior string @description(\"What the user did or tried to do\")\n  user_expectation string @description(\"What the user expected to happen\")\n  actual_result string @description(\"What actually happened\")\n  suggested_fix string? @description(\"Potential solution or recommendation\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this finding\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass HypothesisValidation {\n  hypothesis_statement string @description(\"The hypothesis being tested or discussed\")\n  validation_result string @description(\"Result: 'validated', 'invalidated', 'partially_validated', 'inconclusive'\")\n  supporting_evidence string[] @description(\"Evidence that supports or refutes the hypothesis\")\n  confidence_level string @description(\"Confidence: 'high', 'medium', 'low'\")\n  implications string @description(\"What this means for the product or research direction\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this validation\")\n}\n\nclass UserJourneyInsight {\n  journey_stage string @description(\"Stage: 'awareness', 'consideration', 'purchase', 'onboarding', 'usage', 'retention', 'expansion'\")\n  insight_description string @description(\"Key insight about this journey stage\")\n  pain_points string[] @description(\"Pain points encountered at this stage\")\n  moments_of_delight string[] @description(\"Positive experiences at this stage\")\n  opportunity_area string? @description(\"Opportunity to improve this stage\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this insight\")\n}\n\nclass BehaviorPattern {\n  pattern_description string @description(\"Description of the observed behavior pattern\")\n  frequency string @description(\"How common: 'very_common', 'common', 'occasional', 'rare'\")\n  user_segment string? @description(\"Which user segment exhibits this pattern\")\n  triggers string[] @description(\"What triggers this behavior\")\n  implications string @description(\"What this pattern means for product design\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this pattern\")\n}\n\nclass ResearchQuestionInsight {\n  question string @description(\"The research question raised\")\n  status string @description(\"Status: 'answered', 'partially_answered', 'unanswered'\")\n  answer string? @description(\"The answer if found\")\n  follow_up_needed string? @description(\"What follow-up research is needed\")\n  evidence_ids string[] @description(\"IDs of evidence related to this question\")\n}\n\nclass MentalModel {\n  model_description string @description(\"Description of user's mental model or understanding\")\n  matches_product bool @description(\"Does their mental model match how the product actually works?\")\n  gap_description string? @description(\"If not, what's the gap between their model and reality?\")\n  design_recommendation string? @description(\"How to align product with user mental model\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this mental model\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass ResearchLensExtraction {\n  usability_findings UsabilityFinding[] @description(\"Usability issues and observations\")\n  hypothesis_validations HypothesisValidation[] @description(\"Hypotheses tested or discussed\")\n  journey_insights UserJourneyInsight[] @description(\"Insights across the user journey\")\n  behavior_patterns BehaviorPattern[] @description(\"Observed behavioral patterns\")\n  research_questions ResearchQuestionInsight[] @description(\"Research questions raised or answered\")\n  mental_models MentalModel[] @description(\"User mental models uncovered\")\n  key_learnings string[] @description(\"Top 3-5 key research learnings\")\n  recommended_next_research string[] @description(\"Recommended follow-up research\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractResearchLens(\n  evidence_json: string,\n  interview_context: string\n) -> ResearchLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert UX researcher analyzing interview evidence to extract usability findings, validate hypotheses, and understand user behavior.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence and extract comprehensive research insights:\n\n    ### Usability Findings\n    - Identify where users struggled, got confused, or had friction\n    - Note the severity based on impact on user experience\n    - Capture what they tried to do vs what happened\n    - Include their expectations vs reality\n    - Suggest potential fixes based on the issue\n\n    ### Hypothesis Validation\n    - Look for evidence that validates or invalidates assumptions\n    - \"I thought users would...\", \"We assumed...\", \"We believed...\"\n    - Assess confidence level based on strength of evidence\n    - Note implications for product decisions\n\n    ### User Journey Insights\n    - Map insights to specific stages of the user journey\n    - Identify pain points and moments of delight at each stage\n    - Look for opportunities to improve the journey\n    - Focus on transitions between stages\n\n    ### Behavior Patterns\n    - Recurring behaviors or habits mentioned\n    - How frequently these patterns occur\n    - What triggers these behaviors\n    - Implications for product design and features\n\n    ### Research Questions\n    - Questions that were answered during the interview\n    - New questions that emerged\n    - Gaps in understanding that need follow-up research\n\n    ### Mental Models\n    - How users think about or understand the product/domain\n    - Metaphors or analogies they use\n    - Mismatches between their model and actual product behavior\n    - Recommendations to align product with their mental model\n\n    ### Key Learnings\n    - 3-5 most important research insights\n    - Focus on actionable findings\n    - Connect to user needs and product decisions\n\n    ### Recommended Next Research\n    - Follow-up questions to explore\n    - Hypotheses to test in future research\n    - User segments or scenarios to study further\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "research_questions.baml": "// Nested Research Questions & Interview Prompts generation\n// Input: goal + decision questions (+ optional audience context)\n// Output: plan with decision_questions[], research_questions[], interview_prompts[], other_data_sources[]\n\nclass DecisionQuestionOut {\n  id string @description(\"Unique UUID. Do not use PII.\")\n  text string @description(\"The business decision the user needs to make\")\n  rationale string @description(\"Why this decision is important for achieving the user's goal\")\n  key_metrics string[] @description(\"Concrete metrics that would inform this business decision\")\n  risks_if_wrong string[] @description(\"Business risks if this decision is made incorrectly\")\n}\n\nclass ResearchQuestionOut {\n  id string @description(\"Unique UUID\")\n  dq_id string @description(\"Links to DecisionQuestionOut.id\")\n  text string @description(\"The research question that needs to be answered to inform the decision\")\n  rationale string @description(\"How answering this research question will help make the business decision\")\n  evidence_types string[] @description(\"Types of evidence needed: QUOTES, ANALYTICS, SURVEY, EXPERIMENT, OBSERVATIONS, MARKET_DATA\")\n  suggested_methods string[] @description(\"Research methods to gather this evidence (e.g., user interviews, analytics analysis)\")\n}\n\nclass InterviewPromptOut {\n  id string @description(\"Unique UUID\")\n  rq_ids string[] @description(\"Links to ResearchQuestionOut.id\")\n  text string @description(\"Open-ended question to ask interviewees to gather evidence for the research question\")\n  followups string[] @description(\"Follow-up questions to ask interviewees to dig deeper\")\n  bias_checks string[] @description(\"Reminders to keep questions neutral and avoid leading the interviewee\")\n}\n\nclass ResearchPlanOut {\n  goal string @description(\"The user's business goal they want to achieve\")\n  decision_questions DecisionQuestionOut[] @description(\"Business decisions the user needs to make\")\n  research_questions ResearchQuestionOut[] @description(\"Questions that need to be answered to inform decisions\")\n  interview_prompts InterviewPromptOut[] @description(\"Questions to ask interviewees to gather evidence\")\n  other_data_sources string[] @description(\"Additional data sources beyond interviews (analytics, surveys, etc.)\")\n}\n\nfunction GenerateNestedResearchQuestions(\n  goal: string,\n  decision_questions: string[],\n  target_orgs: string,\n  target_roles: string,\n  custom_instructions: string\n) -> ResearchPlanOut {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher creating a research plan that connects business decisions to interview questions.\n\n    CONTEXT - USER'S BUSINESS SITUATION:\n    - Business Goal: {{ goal }}\n    - Key Decisions They Need to Make:\n    {% for dq in decision_questions %}\n      - {{ dq }}\n    {% endfor %}\n    - Target Interview Participants: {{ target_roles }} at {{ target_orgs }}\n\n    IMPORTANT DISTINCTION:\n    - The USER is the one with the business goal and decisions to make\n    - The INTERVIEWEES are {{ target_roles }} who will be interviewed to provide insights\n    - Interview questions should ask interviewees about THEIR experiences, not the user's business decisions\n\n    If custom instructions are provided, follow them strictly:\n    CUSTOM INSTRUCTIONS:\n    {{ custom_instructions }}\n\n    REQUIREMENTS:\n\n    1) decision_questions: For each business decision the user needs to make:\n       - id: sequential like dq1, dq2, ...\n       - text: clear business decision the user faces\n       - rationale: why this decision matters for achieving their business goal\n       - key_metrics: 2-4 concrete metrics that would inform this business decision\n       - risks_if_wrong: 1-3 business risks if decided incorrectly\n\n    2) research_questions: For each decision, create 1-3 research questions that need answers:\n       - id: rq{dq index}{letter} e.g., rq1a, rq1b, ...\n       - dq_id: link to the parent decision question id\n       - text: what needs to be learned from {{ target_roles }} to inform the business decision\n       - rationale: how this research insight will help make the business decision\n       - evidence_types: 1-3 tags (QUOTES, ANALYTICS, SURVEY, EXPERIMENT, OBSERVATIONS, MARKET_DATA, SUPPORT_TICKETS, BETA_LOGS)\n       - suggested_methods: 1-3 methods (e.g., user interviews, segmented analytics, A/B test, survey)\n\n    3) interview_prompts: Create interview questions to ask {{ target_roles }} at {{ target_orgs }}:\n       - id: ip1, ip2, ...\n       - rq_ids: one or more linked research question ids\n       - text: OPEN-ENDED question asking interviewees about THEIR experiences, behaviors, or perspectives (NOT about the user's business decisions)\n       - followups: 2-3 follow-up questions to dig deeper into the interviewee's experiences\n       - bias_checks: 1-2 reminders to keep questions neutral and avoid leading the interviewee\n\n    4) other_data_sources: 2-4 additional data sources beyond interviews (analytics, logs, competitor research, surveys, etc.).\n\n    INTERVIEW QUESTION GUIDELINES:\n    - Ask interviewees about THEIR experiences, not the user's business\n    - Use \"Tell me about...\" \"Walk me through...\" \"Describe...\" formats\n    - Focus on behaviors, motivations, pain points, and decision-making processes\n    - Avoid yes/no questions and leading language unless the question_category is 'demographic' or intentionally very specific\n    - Make questions specific to {{ target_roles }} at {{ target_orgs }}\n    - Example: Instead of \"How should we improve our pricing?\" ask \"Tell me about your experience evaluating and choosing between similar products or services\"\n\n    Return only valid JSON that matches the schema exactly:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "sales_lens_extraction.baml": "// Sales Lens BANT Extraction\n//\n// Extracts Budget, Authority, Need, Timeline (BANT) framework data from evidence.\n// Also identifies stakeholder roles, next steps, and deal qualification signals.\n\n// ============================================================================\n// Core BANT Classes\n// ============================================================================\n\nclass BudgetInfo {\n  has_budget_discussion bool @description(\"Whether budget was explicitly discussed\")\n  amount_mentioned string? @description(\"Any specific amount or range mentioned (e.g., '$50K', '100-150K range')\")\n  budget_status string? @description(\"Status: 'approved', 'pending', 'not_discussed', 'insufficient', or 'flexible'\")\n  pricing_sensitivity string @description(\"Sensitivity level: 'high', 'medium', or 'low'\")\n  payment_terms string? @description(\"Payment structure if mentioned (e.g., 'annual contract', 'per seat', 'usage-based')\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  supporting_quote string? @description(\"Most relevant verbatim quote about budget\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass AuthorityInfo {\n  decision_maker_identified bool @description(\"Whether a clear decision maker was identified\")\n  decision_maker_name string? @description(\"Name of the decision maker if known\")\n  decision_maker_role string? @description(\"Role/title of decision maker (e.g., 'VP Engineering', 'CEO')\")\n  approval_process string? @description(\"Described approval process (e.g., 'needs board approval', 'can decide independently')\")\n  stakeholders_involved string[] @description(\"Other stakeholders involved in decision\")\n  blockers string[] @description(\"Identified blockers or obstacles (e.g., 'CFO concerned about cost', 'legal review required')\")\n  political_dynamics string? @description(\"Any power dynamics or politics mentioned\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass NeedInfo {\n  primary_pain_points string[] @description(\"Top 3-5 pain points or needs expressed\")\n  pain_severity string @description(\"Overall severity: 'critical', 'significant', 'moderate', or 'minor'\")\n  impact_on_business string? @description(\"How the problem impacts their business\")\n  current_workarounds string[] @description(\"Current solutions or workarounds they're using\")\n  must_have_features string[] @description(\"Features they explicitly said are must-haves\")\n  nice_to_have_features string[] @description(\"Features that are desirable but not critical\")\n  competing_priorities string[] @description(\"Other projects or initiatives competing for attention\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass TimelineInfo {\n  urgency_level string @description(\"Urgency: 'immediate', 'high', 'medium', or 'low'\")\n  target_date string? @description(\"Specific date or timeframe mentioned (e.g., 'Q1 2025', 'by March', 'within 3 months')\")\n  deadline_type string? @description(\"Type of deadline: 'hard_deadline', 'soft_target', 'flexible', or 'no_deadline'\")\n  implementation_timeline string? @description(\"Expected implementation timeframe\")\n  external_drivers string[] @description(\"External factors driving timeline (e.g., 'end of fiscal year', 'product launch')\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass NextStepInfo {\n  action_item string @description(\"Specific action to be taken\")\n  owner string? @description(\"Who is responsible (name or role)\")\n  due_date string? @description(\"When it should be done\")\n  commitment_level string @description(\"Level of commitment: 'firm', 'tentative', or 'vague'\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this\")\n}\n\nclass StakeholderRole {\n  person_name string @description(\"Name of the CUSTOMER stakeholder (NOT internal team members like sales reps)\")\n  person_role string? @description(\"Their job title or role at the CUSTOMER organization\")\n  role_type string @description(\"Buying role: MUST be one of: 'economic_buyer', 'decision_maker', 'influencer', 'champion', or 'blocker'. Only for customer-side people.\")\n  influence_level string @description(\"Influence level: 'high', 'medium', or 'low'\")\n  sentiment string @description(\"Their sentiment toward the solution: 'positive', 'neutral', 'negative', or 'skeptical'\")\n  key_concerns string[] @description(\"Their main concerns or objections\")\n  key_motivations string[] @description(\"What motivates them about this solution\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass DealQualificationSignals {\n  positive_signals string[] @description(\"Positive signals that indicate a qualified opportunity\")\n  warning_flags string[] @description(\"Warning flags or red flags to watch out for\")\n  overall_qualification string @description(\"Overall assessment: 'highly_qualified', 'qualified', 'somewhat_qualified', or 'not_qualified'\")\n  recommended_actions string[] @description(\"Recommended next actions based on qualification\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass SalesLensExtraction {\n  budget BudgetInfo @description(\"Budget information and constraints\")\n  authority AuthorityInfo @description(\"Decision-making authority and process\")\n  need NeedInfo @description(\"Customer needs and pain points\")\n  timeline TimelineInfo @description(\"Timeline and urgency information\")\n  next_steps NextStepInfo[] @description(\"Agreed-upon next steps and action items\")\n  stakeholders StakeholderRole[] @description(\"Stakeholder analysis and roles\")\n  deal_qualification DealQualificationSignals @description(\"Deal qualification assessment\")\n  key_insights string[] @description(\"Top 3-5 strategic insights for the sales team\")\n  risks_and_concerns string[] @description(\"Identified risks or concerns to address\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractSalesLensBant(\n  evidence_json: string,\n  interview_context: string\n) -> SalesLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert sales analyst extracting BANT (Budget, Authority, Need, Timeline) framework information from customer interview evidence.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence above and extract comprehensive BANT information. For each assessment:\n    1. Base your analysis ONLY on the evidence provided - do not infer beyond what's stated\n    2. Always include the evidence_ids that support each claim\n    3. Use verbatim quotes when available for supporting_quote fields\n    4. Assign confidence scores based on clarity and specificity of evidence\n    5. Identify stakeholder dynamics and power structures\n\n    ### Budget\n    - Look for: pricing discussions, budget constraints, cost concerns, ROI conversations, payment terms\n    - Assess sensitivity based on how much they focus on price vs value\n    - Include specific amounts if mentioned, even if approximate\n\n    ### Authority\n    - Identify who has decision-making power\n    - Map the approval process and stakeholders involved\n    - Flag any blockers or political dynamics\n    - Note if they're speaking independently or need buy-in\n\n    ### Need\n    - Extract all pain points mentioned, ranked by severity\n    - Understand business impact of these problems\n    - Distinguish between must-haves and nice-to-haves\n    - Note current workarounds or competing solutions\n\n    ### Timeline\n    - Assess urgency level based on language used\n    - Extract any specific dates or timeframes\n    - Identify external drivers (fiscal year, product launches, etc.)\n    - Determine if deadlines are hard requirements or soft targets\n\n    ### Stakeholders\n    - IMPORTANT: Only identify CUSTOMER-SIDE stakeholders (prospects, clients, decision makers from the customer organization)\n    - EXCLUDE internal team members (sales reps, account executives, customer success, support staff, etc.) - they are NOT stakeholders\n    - Example: If \"DJ\" is conducting the interview or representing your company, DO NOT include them as economic_buyer or decision_maker\n    - Example: If \"Stephen\" is the prospect being interviewed, include them with appropriate customer-side role (e.g., decision_maker, influencer)\n    - Map each CUSTOMER stakeholder to a buying role (economic_buyer, decision_maker, influencer, champion, blocker)\n    - Assess their influence level and sentiment\n    - Identify their specific concerns and motivations\n    - This is CRITICAL for navigating complex B2B sales\n\n    ### Next Steps\n    - Extract specific, actionable commitments\n    - Note who owns each action and when it's due\n    - Assess commitment level (firm vs tentative)\n\n    ### Deal Qualification\n    - Identify positive signals (strong need, clear budget, engaged champion, etc.)\n    - Flag warning signs (lack of urgency, no clear authority, vague needs, etc.)\n    - Provide an overall qualification assessment\n    - Recommend specific actions to advance or qualify out\n\n    ## Output Requirements\n    - Be specific and evidence-based\n    - Always link back to evidence IDs\n    - Use confidence scores to indicate certainty\n    - Provide actionable insights for the sales team\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}