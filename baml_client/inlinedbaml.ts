/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "apply_conversation_lens.baml": "// Generic lens application that works with any template definition\n// This is the dynamic engine that drives all conversation lenses\n\nclass LensFieldValue {\n  field_key string @description(\"Matches field_key from template\")\n  value string @description(\"Extracted value or summary\")\n  confidence float @description(\"0.0-1.0 confidence score\")\n  evidence_ids string[] @description(\"IDs of supporting evidence (use 8-char prefix)\")\n}\n\nclass LensSectionResult {\n  section_key string @description(\"Matches section_key from template\")\n  summary string @description(\"Punchy 1-2 sentence summary of this section's key findings. Use bullet separators (•) for multiple distinct points. Concrete, action-oriented, no fluff.\")\n  fields LensFieldValue[] @description(\"Extracted field values\")\n}\n\n// Rich entity types for different entity categories\nclass LensStakeholderItem {\n  name string @description(\"Person's name as mentioned in conversation\")\n  role string? @description(\"Job title or role mentioned\")\n  influence \"low\" | \"medium\" | \"high\" | null @description(\"Decision-making influence level\")\n  labels string[] @description(\"Labels like 'economic_buyer', 'champion', 'blocker', 'technical_evaluator', 'end_user'\")\n  email string? @description(\"Email if mentioned\")\n  organization string? @description(\"Company/org name if mentioned\")\n  confidence float\n  evidence_ids string[]\n}\n\nclass LensNextStepItem {\n  description string @description(\"What needs to be done\")\n  owner string? @description(\"Who is responsible (name)\")\n  due_date string? @description(\"When it's due (ISO date or relative like 'next week')\")\n  status \"pending\" | \"in_progress\" | \"completed\" | null @description(\"Current status if known\")\n  priority \"high\" | \"medium\" | \"low\" | null\n  confidence float\n  evidence_ids string[]\n}\n\nclass LensObjectionItem {\n  objection string @description(\"The concern or objection raised\")\n  type string @description(\"Category: price, timing, competition, technical, stakeholder, other\")\n  status \"raised\" | \"addressed\" | \"unresolved\" | null @description(\"Current status\")\n  response string? @description(\"How it was addressed, if at all\")\n  confidence float\n  evidence_ids string[]\n}\n\nclass LensEntityResult {\n  entity_type \"stakeholders\" | \"next_steps\" | \"objections\" | \"other\" @description(\"Type of entities in this group\")\n  stakeholders LensStakeholderItem[]? @description(\"Populated when entity_type is 'stakeholders'\")\n  next_steps LensNextStepItem[]? @description(\"Populated when entity_type is 'next_steps'\")\n  objections LensObjectionItem[]? @description(\"Populated when entity_type is 'objections'\")\n}\n\nclass LensHygieneItem {\n  code string @description(\"Identifier like 'missing_budget', 'missing_timeline', 'no_champion'\")\n  severity \"info\" | \"warning\" | \"critical\"\n  message string @description(\"Human-readable description of the gap\")\n  field_key string? @description(\"Related field if applicable\")\n}\n\nclass LensRecommendation {\n  type string @description(\"next_step, follow_up, risk, opportunity\")\n  description string\n  priority \"high\" | \"medium\" | \"low\"\n  rationale string?\n  evidence_ids string[]\n}\n\nclass ConversationLensResult {\n  executive_summary string @description(\"TLDR: 2-3 sentence executive summary of the entire lens analysis. Lead with the most important finding or status. Concrete, direct, actionable.\")\n  sections LensSectionResult[]\n  entities LensEntityResult[]\n  recommendations LensRecommendation[]\n  hygiene LensHygieneItem[] @description(\"Missing or incomplete information warnings\")\n  overall_confidence float\n  processing_notes string?\n}\n\nfunction ApplyConversationLens(\n  template_definition: string,\n  template_name: string,\n  evidence_json: string,\n  interview_context: string,\n  custom_instructions: string?\n) -> ConversationLensResult {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert conversation analyst. Apply the following analytical lens/framework\n    to extract structured insights from interview evidence.\n\n    ## Template: {{ template_name }}\n    {{ template_definition }}\n\n    ## Interview Context\n    {{ interview_context }}\n\n    {% if custom_instructions %}\n    ## Custom Instructions\n    {{ custom_instructions }}\n    {% endif %}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    ### Executive Summary (TLDR)\n    1. Start with a 2-3 sentence executive_summary that captures the most important takeaway\n       - Lead with status/verdict (e.g., \"Strong alignment on goals but timeline risks unresolved\")\n       - Be concrete and actionable, not generic\n       - This is what someone reads if they only have 10 seconds\n\n    ### Section Extraction\n    2. For each section, provide BOTH:\n       - **summary**: Punchy 1-2 sentence summary of key findings. Use bullet separators (•) for multiple points.\n         Style: \"Client wants faster onboarding • Success = 50% reduction in setup time • Hard deadline: Q2 launch\"\n       - **fields**: Detailed field-by-field extraction (see below)\n\n    3. For each field defined in the template, extract the relevant information\n    4. **CRITICAL**: Always populate the `value` field with actual extracted text from the evidence:\n       - For text fields: Extract a summary or direct quote\n       - For text_array fields: Extract multiple items as a list of strings\n       - Never leave value empty if you have evidence_ids - synthesize the content from those evidence items\n       - For monetary/numeric fields like \"deal_size\", \"budget\", \"potential value\": Extract as dollar amounts (e.g., \"$50K\", \"$100,000\", \"$50-100K range\")\n    5. Always cite evidence_ids (use the 8-character ID prefix) that support each extraction\n    6. Assign confidence scores (0.0-1.0) based on how directly the evidence supports the extraction\n    7. Only omit a field entirely if there is truly no relevant evidence - do NOT include a field with evidence_ids but empty value\n\n    ### Entity Extraction\n    8. **Stakeholders**: Extract ALL people mentioned with decision-making relevance:\n       - Include their role/title if mentioned\n       - Assess influence level (high = final decision maker, medium = key influencer, low = end user)\n       - Apply labels: economic_buyer, champion, blocker, technical_evaluator, end_user, coach\n       - Include email and organization if mentioned\n\n    9. **Next Steps**: Extract ALL action items, commitments, or follow-ups mentioned:\n       - Include who owns the action if stated\n       - Include due dates or timeframes if mentioned\n       - Set status based on context (pending if future, completed if done)\n       - Set priority based on urgency signals\n\n    10. **Objections**: Extract concerns, pushback, or blockers raised:\n        - Categorize by type (price, timing, competition, technical, stakeholder, other)\n        - Note if/how the objection was addressed\n        - Track status (raised, addressed, unresolved)\n\n    ### Hygiene Checks\n    11. Generate hygiene warnings for missing critical information:\n        - missing_budget: No budget/pricing discussion\n        - missing_timeline: No timeline or urgency mentioned\n        - missing_authority: Decision maker not identified\n        - missing_need: Core pain/need not clearly articulated\n        - no_champion: No internal advocate identified\n        - unaddressed_objection: Objection raised but not resolved\n\n    ### Recommendations\n    12. Generate actionable recommendations based on gaps and opportunities discovered\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "ask_link_insights.baml": "// Ask Link Response Analysis\n// Generates insights and summaries from survey/Ask link responses\n\nclass ResponseTheme {\n  theme string @description(\"Key theme identified across responses (3-5 words)\")\n  description string @description(\"Brief description of the theme\")\n  frequency int @description(\"Number of responses mentioning this theme\")\n  sentiment string @description(\"Overall sentiment: Positive | Neutral | Negative | Mixed\")\n  example_quotes string[] @description(\"2-3 representative quotes from responses\")\n}\n\nclass QuestionInsight {\n  question string @description(\"The survey question\")\n  summary string @description(\"Concise summary of responses to this question\")\n  key_findings string[] @description(\"Top 3 key findings from responses\")\n  common_answers string[] @description(\"Most common types of answers\")\n  notable_outliers string[] @description(\"Interesting outlier responses worth noting\")\n}\n\nclass SegmentPattern {\n  segment_name string @description(\"Descriptive name for this response segment\")\n  segment_description string @description(\"What characterizes this group\")\n  respondent_count int @description(\"Number of respondents in this segment\")\n  key_characteristics string[] @description(\"Defining characteristics of this segment\")\n  recommended_actions string[] @description(\"Suggested follow-up actions for this segment\")\n}\n\nclass AskLinkInsightsResponse {\n  executive_summary string @description(\"2-3 sentence overview of all responses\")\n  total_responses int @description(\"Total number of responses analyzed\")\n  completion_rate int @description(\"Percentage of responses that were completed\")\n\n  top_themes ResponseTheme[] @description(\"Top 3-5 themes across all responses\")\n  question_insights QuestionInsight[] @description(\"Insights for each survey question\")\n  response_segments SegmentPattern[] @description(\"Distinct patterns/segments in respondents\")\n\n  recommended_followups string[] @description(\"Suggested follow-up questions or research\")\n  actionable_insights string[] @description(\"Clear, actionable insights from the data\")\n  data_quality_notes string[] @description(\"Notes about data quality or gaps\")\n}\n\nfunction AnalyzeAskLinkResponses(\n  ask_link_name: string,\n  questions: string,\n  responses_data: string,\n  context: string\n) -> AskLinkInsightsResponse {\n  client \"CustomGPT4o\"\n  prompt #\"\n    You are a research analyst specializing in survey analysis and qualitative data synthesis.\n\n    ## Ask Link Survey: {{ ask_link_name }}\n\n    ## Survey Questions\n    {{ questions }}\n\n    ## Response Data\n    {{ responses_data }}\n\n    ## Additional Context\n    {{ context }}\n\n    ## Your Task\n    Analyze all survey responses to generate comprehensive insights:\n\n    1. **Executive Summary**\n       - Provide a 2-3 sentence overview capturing the most important findings\n       - Focus on actionable insights, not just observations\n\n    2. **Theme Analysis**\n       - Identify 3-5 key themes that emerge across multiple responses\n       - Note sentiment and provide representative quotes\n       - Quantify frequency where possible\n\n    3. **Question-by-Question Analysis**\n       - For each question, summarize the responses\n       - Highlight key findings and common patterns\n       - Note any surprising or outlier responses worth investigating\n\n    4. **Response Segmentation**\n       - Identify distinct groups or patterns in respondents\n       - What characterizes each segment?\n       - What different follow-up might each segment need?\n\n    5. **Actionable Recommendations**\n       - What should the team do next based on these responses?\n       - What follow-up questions or research would be valuable?\n       - What decisions can be made from this data?\n\n    ## Analysis Guidelines\n    - Be specific and evidence-based - cite actual responses\n    - Focus on patterns, not individual data points\n    - Highlight unexpected findings and anomalies\n    - Consider what questions the data doesn't answer\n    - Provide actionable recommendations, not just observations\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Quick summary function for smaller response sets\nclass QuickResponseSummary {\n  summary string @description(\"1-2 sentence summary. Be HONEST about sample size - if only 1-2 quality responses, say 'Based on limited data from X respondent(s)...'\")\n  quality_responses_count int @description(\"Number of quality responses after filtering junk\")\n  total_responses_count int @description(\"Total responses including junk\")\n  top_insights string[] @description(\"1-3 BRIEF insights. If <3 quality responses, prefix with 'Limited data:' and keep very short. Empty array if insufficient data.\")\n  sentiment_overview string @description(\"Overall sentiment: Positive | Neutral | Negative | Mixed | Insufficient data\")\n  suggested_actions string[] @description(\"1-2 brief actions. If <3 quality responses, just say 'Collect more responses before drawing conclusions'. Empty if no actionable data.\")\n  data_quality_warning string @description(\"Plain English warning like 'Only 1 of 3 responses contained meaningful answers - results are not statistically significant.' Empty if data quality is good (>50% quality).\")\n}\n\nfunction SummarizeAskLinkResponses(\n  ask_link_name: string,\n  questions: string,\n  responses_data: string\n) -> QuickResponseSummary {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    Analyze these survey responses HONESTLY.\n\n    ## Survey: {{ ask_link_name }}\n\n    ## Questions\n    {{ questions }}\n\n    ## Responses\n    {{ responses_data }}\n\n    ## CRITICAL: Be Brutally Honest About Data Quality\n\n    STEP 1: Count quality vs junk responses\n    - Junk = gibberish (\"asdf\", \"qwerty\", random chars), test entries (\"test\", \"123\"), single characters, nonsense\n    - Quality = thoughtful answers that actually address the questions\n    - Report EXACT counts: quality_responses_count and total_responses_count\n\n    STEP 2: Adjust your analysis based on sample size\n    - If 0-1 quality responses: Say \"Insufficient data to draw conclusions\" - do NOT make up insights\n    - If 2 quality responses: Be very cautious, prefix everything with \"Limited data suggests...\"\n    - If 3+ quality responses: Can provide more confident insights, but still note sample size\n\n    STEP 3: Be plain about data quality issues\n    - If >50% responses were junk, put a clear warning in data_quality_warning\n    - Example: \"Only 1 of 3 responses contained meaningful answers. These results are not representative.\"\n\n    ## Output Guidelines\n    - summary: Start with sample size context (\"Based on 1 quality response out of 3 total...\")\n    - top_insights: Keep VERY short (1 line each). If <3 quality responses, provide 1-2 max or empty array.\n    - suggested_actions: If insufficient data, just say \"Collect more responses\" - don't make up actions\n    - DO NOT pretend you have findings when you don't\n    - DO NOT pad insights to hit a number - quality over quantity\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test for development\ntest AnalyzeAskLinkResponses_Sample {\n  functions [AnalyzeAskLinkResponses]\n  args {\n    ask_link_name \"Product Feedback Survey\"\n    questions #\"\n      1. What's your biggest challenge with our product?\n      2. What feature would you most like to see added?\n      3. How likely are you to recommend us to a colleague? (1-10)\n      4. Any other feedback?\n    \"#\n    responses_data #\"\n      ## Response 1 (john@acme.com) - Completed\n      Q1: The onboarding process is confusing. Took me 3 days to figure out basic features.\n      Q2: Better documentation and video tutorials\n      Q3: 6\n      Q4: Love the concept but execution needs work\n\n      ## Response 2 (sarah@startup.io) - Completed\n      Q1: Integration with our existing tools is painful\n      Q2: Slack integration\n      Q3: 8\n      Q4: Great product, just needs more integrations\n\n      ## Response 3 (mike@corp.co) - Completed\n      Q1: Too many clicks to do simple things\n      Q2: Keyboard shortcuts\n      Q3: 7\n      Q4: UI could be more efficient\n\n      ## Response 4 (lisa@agency.com) - In Progress\n      Q1: Onboarding was rough, almost gave up\n      Q2: —\n      Q3: —\n      Q4: —\n    \"#\n    context \"Early-stage B2B SaaS product, 50 active users, seeking product-market fit\"\n  }\n}\n",
  "auto_group_themes.baml": "// Auto-group themes from evidence\n// Used by db.autoThemes.server.ts to consolidate evidence into themes\n\nclass ProposedTheme {\n  name string @description(\"Theme name - concise (3-7 words), actionable insight\")\n  statement string @description(\"Clear statement of the theme/insight (1-2 sentences). This will be used for semantic matching.\")\n  inclusion_criteria string @description(\"What types of quotes/evidence belong to this theme\")\n  exclusion_criteria string | null @description(\"What should NOT be included\")\n  synonyms string[] @description(\"Alternative phrasings (3-5 terms)\")\n}\n\nclass AutoGroupThemesResponse {\n  themes ProposedTheme[] @description(\"Consolidated themes from the evidence\")\n}\n\nfunction AutoGroupThemes(evidence_json: string, guidance: string) -> AutoGroupThemesResponse {\n  client \"CustomGPT4o\"\n  prompt #\"\n    You are a user research analyst consolidating evidence into actionable themes.\n\n    ## Evidence Data (verbatim quotes from user interviews)\n    {{ evidence_json }}\n\n    ## Guidance\n    {{ guidance }}\n\n    ## Instructions\n    1. Analyze the evidence and identify 5-12 distinct themes/patterns\n    2. Each theme needs a clear `statement` that captures its essence (used for semantic matching)\n    3. Include `inclusion_criteria` describing what quotes belong\n    4. Theme names should be actionable insights, not just topics\n       - Good: \"Users struggle with complex onboarding flows\"\n       - Bad: \"Onboarding issues\"\n\n    Note: Evidence linking happens automatically via semantic similarity - just focus on creating clear, well-defined themes.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest auto_group_themes_basic {\n  functions [AutoGroupThemes]\n  args {\n    evidence_json #\"\n      [\n        {\"id\": \"ev-1\", \"verbatim\": \"I hate how slow the app loads\", \"personas\": [\"power_user\"], \"journey_stage\": \"onboarding\"},\n        {\"id\": \"ev-2\", \"verbatim\": \"Loading takes forever on my phone\", \"personas\": [\"casual_user\"], \"journey_stage\": \"daily_use\"},\n        {\"id\": \"ev-3\", \"verbatim\": \"I wish I could customize my dashboard\", \"personas\": [\"power_user\"], \"journey_stage\": \"daily_use\"}\n      ]\n    \"#\n    guidance \"Focus on UX pain points\"\n  }\n}\n",
  "auto_insights.baml": "// Auto-Insights BAML Schema and Function\n// Generates executive-level insights and recommendations from user research data\n\nclass ActionButton {\n  label string @description(\"Button text for the action\")\n  action_type string @description(\"Type of action: create_opportunity | prioritize_insight | schedule_research | create_persona | tag_insights\")\n  parameters string @description(\"Action-specific parameters as JSON string\")\n  priority string @description(\"Action priority: High | Medium | Low\")\n}\n\nclass ExecutiveInsight {\n  title string @description(\"Executive-level insight title (5-8 words)\")\n  insight string @description(\"Strategic insight or recommendation (2-3 sentences without the fluff)\")\n  evidence string[] @description(\"Supporting evidence from user research (quotes, data points)\")\n  business_impact string @description(\"Business impact description and potential value\")\n  impact_level string @description(\"Impact level: High | Medium | Low\")\n  confidence_level string @description(\"Confidence in this insight: High | Medium | Low\")\n  personas_affected string[] @description(\"Which personas this insight affects most\")\n  recommended_actions ActionButton[] @description(\"Actionable next steps with buttons\")\n  category string @description(\"Insight category: Revenue | Product | User Experience | Market | Risk\")\n}\n\nclass OpportunityRecommendation {\n  title string @description(\"Opportunity title\")\n  description string @description(\"Detailed opportunity description\")\n  revenue_potential string @description(\"Revenue potential: High | Medium | Low\")\n  effort_estimate string @description(\"Implementation effort: High | Medium | Low\")\n  target_personas string[] @description(\"Primary personas who would benefit\")\n  supporting_insights string[] @description(\"Key insights that support this opportunity\")\n  competitive_advantage string @description(\"How this creates competitive advantage\")\n  recommended_actions ActionButton[] @description(\"Next steps to pursue this opportunity\")\n}\n\nclass PersonaAnalysis {\n  persona_name string @description(\"Persona name\")\n  key_pain_points string[] @description(\"Top 3 pain points for this persona\")\n  unmet_needs string[] @description(\"Unmet needs and desired outcomes\")\n  revenue_potential string @description(\"Revenue potential from this persona: High | Medium | Low\")\n  willingness_to_pay string @description(\"Likelihood to pay for solutions: High | Medium | Low\")\n  recommended_solutions string[] @description(\"Specific solutions this persona would value\")\n  competitive_threats string[] @description(\"How competitors might target this persona\")\n}\n\nclass AutoInsightsResponse {\n  executive_summary string @description(\"High-level summary of key findings (3-4 sentences)\")\n  top_opportunities OpportunityRecommendation[] @description(\"Top 3-5 revenue-generating opportunities\")\n  critical_insights ExecutiveInsight[] @description(\"Most important strategic insights\")\n  persona_analysis PersonaAnalysis[] @description(\"Analysis of each key persona\")\n  competitive_considerations string[] @description(\"Key competitive pressures and threats\")\n  immediate_actions ActionButton[] @description(\"Top 3 immediate actions to take\")\n  strategic_recommendations string[] @description(\"Long-term strategic recommendations\")\n}\n\nfunction GenerateAutoInsights(\n  research_data: string,\n  competitive_context: string,\n  business_goals: string\n) -> AutoInsightsResponse {\n  client \"CustomGPT4o\"\n  prompt #\"\n    You are a senior product strategist and user research expert analyzing comprehensive user research data to generate executive-level insights and recommendations.\n\n    ## Research Data\n    {{ research_data }}\n\n    ## Competitive Context\n    {{ competitive_context }}\n\n    ## Business Goals\n    {{ business_goals }}\n\n    ## Your Task\n    Analyze this data to answer key executive questions:\n\n    1. **What are the top revenue-generating opportunities?**\n       - Identify opportunities with highest revenue potential\n       - Consider market size, willingness to pay, and competitive advantage\n       - Prioritize based on effort vs. impact\n\n    2. **What are the most critical pain points to solve?**\n       - Focus on high-impact, high-frequency pain points\n       - Consider emotional intensity and business impact\n       - Identify pain points that competitors aren't addressing\n\n    3. **Which personas offer the best revenue potential?**\n       - Analyze willingness to pay by persona\n       - Consider market size and accessibility\n       - Identify underserved segments\n\n    4. **What changes would benefit different personas most?**\n       - Persona-specific recommendations\n       - Consider journey stage and context\n       - Prioritize changes with broad appeal\n\n    5. **Given competitive pressures, what are the most profitable opportunities?**\n       - Consider competitive landscape\n       - Identify differentiation opportunities\n       - Focus on defensible advantages\n\n    ## Analysis Guidelines\n    - **Be Strategic**: Focus on business impact, not just user satisfaction\n    - **Be Specific**: Provide concrete, actionable recommendations\n    - **Be Evidence-Based**: Ground insights in actual user research data\n    - **Be Prioritized**: Rank opportunities by revenue potential and feasibility\n    - **Be Competitive**: Consider how to win against competitors\n\n    ## Action Button Guidelines\n    Create actionable buttons with these types:\n    - `create_opportunity`: Creates new opportunity with title and description\n    - `prioritize_insight`: Marks insight as high priority for follow-up\n    - `schedule_research`: Schedules additional research on specific topic\n    - `create_persona`: Creates new persona based on findings\n    - `tag_insights`: Tags related insights for better organization\n\n    Parameters should include relevant IDs, titles, descriptions, and metadata.\n\n    ## Output Requirements\n    - **Executive Summary**: 3-4 sentences highlighting the most important findings\n    - **Top Opportunities**: 3-5 opportunities ranked by revenue potential\n    - **Critical Insights**: 5-7 strategic insights with evidence and actions\n    - **Persona Analysis**: Detailed analysis of each key persona\n    - **Competitive Considerations**: Key threats and competitive responses needed\n    - **Immediate Actions**: Top 3 actions to take in the next 30 days\n    - **Strategic Recommendations**: Long-term strategic direction\n\n    Focus on insights that drive business value and competitive advantage.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test function for development\ntest GenerateAutoInsights_Sample {\n  functions [GenerateAutoInsights]\n  args {\n    research_data #\"\n      # Sample Research Data\n      ## Overview\n      - Total Insights: 45\n      - Total Interviews: 12\n      - Total People: 8\n      - Date Range: 2024-01-15 to 2024-03-20\n\n      ## Top Insights\n      ### Time Management Struggles (Category: User Experience)\n      - Pain: Users spend 2-3 hours daily on manual planning\n      - Desired Outcome: Automated planning that saves time\n      - Evidence: \"I waste so much time just figuring out what to do next\" (Interview #3)\n      - Impact: 5/5, Novelty: 3/5\n      - Personas: Busy Professional, Student\n\n      ### Lack of Progress Visibility (Category: Product)\n      - Pain: Users can't see long-term progress toward goals\n      - Desired Outcome: Clear progress tracking and milestones\n      - Evidence: \"I never know if I'm actually getting closer to my goals\" (Interview #7)\n      - Impact: 4/5, Novelty: 4/5\n      - Personas: Goal-Oriented Achiever\n\n      ## Personas\n      ### Busy Professional (60% of users)\n      - Top Pain Points: Time management, Context switching, Overwhelm\n      - Desired Outcomes: Efficiency, Focus, Work-life balance\n\n      ### Student (25% of users)\n      - Top Pain Points: Procrastination, Study planning, Motivation\n      - Desired Outcomes: Better grades, Reduced stress, Time for social life\n    \"#\n    competitive_context #\"\n      Key competitors include Notion, Todoist, and Asana. Most focus on task management but lack intelligent planning and progress visualization.\n    \"#\n    business_goals #\"\n      - Achieve $1M ARR within 18 months\n      - Build defensible AI-powered planning features\n      - Target productivity-focused professionals and students\n    \"#\n  }\n}\n",
  "auto_title.baml": "// Generate a concise, descriptive title from content\n\nfunction GenerateTitleFromContent(\n  content: string\n) -> string {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Generate a concise, descriptive title (2-5 words) for this content.\n\n    RULES:\n    - Title should capture the main topic or theme\n    - Use 2-5 words maximum\n    - Use title case\n    - Do NOT use generic titles like \"Interview\", \"Recording\", \"Conversation\", or \"Notes\"\n    - Do NOT include quotes, punctuation, or formatting\n    - If content is unclear or empty, respond with \"Untitled\"\n\n    {{ _.role(\"user\") }}\n    Content:\n    {{ content }}\n\n    {{ _.role(\"assistant\") }}\n  \"#\n}\n",
  "auto_title.tests.baml": "// Tests for GenerateTitleFromContent\n\n// ── Sales call transcript ────────────────────────────────────────────\ntest GenerateTitle_SalesCall {\n  functions [GenerateTitleFromContent]\n  args {\n    content #\"\n      Discussion about migrating from Looker to a self-serve analytics platform.\n      Key topics: pricing comparison, Snowflake integration requirements, timeline\n      for Q1 evaluation, and stakeholder sign-off process with CTO involvement.\n    \"#\n  }\n}\n\n// ── Technical discussion ─────────────────────────────────────────────\ntest GenerateTitle_TechDiscussion {\n  functions [GenerateTitleFromContent]\n  args {\n    content #\"\n      Deep dive into webhook retry logic and idempotency key edge cases.\n      Team decided on a two-day scoped fix for the retry path to unblock\n      the Q1 launch, with a follow-up tech debt ticket for full webhook\n      system refactoring.\n    \"#\n  }\n}\n\n// ── User research interview ──────────────────────────────────────────\ntest GenerateTitle_ResearchInterview {\n  functions [GenerateTitleFromContent]\n  args {\n    content #\"\n      Interview with high school tutor about challenges facing underserved\n      students in East Palo Alto. Discussion of limited worldview exposure,\n      mentorship programs pairing Stanford students with high schoolers,\n      and the importance of individualized education approaches for students\n      with different learning styles.\n    \"#\n  }\n}\n\n// ── Product feedback ─────────────────────────────────────────────────\ntest GenerateTitle_ProductFeedback {\n  functions [GenerateTitleFromContent]\n  args {\n    content #\"\n      Customer frustrated with export failures on enterprise plan. CSV exports\n      timing out silently due to 3x data growth. No error notifications sent.\n      Requesting root cause analysis before renewal evaluation completes.\n    \"#\n  }\n}\n\n// ── Empty content edge case ──────────────────────────────────────────\ntest GenerateTitle_EmptyContent {\n  functions [GenerateTitleFromContent]\n  args {\n    content \"\"\n  }\n}\n\n// ── Very short content ───────────────────────────────────────────────\ntest GenerateTitle_ShortContent {\n  functions [GenerateTitleFromContent]\n  args {\n    content \"Quick sync about the roadmap priorities for next sprint.\"\n  }\n}\n",
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPTo3 {\n  provider openai\n  options {\n    model \"o3\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPTo3Mini {\n  provider openai\n  options {\n    model \"o3-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n\n\n// Evidence extraction: fast model with fallback to heavier model on failure\nclient<llm> EvidenceExtractionFast {\n  provider fallback\n  options {\n    strategy [CustomGPT5Mini, CustomGPT4o]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between openai clients only\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
  "contextual_suggestions.baml": "// Enhanced contextual suggestions for project setup and interview questions\n// Provides real-time suggestions based on project context and user input\n// Supports both project goals setup and interview question generation\n\nclass ContextualSuggestions {\n  decision_questions string[] @description(\"Contextual decision that the user needs to make in order to best achieve their goal. \")\n  assumptions string[] @description(\"Relevant assumptions\")\n  unknowns string[] @description(\"Key research questions/unknowns and what must be learned to help make a decision.\")\n  organizations string[] @description(\"Target organization types\")\n  roles string[] @description(\"Target user roles\")\n  interview_questions string[] @description(\"Interview questions for specific categories\")\n}\n\nfunction GenerateContextualSuggestions(\n  research_goal: string,\n  current_input: string,\n  suggestion_type: string, // \"decision_questions\", \"assumptions\", \"unknowns\", \"organizations\", \"roles\", \"interview_questions\"\n  existing_items: string[],\n  rejected_items: string[],\n  project_context: string,\n  custom_instructions: string,\n  response_count: int,\n  question_category: string? // For interview questions: \"context\", \"pain\", \"workflow\", etc.\n) -> string[] {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher helping someone set up their research project and create interview questions.\n    Generate {{ response_count }} highly relevant, contextual suggestions for the {{ suggestion_type }} field.\n\n    PROJECT CONTEXT:\n    - Research Goal: {{ research_goal }}\n    - Current Input Being Typed: \"{{ current_input }}\"\n    - Exclude (already added or previously shown): {{ existing_items }}\n    - Rejected Items (avoid similar suggestions): {{ rejected_items }}\n    - Additional Context: {{ project_context }}\n    {% if custom_instructions %}- Custom Instructions: {{ custom_instructions }}{% endif %}\n    {% if question_category %}- Question Category: {{ question_category }}{% endif %}\n\n    CRITICAL REQUIREMENTS:\n    - Build upon the research goal and ESPECIALLY the current input (\"{{ current_input }}\") as the primary direction\n    - The current input should heavily influence the suggestions - expand on its theme and direction\n    - Avoid generating any suggestions similar to those in the exclude list: {{ existing_items }}\n    - Avoid generating suggestions similar to rejected items: {{ rejected_items }}\n    - Make suggestions specific to the research domain mentioned in the goal\n    - If current input exists, treat it as the primary context and build complementary suggestions\n    {% if custom_instructions %}- Follow the custom instructions: {{ custom_instructions }}{% endif %}\n\n    GENERATE SUGGESTIONS FOR: {{ suggestion_type }}\n\n    {% if suggestion_type == \"decision_questions\" %}\n   Generate specific, actionable decisions that the user could make to advance their business goal. Each decision should:\n\t\t- Directly influence product, marketing, or customer strategy\n\t\t- Be informed by customer behavior or insights\n\t\t- Lead to measurable outcomes that can validate success\n\t\t- Reduce uncertainty about what to build, whom to target, or how to position the product\n\n    Format examples:\n\t\t- \"Prioritize building automated cash-flow projections over manual expense tracking\"\n\t\t- \"Focus on milestone-based progress tracking instead of daily streaks\"\n\t\t- \"Gate collaboration tools behind premium plans instead of storage limits\"\n\t\t- \"Launch a loyalty program rewarding clients for re-booking the same freelancer\"\n    {% endif %}\n\n    {% if suggestion_type == \"assumptions\" %}\n    Generate testable assumptions that are core beliefs driving this research. Focus on:\n    - Specific customer behavior patterns you believe to be true\n    - Market conditions or competitive dynamics you're assuming\n    - Product/feature beliefs that influence your roadmap\n    - Business model assumptions that affect strategy\n\n    Make them concrete and testable. Format examples:\n    - \"Customers value outcome X more than feature Y\"\n    - \"Users abandon the product primarily due to onboarding friction\"\n    - \"Price sensitivity decreases once customers see clear ROI\"\n    - \"Our target market prefers self-service over human support\"\n    {% endif %}\n\n    {% if suggestion_type == \"unknowns\" %}\n    Generate research questions that are critical unknowns that create uncertainty in decision-making. Focus on:\n    - Knowledge gaps that could dramatically change your strategy if filled\n\t\t- Customer context, goals, friction and pain points that could influence the user's decision\n    - Customer behavior patterns that you're unsure about\n    - Market dynamics that could affect adoption or success\n    - Competitive threats or advantages that remain unclear\n\n    Frame as specific uncertainties. Format examples:\n    - \"Customer willingness to pay for premium features\"\n    - \"Which competitor features drive the most switching\"\n    - \"How much friction customers will tolerate before churning\"\n    - \"Whether our value prop resonates with mid-market vs enterprise\"\n    {% endif %}\n\n    {% if suggestion_type == \"organizations\" %}\n    Generate specific organization types that would be ideal participants for this research. Focus on:\n    - Company sizes, stages, and revenue ranges that match your target market\n    - Industry verticals where your research goal is most relevant\n    - Business models that align with what you're trying to learn\n    - Market segments that face the problems you're investigating\n\n    Be specific about characteristics. Format examples:\n    - \"Series A B2B SaaS companies (50-200 employees)\"\n    - \"Ecommerce brands with $1M-10M annual revenue\"\n    - \"Digital marketing agencies serving SMB clients\"\n    - \"Healthcare startups in regulatory-heavy markets\"\n    {% endif %}\n\n    {% if suggestion_type == \"roles\" %}\n    Generate specific user roles that would provide the most valuable insights for this research. Focus on:\n    - Decision makers who influence purchasing or adoption decisions\n    - End users who directly experience the problems you're researching\n    - Stakeholders who would be affected by potential solutions\n    - Roles that span different levels (individual contributors, managers, executives)\n\n    Include seniority and functional context. Format examples:\n    - \"VP of Product (50-500 person companies)\"\n    - \"Customer Success Manager at SaaS companies\"\n    - \"Marketing Operations Director\"\n    - \"Small business owner (solo or 2-10 employees)\"\n    {% endif %}\n\n    {% if suggestion_type == \"interview_questions\" %}\n    Generate specific, well-crafted interview questions{% if question_category %} for the {{ question_category }} category{% endif %}. Focus on:\n    - Open-ended questions that encourage detailed responses\n    - Questions that align with the research goal and current input direction\n    - Questions that would provide actionable insights\n    - Questions appropriate for the specified category context\n    {% if question_category == \"context\" %}- Background and situational questions{% endif %}\n    {% if question_category == \"pain\" %}- Questions about problems, frustrations, and challenges{% endif %}\n    {% if question_category == \"workflow\" %}- Questions about processes, behaviors, and current methods{% endif %}\n    {% if question_category == \"goals\" %}- Questions about objectives, desired outcomes, and motivations{% endif %}\n    {% if question_category == \"constraints\" %}- Questions about limitations, barriers, and restrictions{% endif %}\n    {% if question_category == \"willingness\" %}- Questions about pricing, value perception, and purchase decisions{% endif %}\n    {% if question_category == \"demographics\" %}- Questions about background, role, and organizational context{% endif %}\n\n    Format examples:\n    - \"Can you walk me through how you currently [process/task]?\"\n    - \"What's the biggest challenge you face when [context]?\"\n    - \"Tell me about a time when [situation] didn't go as planned.\"\n    - \"How do you decide whether to [decision/action]?\"\n    {% endif %}\n\n    REQUIREMENTS:\n    - Generate exactly {{ response_count }} suggestions\n    - Each suggestion should be 4-25 words (interview questions can be slightly longer)\n    - Avoid duplicating any in exclude list: {{ existing_items }}\n    - Avoid suggestions similar to rejected items: {{ rejected_items }}\n    - Be specific and actionable, not generic\n    - Directly relate to the research goal and current input context\n    - Use clear, professional language that a researcher would understand\n    - PRIORITIZE building upon the current input (\"{{ current_input }}\") as the main direction\n    {% if custom_instructions %}- Follow custom instructions: {{ custom_instructions }}{% endif %}\n\n    Return only a JSON array of exactly {{ response_count }} strings, like: [\"suggestion 1\", \"suggestion 2\", \"suggestion 3\"]\n  \"#\n}\n",
  "contextual_suggestions.tests.baml": "// Tests for GenerateContextualSuggestions\n\ntest GenerateContextualSuggestions_DecisionQuestions_SaaS {\n  functions [GenerateContextualSuggestions]\n  args {\n    research_goal \"Increase trial-to-paid conversion for a B2B SaaS analytics product\"\n    current_input \"Users drop off after connecting their first data source\"\n    suggestion_type \"decision_questions\"\n    existing_items [\"What blocks teams from completing setup?\", \"Which roles influence purchase?\"]\n    rejected_items []\n    project_context \"SMB teams evaluating analytics tools; 14-day trials; self-serve onboarding\"\n    custom_instructions \"\"\n    response_count 5\n  }\n}\n\ntest GenerateContextualSuggestions_Roles_Healthcare {\n  functions [GenerateContextualSuggestions]\n  args {\n    research_goal \"Improve patient intake and follow-up in outpatient clinics\"\n    current_input \"Confusion around discharge instructions and next steps\"\n    suggestion_type \"roles\"\n    existing_items [\"Front-desk staff\", \"Primary-care physicians\"]\n    rejected_items []\n    project_context \"Regional nonprofit hospital network; 6 clinics; chronic care programs for diabetes and hypertension\"\n    custom_instructions \"\"\n    response_count 5\n  }\n}\n",
  "conversation_analysis.baml": "// Standalone conversation analyzer schema\n\nclass ConversationQuestion {\n  question string\n  asked_by string?\n  intent string?\n  evidence_snippet string?\n  confidence float\n}\n\nclass ParticipantGoal {\n  speaker string?\n  goal string\n  evidence_snippet string?\n  confidence float\n}\n\nclass ConversationTakeaway {\n  priority \"high\" | \"medium\" | \"low\"\n  summary string\n  evidence_snippets string[]\n}\n\nclass ConversationRecommendation {\n  focus_area string\n  action string\n  rationale string\n}\n\nclass ConversationAnalysis {\n  overview string\n  duration_estimate string?\n  questions ConversationQuestion[]\n  participant_goals ParticipantGoal[]\n  key_takeaways ConversationTakeaway[]\n  open_questions string[]\n  recommended_next_steps ConversationRecommendation[]\n}\n\nfunction AnalyzeStandaloneConversation(\n  transcript: string,\n  context: string\n) -> ConversationAnalysis {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert conversation analyst helping revenue teams understand standalone call recordings.\n\n    Transcript:\n    {{ transcript }}\n\n    Context (may be empty):\n    {{ context }}\n\n    Produce a structured analysis that:\n      1. Identifies the explicit questions asked, who asked them, and the underlying intent.\n      2. Infers each participant's goals or objectives from their statements.\n      3. Summarizes the key takeaways that matter for sales or discovery follow-up, citing short evidence snippets.\n      4. Highlights open questions or missing information that should be resolved next.\n      5. Recommends next steps that keep the deal or relationship moving forward.\n\n    Requirements:\n      - Keep evidence snippets under 200 characters. Use exact quotes when possible.\n      - Confidence scores must be between 0 and 1.\n      - Never hallucinate participants not present in the transcript.\n      - If intent or speaker cannot be determined, leave the optional fields null.\n      - Maintain a concise but actionable overview paragraph for executives.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "conversation_analysis.tests.baml": "// Tests for AnalyzeStandaloneConversation\n\n// ── Sales discovery call ─────────────────────────────────────────────\ntest AnalyzeConversation_SalesDiscovery {\n  functions [AnalyzeStandaloneConversation]\n  args {\n    transcript #\"\n      Sarah (Sales Rep) [0:00]: Hi Mike, thanks for hopping on. I wanted to learn more about your team's analytics workflow.\n      Mike (VP Engineering) [0:08]: Sure. We've been using Looker for about two years but honestly it's become a bottleneck. Only a few people on the team can actually build reports.\n      Sarah [0:18]: What happens when someone needs a new report?\n      Mike [0:22]: They file a ticket with our data team. Average turnaround is about a week. For urgent stuff we can do two days but it creates a lot of stress.\n      Sarah [0:35]: How does that impact your decision-making?\n      Mike [0:40]: We end up making gut calls more than I'd like. Last quarter we launched a feature based on assumptions and it flopped. If we'd had the usage data faster we would have caught it.\n      Sarah [0:55]: What would an ideal solution look like for you?\n      Mike [1:02]: Self-serve dashboards that my PMs can build themselves. No SQL required. And it needs to integrate with our Snowflake warehouse.\n      Sarah [1:15]: Makes sense. What's your timeline for making a change?\n      Mike [1:20]: Our Looker contract renews in March. I'd want to have something in place by February so we can run both in parallel for a month.\n      Sarah [1:30]: Who else would need to be involved in the evaluation?\n      Mike [1:35]: Our CTO has final sign-off. And I'd want our lead PM to test it since she'd be the heaviest user.\n    \"#\n    context \"B2B SaaS analytics platform sales call. Prospect is evaluating alternatives to Looker.\"\n  }\n}\n\n// ── Customer support escalation ──────────────────────────────────────\ntest AnalyzeConversation_SupportEscalation {\n  functions [AnalyzeStandaloneConversation]\n  args {\n    transcript #\"\n      Agent [0:00]: Hi, this is Lisa from the enterprise support team. I understand you're having issues with your data exports?\n      Customer [0:06]: Yes, this is the third time this month our scheduled CSV exports have failed silently. No error notification, nothing. We only find out when finance asks where the report is.\n      Agent [0:18]: I'm sorry about that. Can you tell me which export jobs are affected?\n      Customer [0:22]: The daily revenue reconciliation and the weekly churn report. Both feed into our board deck. Our CFO is furious.\n      Agent [0:32]: I see those jobs in our system. It looks like they're timing out due to the data volume increase. Your dataset has grown 3x since you set these up.\n      Customer [0:42]: OK but why no error notification? We're paying for enterprise specifically for reliability guarantees.\n      Agent [0:50]: You're right, the silent failure is a bug on our side. I'm going to escalate this to engineering as a P1. In the meantime, I can set up a workaround with smaller batch sizes.\n      Customer [1:00]: Fine, but I need a root cause analysis by end of week. We're in our renewal evaluation right now and this isn't helping.\n    \"#\n    context \"Enterprise customer support escalation. Customer on annual enterprise plan, renewal coming up.\"\n  }\n}\n\n// ── Research interview with empty context ────────────────────────────\ntest AnalyzeConversation_ResearchInterview {\n  functions [AnalyzeStandaloneConversation]\n  args {\n    transcript #\"\n      Interviewer [0:00]: Tell me about the last time you tried to learn a new skill online.\n      Participant [0:05]: I tried learning Python last month. I signed up for three different platforms — Codecademy, Coursera, and YouTube tutorials. I kept bouncing between them because none of them felt right.\n      Interviewer [0:18]: What do you mean by \"felt right\"?\n      Participant [0:22]: Each one assumed a different starting point. Codecademy was too basic, Coursera lectures were too theoretical, and YouTube was all over the place. I wanted something that met me where I was — I know some JavaScript so I'm not a total beginner, but I'm not ready for advanced Python either.\n      Interviewer [0:40]: How did that make you feel?\n      Participant [0:43]: Frustrated honestly. I have maybe 30 minutes a day to learn and I was spending half of it figuring out which lesson to do next instead of actually coding. After two weeks I just gave up.\n      Interviewer [0:55]: If you could design the perfect learning experience, what would it look like?\n      Participant [1:00]: Something that asks me what I already know, gives me a quick assessment, and then builds a path from there. And it would track what I've actually retained, not just what videos I watched.\n    \"#\n    context \"\"\n  }\n}\n\n// ── Internal team meeting ────────────────────────────────────────────\ntest AnalyzeConversation_InternalMeeting {\n  functions [AnalyzeStandaloneConversation]\n  args {\n    transcript #\"\n      PM [0:00]: OK let's review where we are on the Q1 launch. Engineering, what's the status?\n      Eng Lead [0:05]: Auth migration is done. API rate limiting ships tomorrow. The only blocker is the webhook retry logic — we found an edge case with idempotency keys.\n      PM [0:15]: How long to fix?\n      Eng Lead [0:18]: Two days if we scope it to just the retry path. A week if we want to refactor the whole webhook system.\n      PM [0:25]: Let's do the two-day fix for launch and file a tech debt ticket for the refactor. Design, where are we?\n      Designer [0:32]: Dashboard redesign is in final review. One open question — do we show the usage graph on the free tier or gate it?\n      PM [0:40]: Good question. Let's gate it. It's one of our best upgrade drivers. Marketing, anything?\n      Marketing [0:47]: Launch blog post is drafted. We need screenshots of the new dashboard and a quote from the beta customer. Can we get those by Thursday?\n      PM [0:55]: I'll get the screenshots. Eng lead, can you ping the beta customer for a quote?\n      Eng Lead [1:00]: Sure, I'll reach out to the Acme team today.\n    \"#\n    context \"Weekly product launch standup for Q1 release. Cross-functional team.\"\n  }\n}\n",
  "conversation_takeaways.baml": "// High-level conversation value assessment across all lenses\n\nclass ConversationEvidence {\n  id string @description(\"Evidence UUID for linking back\")\n  verbatim string @description(\"Exact quote from the conversation\")\n  gist string? @description(\"AI-generated summary of the evidence\")\n  speaker string? @description(\"Who said this\")\n  evidence_type string? @description(\"Type of evidence: pain_point, desire, commitment, etc.\")\n  timestamp_start float? @description(\"When this was said in the conversation (seconds)\")\n}\n\nclass ConversationTakeaways {\n  value_synopsis string @description(\"2-3 bullet-style fragments on conversation value. Lead with specifics; zero corporate fluff.\")\n  critical_next_step string @description(\"1 punchy bullet with the single most important next step or caution; concrete owner/time/cue when possible.\")\n  future_improvement string @description(\"1 punchy bullet on what to do (differently) in future; tactical, not generic.\")\n  supporting_evidence_ids string[] @description(\"IDs of evidence items that most strongly support these takeaways\")\n}\n\nfunction ExtractConversationTakeaways(\n  evidence: ConversationEvidence[],\n  bant_summary: string?,\n  meddic_summary: string?,\n  stakeholders_summary: string?,\n  duration_minutes: int?,\n  custom_instructions: string?\n) -> ConversationTakeaways {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing this conversation to assess its value and identify next steps.\n\n    Interview Duration: {{ duration_minutes }} minutes\n    Evidence Items: {{ evidence | length }}\n\n    ## Evidence from Conversation\n    {% for item in evidence %}\n    ---\n    {% if item.speaker %}Speaker: {{ item.speaker }}{% endif %}\n    {% if item.evidence_type %}Type: {{ item.evidence_type }}{% endif %}\n\n    Quote: \"{{ item.verbatim }}\"\n    {% if item.gist %}Summary: {{ item.gist }}{% endif %}\n    {% endfor %}\n\n    {% if bant_summary %}\n    ## BANT/GPCT Analysis\n    {{ bant_summary }}\n    {% endif %}\n\n    {% if meddic_summary %}\n    ## MEDDIC Analysis\n    {{ meddic_summary }}\n    {% endif %}\n\n    {% if stakeholders_summary %}\n    ## Stakeholders Identified\n    {{ stakeholders_summary }}\n    {% endif %}\n\n    ## Task\n    {% if custom_instructions %}\n    **IMPORTANT: Custom analysis instructions have been provided. Follow these instructions while still returning the required JSON structure:**\n\n    {{ custom_instructions }}\n\n    You MUST still return valid JSON with the required fields below, but adapt the content, tone, language, and focus according to the custom instructions above.\n    {% endif %}\n\n    Provide a practical business assessment with sharp, scannable phrasing. Style rules:\n    - No corporate filler or soft adjectives; use plain, tactical language.\n    - Use dash bullets only (\"- ...\"). Do NOT add labels like \"Value:\", \"Next:\", or \"Improve:\".\n    - Keep each fragment under ~20 words and call out concrete topics, decisions, or blockers.\n    - Do NOT cite, reference, or allude to evidence items by ID, number, hash, code, or timestamp.\n    - Do NOT write \"see quote #\" / \"evidence #\" / \"ID\" / \"(ref: ...)\" or anything citation-like.\n\n    Return JSON with these fields:\n\n    {\n      \"value_synopsis\": \"- <2-3 terse bullets/lines on what mattered (topics/decisions/blockers), no fluff>\",\n      \"critical_next_step\": \"- <single decisive action with owner or timing if known>\",\n      \"future_improvement\": \"- <single change to make the next call stronger>\",\n      \"supporting_evidence_ids\": []\n    }\n\n    Write in clear, practical business language. Reference what was discussed, not evidence identifiers.\n  \"#\n}\n",
  "conversation_takeaways.tests.baml": "// Tests for ExtractConversationTakeaways\n\n// ── Sales call with BANT context ─────────────────────────────────────\ntest ConversationTakeaways_SalesWithBANT {\n  functions [ExtractConversationTakeaways]\n  args {\n    evidence [\n      {\n        id \"ev-001\"\n        verbatim \"We're paying 120k a year for Looker but only 10 out of 30 seats are active.\"\n        gist \"High spend on underutilized analytics tool\"\n        speaker \"Mike, VP Engineering\"\n        evidence_type \"pain_point\"\n        timestamp_start 22.5\n      },\n      {\n        id \"ev-002\"\n        verbatim \"Our Looker contract renews in March. I'd want something in place by February.\"\n        gist \"Hard deadline for switching analytics tools\"\n        speaker \"Mike, VP Engineering\"\n        evidence_type \"commitment\"\n        timestamp_start 80.0\n      },\n      {\n        id \"ev-003\"\n        verbatim \"Our CTO has final sign-off. And I'd want our lead PM to test it.\"\n        gist \"Two additional stakeholders needed for decision\"\n        speaker \"Mike, VP Engineering\"\n        evidence_type \"commitment\"\n        timestamp_start 95.0\n      },\n      {\n        id \"ev-004\"\n        verbatim \"We end up making gut calls more than I'd like. Last quarter we launched a feature based on assumptions and it flopped.\"\n        gist \"Lack of data access leading to poor product decisions\"\n        speaker \"Mike, VP Engineering\"\n        evidence_type \"pain_point\"\n        timestamp_start 40.0\n      }\n    ]\n    bant_summary \"Budget: 120k/year current spend. Authority: VP Eng (champion), CTO (decision maker). Need: Self-serve dashboards, Snowflake integration. Timeline: Feb deadline, March renewal.\"\n    meddic_summary null\n    stakeholders_summary \"Mike (VP Engineering) - Champion. CTO - Economic buyer. Lead PM - End user evaluator.\"\n    duration_minutes 12\n    custom_instructions null\n  }\n}\n\n// ── Support escalation (no sales context) ────────────────────────────\ntest ConversationTakeaways_SupportEscalation {\n  functions [ExtractConversationTakeaways]\n  args {\n    evidence [\n      {\n        id \"ev-010\"\n        verbatim \"This is the third time this month our scheduled CSV exports have failed silently.\"\n        gist \"Recurring silent export failures\"\n        speaker \"Customer\"\n        evidence_type \"pain_point\"\n        timestamp_start 6.0\n      },\n      {\n        id \"ev-011\"\n        verbatim \"Our CFO is furious.\"\n        gist \"Executive-level frustration with reliability\"\n        speaker \"Customer\"\n        evidence_type \"pain_point\"\n        timestamp_start 28.0\n      },\n      {\n        id \"ev-012\"\n        verbatim \"We're in our renewal evaluation right now and this isn't helping.\"\n        gist \"Churn risk tied to reliability issues\"\n        speaker \"Customer\"\n        evidence_type \"commitment\"\n        timestamp_start 62.0\n      },\n      {\n        id \"ev-013\"\n        verbatim \"Your dataset has grown 3x since you set these up.\"\n        gist \"Root cause: data volume outgrew export config\"\n        speaker \"Agent\"\n        evidence_type \"desire\"\n        timestamp_start 38.0\n      }\n    ]\n    bant_summary null\n    meddic_summary null\n    stakeholders_summary null\n    duration_minutes 8\n    custom_instructions null\n  }\n}\n\n// ── Research interview with custom instructions ──────────────────────\ntest ConversationTakeaways_ResearchWithCustom {\n  functions [ExtractConversationTakeaways]\n  args {\n    evidence [\n      {\n        id \"ev-020\"\n        verbatim \"I signed up for three different platforms and kept bouncing between them because none felt right.\"\n        gist \"Platform fatigue from mismatched skill levels\"\n        speaker \"Participant\"\n        evidence_type \"pain_point\"\n        timestamp_start 5.0\n      },\n      {\n        id \"ev-021\"\n        verbatim \"I have maybe 30 minutes a day to learn and I was spending half figuring out which lesson to do next.\"\n        gist \"Time wasted on navigation instead of learning\"\n        speaker \"Participant\"\n        evidence_type \"pain_point\"\n        timestamp_start 43.0\n      },\n      {\n        id \"ev-022\"\n        verbatim \"Something that asks me what I already know, gives me a quick assessment, and builds a path from there.\"\n        gist \"Desire for adaptive skill assessment and personalized paths\"\n        speaker \"Participant\"\n        evidence_type \"desire\"\n        timestamp_start 60.0\n      }\n    ]\n    bant_summary null\n    meddic_summary null\n    stakeholders_summary null\n    duration_minutes 15\n    custom_instructions \"Focus on learning experience design implications. What does this tell us about our onboarding flow?\"\n  }\n}\n\n// ── Minimal evidence (edge case) ─────────────────────────────────────\ntest ConversationTakeaways_MinimalEvidence {\n  functions [ExtractConversationTakeaways]\n  args {\n    evidence [\n      {\n        id \"ev-030\"\n        verbatim \"We need this fixed by Friday.\"\n        gist \"Urgent timeline\"\n        speaker \"Customer\"\n        evidence_type \"commitment\"\n        timestamp_start 10.0\n      }\n    ]\n    bant_summary null\n    meddic_summary null\n    stakeholders_summary null\n    duration_minutes 3\n    custom_instructions null\n  }\n}\n",
  "derive_persona_facets.baml": "// Derive Persona Facets BAML Schema and Function\n// Phase 2: Synthesizes enduring persona traits from raw evidence\n\nclass PersonaFacet {\n  person_key string @description(\"Reference to person from extraction\")\n  kind_slug string @description(\"One: motivation | value | attitude | skill | preference | personality | identity | belief | habit | constraint\")\n  value string @description(\"≤12 words; enduring trait phrasing. E.g., 'values autonomy in work', 'prefers visual learning over text', 'motivated by social impact'\")\n  evidence_refs int[] @description(\"List of FacetMention.index values supporting this trait\")\n  confidence float @description(\"0-1; based on frequency, consistency, and salience\")\n  frequency int @description(\"Number of distinct supporting mentions\")\n  reasoning string? @description(\"≤20 words explaining why this is an enduring trait vs situational\")\n}\n\nclass PersonaExtraction {\n  persona_facets PersonaFacet[] @description(\"Enduring traits for each person\")\n  summary string? @description(\"1-2 sentence synthesis of persona patterns across all participants\")\n}\n\nfunction DerivePersonaFacetsFromEvidence(\n  extraction: Extraction\n) -> PersonaExtraction {\n  client \"CustomGPT5\"\n  prompt #\"\nYou are a research analyst synthesizing persona insights from structured evidence.\n\n## Task\nGiven evidence turns and facet mentions, infer **significant and enduring persona facets** for each participant.\n\n## Steps\n1. **Group by person**: Cluster all FacetMention items by `person_key`. Validate that each `person_key` matches one of the `extraction.people[*].person_key`. Ignore mentions whose key is missing or not in the roster.\n2. **Identify patterns**: Look for recurring themes, consistent attitudes, stated values, behavioral habits. Track how traits shift (or stay stable) across different job scenarios, roles, or environments called out in the interview.\n3. **Promote to traits**: Elevate mentions that reflect significant choices, preferences and values or that reveal stable characteristics (not one-off comments or interview topics).\n4. **Merge similar**: Combine semantically similar mentions into a single PersonaFacet with multiple evidence_refs.\n5. **Filter noise**: Skip generic interview content (topics discussed but not personal traits). Only keep facets that explain why they act the way they do across contexts.\n6. **Capture purchase intent**: When participants discuss products/services, extract facets that encode their evaluation criteria, willingness-to-pay thresholds, or decision triggers.\n\n\n## PersonaFacet Criteria\nEach `PersonaFacet.value` must be:\n- **Enduring**: Represents a stable trait, not momentary state\n- **Personal**: Describes the person, not just interview content\n- **Meaningful**: Highlights a differentiated choice, tension, willingness-to-pay stance, or value (skip generic attributes everyone would share)\n- **Specific**: Concrete phrasing with subject+predicate (e.g., \"prefers async communication for focus\")\n- **Evidence-backed**: Supported by at least 1 FacetMention (ideally 2+)\n\n## kind_slug Guide\n- **motivation**: What drives them (e.g., \"motivated by learning new skills\")\n- **value**: What they believe matters (e.g., \"values work-life balance\")\n- **attitude**: How they view things (e.g., \"skeptical of AI accuracy\")\n- **skill**: What they're good at (e.g., \"proficient in visual design\")\n- **preference**: How they like to work (e.g., \"prefers written documentation\")\n- **personality**: Behavioral tendencies (e.g., \"introverted in large groups\")\n- **identity**: Self-concept (e.g., \"identifies as generalist designer\")\n- **belief**: Worldview elements (e.g., \"believes design should serve society\")\n- **habit**: Regular behaviors (e.g., \"reviews notes daily before class\")\n- **constraint**: Limitations (e.g., \"limited by budget for tools\")\n\n## Evidence\n{{ extraction }}\n\n## Guardrails\n- Each `evidence_refs` array must contain valid `FacetMention.index` values from the input.\n- Never merge mentions from different people; keep persona facets scoped to one `person_key`. If multiple people share the same behavior, create separate facets referencing their respective evidence.\n- `confidence` should reflect: frequency (more mentions = higher), consistency (contradictions lower it), salience (strong emotional/attitudinal signal).\n- Do NOT create facets for interview topics unless they reveal a personal stance/value/habit.\n- When merging mentions, combine `evidence_refs` arrays.\n- Prefer 3-10 high-quality facets per person over 50+ low-signal ones.\n\nOutput ONLY valid JSON conforming to {{ ctx.output_format }}.\n\"#\n}\n\n// Test with sample extraction\ntest DerivePersonaFacets_Sample {\n  functions [DerivePersonaFacetsFromEvidence]\n  args {\n    extraction {\n      people [\n        {\n          person_key: \"participant-1\"\n          display_name: \"SPEAKER 2\"\n          inferred_name: \"Kai\"\n          role: \"participant\"\n        }\n      ]\n      evidence [\n        {\n          index: 0\n          person_key: \"participant-1\"\n          gist: \"Uses AI daily for essay writing\"\n          chunk: \"I use AI majority of the time when working through essays to help connect ideas together and format properly.\"\n          verbatim: \"I use AI majority of the time\"\n          anchors: {\n            speaker_label: \"SPEAKER 2\"\n            start_ms: 0\n            end_ms: 5000\n          }\n          facet_mentions [\n            {\n              person_key: \"participant-1\"\n              kind_slug: \"tool\"\n              value: \"uses AI for essay writing and formatting\"\n            }\n          ]\n        },\n        {\n          index: 1\n          person_key: \"participant-1\"\n          gist: \"Prefers working solo over groups\"\n          chunk: \"I think personally I work better when I'm alone.\"\n          verbatim: \"I work better when I'm alone\"\n          anchors: {\n            speaker_label: \"SPEAKER 2\"\n            start_ms: 6000\n            end_ms: 10000\n          }\n          facet_mentions [\n            {\n              person_key: \"participant-1\"\n              kind_slug: \"preference\"\n              value: \"prefers solo work over group work\"\n            }\n          ]\n        }\n      ]\n      facet_mentions [\n        {\n          person_key: \"participant-1\"\n          kind_slug: \"tool\"\n          value: \"uses AI for essay writing and formatting\"\n          quote: \"I use AI majority of the time\"\n        },\n        {\n          person_key: \"participant-1\"\n          kind_slug: \"behavior\"\n          value: \"uses AI majority of time for academic work\"\n          quote: \"working through essays\"\n        },\n        {\n          person_key: \"participant-1\"\n          kind_slug: \"preference\"\n          value: \"prefers solo work over group work\"\n          quote: \"I work better when I'm alone\"\n        },\n        {\n          person_key: \"participant-1\"\n          kind_slug: \"value\"\n          value: \"values working independently\"\n          quote: \"I think personally I work better\"\n        }\n      ]\n      scenes []\n      interaction_context: Research\n      context_confidence: 0.9\n      context_reasoning: \"User interview about study habits and AI tool usage with a college student\"\n    }\n  }\n}\n",
  "extract_evidence.baml": "// ============================================================================\n// Extract Evidence - Primary BAML Schema and Function\n// ============================================================================\n// Produces normalized evidence units from transcripts with timestamp anchors\n// for precise media playback and auditability.\n//\n// Previous version (extract_evidence.baml with string-based Anchor class) has\n// been deprecated in favor of this integer-based millisecond approach.\n// ============================================================================\n\n// === TurnAnchors: Standardized anchor format for transcript evidence ===\n// Uses integer milliseconds for direct video/audio seeking\nclass TurnAnchors {\n  start_ms int? @description(\"CRITICAL: Start time in milliseconds. Extract from transcript timestamps or chapter data. This is REQUIRED for video playback.\")\n  end_ms int? @description(\"End time in milliseconds when available\")\n  chapter_title string? @description(\"Optional chapter/section title\")\n  char_span int[]? @description(\"Optional [start,end] character offsets in transcript\")\n}\n\nclass EvidenceTurn {\n  person_key string @description(\"REQUIRED: Exact match to Person.person_key (e.g., 'participant-1', 'interviewer-1'). Must reference a person defined in the people array.\")\n  speaker_label string? @description(\"Literal transcript speaker label, e.g., 'SPEAKER A', 'Speaker B' or the provided diarization name\")\n  gist string @description(\"≤12-word essence of the turn; slide-like headline\")\n  chunk string @description(\"2–5 sentences capturing the person's full thought\")\n  verbatim string @description(\"≤15-word exact quote/snippet from the chunk\")\n  anchors TurnAnchors @description(\"Anchors to source for auditability\")\n  // confidence string @description(\"low | medium | high\")\n  why_it_matters string? @description(\"≤10 words on consequence/importance (e.g., trigger/impact; note if generalizable)\")\n\tfacet_mentions FacetMention[] @description(\"Facet mentions that appear in this turn\")\n  isQuestion bool? @description(\"TRUE if this turn contains a question (any speaker). Useful for filtering question-response patterns.\")\n  // Empathy maps (says/does/thinks/feels/pains/gains) removed from extraction pass for performance.\n  // Reimplemented as paid-tier feature derived from facet_mentions. See bead Insights-vpws.\n}\n\nclass FacetMention {\n  // index int @description(\"0-based index within the stream for ordering\")\n  // parent_index int @description(\"Index of the EvidenceTurn this mention derives from\")\n  person_key string @description(\"REQUIRED: Exact match to Person.person_key. Must match the person_key of the parent EvidenceTurn.\")\n  kind_slug string @description(\"One: goal | pain | behavior | tool | value | requirements | preference | demographic | context | artifact | emotion | workflow | feature\")\n  value string @description(\"CRITICAL: Human-readable descriptive text (≤12 words), NOT an ID or reference number. Examples: 'Healthcare Professional', 'prefers explicit topic mapping for workflow', 'requires calendar integration to schedule study'. NEVER use formats like 'ID:123' or numeric references. Prefer verb+object or noun+modifier. Include trigger/condition and objective when helpful.\")\n  quote string? @description(\"Optional ≤15-word supporting quote from the parent turn\")\n  // confidence float? @description(\"Discrete buckets recommended: 1, 0.75, 0.5, 0.25, 0\")\n}\n\nclass Scene {\n  scene_id string @description(\"Stable id for the scene/segment\")\n  start_index int @description(\"First EvidenceTurn index in the scene\")\n  end_index int @description(\"Last EvidenceTurn index in the scene\")\n  topic string @description(\"Short topic label for the scene\")\n  summary string? @description(\"1–2 sentence summary of what the scene covers\")\n}\n\nclass Person {\n  person_key string @description(\"REQUIRED: Deterministic slug like 'participant-1', 'participant-2', 'interviewer-1'. Number based on first appearance order. This MUST be used consistently in all EvidenceTurn and FacetMention references.\")\n  speaker_label string? @description(\"Literal transcript speaker label, e.g., 'SPEAKER A', 'Speaker B' or the provided diarization name\")\n\tperson_name string? @description(\"The person's common name, like John Smith, Sally A., etc.\")\n\tinferred_name string? @description(\"Preferred name if confidently inferred from context\")\n\trole string? @description(\"their role in the coversation (participant | interviewer | observer | moderator | customer | Sales Rep\")\n}\n\n// === Interaction Context: What kind of conversation is this? ===\n// LLM-determined classification for automatic lens selection\nenum InteractionContext {\n  Research @description(\"User research, customer discovery, interviews - exploring user needs and behaviors\")\n  Sales @description(\"Sales calls, demos, deal discussions, objection handling - revenue-focused conversations\")\n  Support @description(\"Support conversations, escalations, customer success check-ins - helping existing customers\")\n  Internal @description(\"Team meetings, internal debriefs, planning sessions - no external participants\")\n  Debrief @description(\"Voice memos, call recaps, field notes - quick capture of thoughts, decisions, and action items\")\n  Personal @description(\"Personal content, vlogs, non-business recordings - content about personal life or experiences\")\n}\n\nclass Extraction {\n\t//  people EvidenceParticipant[]\n\t people Person[]\n\t evidence EvidenceTurn[] @description(\"Chronological stream of evidence turns\")\n\t facet_mentions FacetMention[] @description(\"Flattened array of all facet mentions for easier phase-2 processing\")\n\t scenes Scene[]\n\n\t // LLM-determined interaction context for automatic lens selection\n\t interaction_context InteractionContext @description(\"What kind of conversation is this? Used for automatic lens selection.\")\n\t context_confidence float @description(\"0.0-1.0 confidence in the interaction_context classification\")\n\t context_reasoning string @description(\"Brief 1-2 sentence explanation of why this context was chosen\")\n}\n\nclass SpeakerUtterance {\n  speaker string @description(\"Speaker label like 'SPEAKER A', 'SPEAKER B'\")\n  text string @description(\"The utterance text\")\n  start int? @description(\"Start time in milliseconds\")\n  end int? @description(\"End time in milliseconds\")\n}\n\n// === Shared Support Classes ===\n\nclass Chapter {\n  start_ms int @description(\"Chapter start time in milliseconds\")\n  end_ms int? @description(\"Chapter end time in milliseconds (optional)\")\n  summary string? @description(\"Brief summary of this chapter/section\")\n  title string? @description(\"Chapter or section title\")\n}\n\nclass FacetCatalogKind {\n  slug string @description(\"Kind identifier, e.g., goal | pain | task | tool | value\")\n  label string @description(\"Display label for the kind\")\n}\n\nclass FacetCatalogEntry {\n  facet_account_id int @description(\"Facet account ID (primary key from facet_account table)\")\n  kind_slug string @description(\"Kind slug this facet belongs to\")\n  label string @description(\"Preferred display label\")\n  alias string? @description(\"Project-level alias to show instead of label when present\")\n  synonyms string[]? @description(\"Known synonyms and aliases\")\n}\n\nclass FacetCatalog {\n  kinds FacetCatalogKind[] @description(\"Merged catalog of facet kinds (project ▶ account ▶ global)\")\n  facets FacetCatalogEntry[] @description(\"Merged facet entries available to this project\")\n  version string @description(\"Opaque version string for caching and diffing\")\n}\n\nfunction ExtractEvidenceFromTranscriptV2(\n  speaker_transcripts: SpeakerUtterance[],\n  chapters: Chapter[],\n  language: string,\n  facet_catalog: FacetCatalog\n) -> Extraction {\n  client \"EvidenceExtractionFast\"\n  prompt #\"\nYou are an expert UX researcher.\nYour task is to produce an exhaustive, chronological Event Stream from an conversation transcript so the reader can follow what happened moment by moment, with explicit mention-level signals. Do not summarize; capture every distinct signal as a separate mention. Do not perform catalog linking in this pass.\nNote this could be a monologue in which case be sure to create evidenceTurns for each separate topic.\n\n## Steps\n1. Identify every human speaker. Populate the `people` array once with:\n   - `person_key`: deterministic slug per human such as `participant-1`, `participant-2`, `interviewer-1`. Derive the number from first appearance order. Reuse the EXACT same `person_key` string for all references to that person. Never reuse a slug for different humans.\n   - `display_name`: the literal transcript label (e.g., \"SPEAKER 2\", \"Kai\", \"Interviewer\").\n   - `inferred_name` and `role` when confident (role ∈ participant | interviewer | moderator | observer | customer | sales_rep).\n   - Include any known segments/personas/organization in the optional fields when the transcript states them.\n2. Slice the transcript into coherent, chronological turns (where each turn is a single speaker). Emit one `EvidenceTurn` per turn, anchored to the correct `person_key` with gist, chunk, verbatim, anchors, and facet mentions.\n3. For each `EvidenceTurn`, emit one or more `FacetMention` items—one per distinct, atomic signal (goal, pain, behavior, tool, value, preference, demographic, context, artifact, emotion, feature, price). Each `FacetMention` must reference its parent `EvidenceTurn` via `parent_index`. Keep `value` concrete and readable in isolation (≤12 words). Prefer verb+object or noun+modifier. Avoid vague superlatives (e.g., \"best\", \"amazing\") unless paired with a criterion. Include a short `quote` when high-signal.\n4. Segment the conversation into `Scene`s when the topic/goal shifts. Each scene spans a contiguous block of `EvidenceTurn.index` values and has a short topic label.\n\n## Selection Priorities\nHigh-severity pains, frequent/recency-marked behaviors, explicit goals, success criteria.\nWorkarounds, hacks, switching triggers, evaluation criteria, blockers, willingness-to-pay signals.\nMoments that reveal motivations, anxieties, decision criteria, or definitions of success.\n\n## SKIP Non-Evidence (Do NOT Extract)\n- Weather talk, bathroom breaks, technical difficulties\n- Social pleasantries (\"nice to meet you\", \"how are you\", \"have a great day\")\n- Procedural questions (\"can we continue?\", \"is this recording?\", \"can you hear me?\")\n- Off-topic chitchat unrelated to product, workflow, or user psychology\n- Interviewer instructions or transitions unless they reveal user confusion/friction\n\nExamples to SKIP:\n❌ \"It's really hot today\" - weather\n❌ \"Can I grab some water real quick?\" - procedural\n❌ \"That's fine, go ahead\" - generic acknowledgment\n❌ \"So, let's talk about...\" - interviewer transition (no signal)\n\nExamples to EXTRACT:\n✅ \"I wish the tool would...\" - pain/goal\n✅ \"I usually work around that by...\" - workaround/behavior\n✅ \"It's frustrating when...\" - pain with emotional signal\n✅ \"I use Notion because...\" - tool + rationale\n\nONLY extract turns with business or psychographic relevance.\n\n## EvidenceTurn\n- index: 0-based chronological index (strictly ascending) and equals its position in the stream.\n- **person_key**: REQUIRED. Exact match (character-for-character) to the `person_key` defined for that person in `people`. Never invent a new slug at the turn level. CRITICAL: Distinguish between interviewer and participant - if someone is asking questions, they're likely the interviewer; if answering, they're the participant.\n- gist: ≤12 words; no labels like \"Quote:\".\n- chunk: 2–5 sentences of the participant’s words.\n- verbatim: ≤15-word quote from the chunk.\n- **anchors.start_ms**: CRITICAL - ALWAYS use the `start` field from the corresponding SpeakerUtterance. This timing is already in milliseconds and is REQUIRED for video playback functionality.\n- anchors: include start_ms (REQUIRED), end_ms when available, speaker label, optional chapter_title.\n- confidence: low | medium | high. Map evidence strength: direct quote ≥ concrete behavior ≥ inferred belief.\n- **isQuestion**: Set to TRUE if this turn contains any question (explicit questions, requests for clarification, probes, etc.) regardless of speaker. FALSE or omit if no questions. Useful for filtering question-response patterns and conversation analysis.\n- why_it_matters: ≤10 words; express the consequence or importance (e.g., \"blocks timely status updates\").\n\n## FacetMention (extraction-only, no linking)\n- parent_index: points to the `EvidenceTurn.index` where the signal appeared.\n- **person_key**: REQUIRED. Must match the exact slug from `people` AND match the person_key of the parent EvidenceTurn. CRITICAL: Assign facets to the person who EXPRESSED the trait/behavior, not the person being discussed. If the interviewer asks \"What tools do you use?\", the participant's answer creates facets for the PARTICIPANT, not the interviewer.\n- kind_slug: one of goal | pain | behavior | tool | value | workflow | preference | demographic | context | artifact | emotion | feature.\n- value: concrete, atomic (≤12 words). Prefer verb+object or noun+modifier. Include frequency/recency when stated (e.g., \"daily\", \"last week\"). Include trigger/condition and objective when helpful. For preference/value, compress subject + rationale into one field when possible: e.g., \"values integrated planning + calendar (tracks progress)\", \"prefers explicit topic mapping for workflow\", \"requires calendar integration to schedule study\".\n- quote: include when it strengthens auditability; ≤15 words.\n- confidence: one of 1, 0.75, 0.5, 0.25, 0.\n- Output one FacetMention per distinct signal in a turn; do not merge similar mentions across turns.\n\n## Scenes\n- Create a new scene when the topic/goal shifts meaningfully.\n- Each scene has `start_index`, `end_index`, and a short `topic` label.\n\n## Interaction Context Classification\nDetermine the `interaction_context` for this conversation. This is used for automatic lens selection.\n- **Research**: User research, customer discovery interviews - exploring user needs, behaviors, pain points. Look for: open-ended questions, exploration of workflows, understanding motivations.\n- **Sales**: Sales calls, demos, deal discussions - revenue-focused. Look for: pricing discussions, feature requirements, objection handling, deal stages, competition mentions.\n- **Support**: Support conversations, escalations, customer success - helping existing customers. Look for: bug reports, how-to questions, account issues, renewal discussions.\n- **Internal**: Team meetings, debriefs, planning - no external participants. Look for: all speakers from same organization, strategy discussions, project planning.\n- **Personal**: Solo voice memos, reflections - single speaker capturing thoughts. Look for: single speaker, stream of consciousness, personal goals/reflections.\n\nConsider:\n- Number of speakers and their roles (single speaker = likely personal)\n- Topics discussed (deals/pricing = sales, bugs/issues = support, user needs = research)\n- Presence of external customers/users vs internal team only\n- Tone and question style (exploratory vs transactional)\n\nSet `context_confidence` between 0.0-1.0 based on how clear the signals are.\n\n## Guardrails\n- Emit all items in ascending `index` / `parent_index` order.\n- Do not fall back to a generic person — if a turn's `person_key` cannot be matched to `people`, revisit your mapping rather than defaulting to the primary participant.\n- Do not output any catalog ids or proposals; linking occurs in a separate step.\n- Keep `value` and `verbatim` within word limits. Ban vague comparatives unless paired with a concrete subject/rationale. Each mention should be testable and specific (avoid grouping multiple subjects; emit one mention per subject).\n- Prefer fewer, higher-quality turns over many weak ones; but do not drop distinct signals (emit mentions instead).\n- Output facet_mentions both nested in EvidenceTurn AND as a flattened top-level array (this enables phase-2 persona synthesis).\n- ALWAYS output `interaction_context`, `context_confidence`, and `context_reasoning` at the top level.\n\nSpeaker Transcripts (language={{ language }})\nEach utterance includes speaker label, text, and timing in milliseconds:\n{{ speaker_transcripts }}\n\nChapters (optional; may help anchoring)\n{{ chapters }}\n\n{% if facet_catalog and (facet_catalog.kinds|length > 0 or facet_catalog.facets|length > 0) %}\nFacet catalog (read-only; do not link in this pass)\n{{ facet_catalog }}\n{% endif %}\n\nOutput ONLY JSON conforming to {{ ctx.output_format }} (no prose/markdown). Ensure indices are contiguous from 0 and strictly ascending; each FacetMention.parent_index references an existing EvidenceTurn.index; omit empty/null fields.\n\"#\n}\n\n// Basic extraction test\ntest ExtractEvidenceFromTranscriptV2_BasicTest {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    speaker_transcripts [\n      {\n        speaker \"INTERVIEWER\"\n        text \"How do you feel about your current project management tool?\"\n        start 0\n        end 5000\n      },\n      {\n        speaker \"PARTICIPANT\"\n        text \"Honestly, it's really frustrating. I spend way too much time just trying to find where I put things. Like, I'll create a task and then I can't remember which project I assigned it to. It makes me feel disorganized and stressed out.\"\n        start 5500\n        end 20000\n      },\n      {\n        speaker \"INTERVIEWER\"\n        text \"What do you do when that happens?\"\n        start 20500\n        end 23000\n      },\n      {\n        speaker \"PARTICIPANT\"\n        text \"I usually end up searching through every project folder, which takes forever. Sometimes I just give up and create a duplicate task. I know it's not efficient, but I need to get my work done. I really wish there was a better way to organize everything automatically.\"\n        start 23500\n        end 40000\n      },\n      {\n        speaker \"INTERVIEWER\"\n        text \"What would success look like for you?\"\n        start 40500\n        end 43000\n      },\n      {\n        speaker \"PARTICIPANT\"\n        text \"I want to feel confident that I can find anything I need within seconds. When I'm in a meeting and someone asks about a project status, I want to pull it up instantly instead of saying 'let me get back to you on that.' That would make me feel so much more professional and in control.\"\n        start 43500\n        end 60000\n      }\n    ]\n    chapters []\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n\n",
  "extract_evidence.tests.baml": "// Tests for ExtractEvidenceFromTranscriptV2\n// Core pipeline function — most critical for interview processing reliability\n\n// ── Sales call: should detect Sales interaction context ──────────────\ntest ExtractEvidence_SalesCall {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    speaker_transcripts [\n      {\n        speaker \"SPEAKER A\"\n        text \"Thanks for taking the time today, Sarah. I wanted to walk you through our new analytics dashboard and see if it could help your team.\"\n        start 0\n        end 8000\n      },\n      {\n        speaker \"SPEAKER B\"\n        text \"Sure. We've been evaluating a few tools. Right now we use Looker but it's way too expensive for what we get. Our contract is up in March.\"\n        start 8500\n        end 18000\n      },\n      {\n        speaker \"SPEAKER A\"\n        text \"Got it. What does your team spend on Looker annually?\"\n        start 18500\n        end 22000\n      },\n      {\n        speaker \"SPEAKER B\"\n        text \"About 120k a year for 30 seats. Honestly only 10 people actually use it regularly. The rest gave up because the learning curve was too steep.\"\n        start 22500\n        end 35000\n      },\n      {\n        speaker \"SPEAKER A\"\n        text \"That's a common issue we hear. Our pricing is per active user, so you'd only pay for those 10. Would a 2-week pilot with your core team be helpful?\"\n        start 35500\n        end 48000\n      },\n      {\n        speaker \"SPEAKER B\"\n        text \"Yeah, that would be great. I need to loop in our VP of Engineering though — she has final say on tooling decisions. Can we set something up for next week?\"\n        start 48500\n        end 60000\n      }\n    ]\n    chapters []\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n\n// ── Support conversation: should detect Support context ──────────────\ntest ExtractEvidence_SupportConversation {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    speaker_transcripts [\n      {\n        speaker \"AGENT\"\n        text \"Hi, this is Alex from support. I see you submitted a ticket about export failures. Can you tell me more about what's happening?\"\n        start 0\n        end 10000\n      },\n      {\n        speaker \"CUSTOMER\"\n        text \"Yeah, every time I try to export a report as PDF, it just hangs and then times out. I've tried three different browsers. This has been happening since last Tuesday's update.\"\n        start 10500\n        end 25000\n      },\n      {\n        speaker \"AGENT\"\n        text \"I'm sorry about that. Let me check your account. Are you on the enterprise plan?\"\n        start 25500\n        end 32000\n      },\n      {\n        speaker \"CUSTOMER\"\n        text \"Yes, we're on enterprise. We need this fixed ASAP — our quarterly board report is due Friday and we can't generate it without exports working.\"\n        start 32500\n        end 45000\n      }\n    ]\n    chapters []\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n\n// ── Single-speaker debrief/voice memo ────────────────────────────────\ntest ExtractEvidence_VoiceMemo {\n  functions [ExtractEvidenceFromTranscriptV2]\n  args {\n    speaker_transcripts [\n      {\n        speaker \"SPEAKER A\"\n        text \"Just got off the call with the Acme team. Three big takeaways. First, they're definitely interested in the annual plan but need a 15% discount to get it past procurement. Second, the VP of Product, Janet, is our champion — she's been pushing internally for months. Third, they want SSO before they'll sign anything. Their security team won't budge on that.\"\n        start 0\n        end 30000\n      },\n      {\n        speaker \"SPEAKER A\"\n        text \"Action items for me: send the discounted proposal by Wednesday, get the SSO timeline from engineering, and schedule a follow-up with Janet for next week. I think we can close this in Q1 if we move fast.\"\n        start 30500\n        end 50000\n      }\n    ]\n    chapters []\n    language \"en\"\n    facet_catalog {\n      kinds []\n      facets []\n      version \"test\"\n    }\n  }\n}\n",
  "extract_evidence_from_document.baml": "// ============================================================================\n// Extract Evidence from Document - For notes, reports, and unstructured text\n// ============================================================================\n// Simpler extraction for documents without speaker diarization or timestamps.\n// Used for: web research notes, market reports, meeting notes, etc.\n// ============================================================================\n\nclass DocumentEvidence {\n  gist string @description(\"<=12-word essence; slide-like headline\")\n  verbatim string @description(\"Key quote or excerpt (<=50 words)\")\n  context_summary string? @description(\"1-2 sentences on why this matters\")\n  source_section string? @description(\"Section/heading where this was found\")\n\n  // Empathy map facets (optional, high-signal only)\n  pains string[]? @description(\"Obstacles or frustrations mentioned; 0-3 items\")\n  gains string[]? @description(\"Desired outcomes or benefits; 0-3 items\")\n  thinks string[]? @description(\"Beliefs or assumptions; 0-2 items\")\n  feels string[]? @description(\"Emotional signals; 0-2 items\")\n}\n\nclass DocumentExtraction {\n  summary string @description(\"2-3 sentence summary of the entire document\")\n  evidence DocumentEvidence[] @description(\"Key evidence units extracted from the document\")\n  topics string[] @description(\"Main topics/themes covered (3-7 items)\")\n}\n\nfunction ExtractEvidenceFromDocument(\n  document_text: string,\n  document_title: string?,\n  document_type: string,\n  max_evidence: int\n) -> DocumentExtraction {\n  client \"CustomGPT5\"\n  prompt #\"\nYou are an expert research analyst extracting key evidence from documents.\n\n## Task\nExtract the most important evidence units from this {{ document_type }} document.\nFocus on actionable insights, data points, quotes, and findings.\n\n## Document\n{% if document_title %}Title: {{ document_title }}{% endif %}\n\n{{ document_text }}\n\n## Instructions\n1. Write a 2-3 sentence summary of the document\n2. Extract up to {{ max_evidence }} key evidence units, prioritizing:\n   - Specific data points, statistics, or metrics\n   - Direct quotes or statements\n   - Key findings or conclusions\n   - Pain points or challenges mentioned\n   - Opportunities or gains identified\n3. Identify 3-7 main topics/themes\n\n## Evidence Selection Criteria\n- HIGH PRIORITY: Specific numbers, quotes, named entities, actionable insights\n- MEDIUM: General observations with supporting context\n- SKIP: Generic statements, filler content, obvious facts\n\n## Output\nReturn JSON matching {{ ctx.output_format }}\n\"#\n}\n\n// Test case\ntest ExtractEvidenceFromDocument_WebResearch {\n  functions [ExtractEvidenceFromDocument]\n  args {\n    document_text #\"\n# Web Research: SaaS Pricing Trends 2024\n\n**Search Date:** 12/10/2024\n**Results Found:** 5\n\n---\n\n## [The State of SaaS Pricing in 2024](https://example.com/pricing)\n\n**Published:** November 15, 2024 | **Relevance:** 92%\n\nAccording to a recent survey of 500 SaaS companies, 67% have moved to usage-based pricing models in 2024, up from 45% in 2022. The average price increase was 12% year-over-year. Companies report that usage-based pricing led to 23% higher customer retention compared to flat-rate models.\n\n---\n\n## [Enterprise Software Buying Trends](https://example.com/enterprise)\n\n**Published:** October 2024 | **Relevance:** 88%\n\nEnterprise buyers now require an average of 6.8 stakeholders to approve software purchases, up from 5.4 in 2023. Security compliance (mentioned by 89% of buyers) and integration capabilities (78%) are the top evaluation criteria. Budget cycles have extended by 2-3 months on average.\n\n---\n\n## [SMB Tech Stack Report](https://example.com/smb)\n\n**Published:** September 2024 | **Relevance:** 85%\n\nSmall businesses spend an average of $15,000/year on SaaS tools. The most common pain point cited was \"too many disconnected tools\" (62% of respondents). AI-powered features are now expected by 74% of SMB buyers.\n    \"#\n    document_title \"Web Research: SaaS Pricing Trends 2024\"\n    document_type \"web_research\"\n    max_evidence 10\n  }\n}\n",
  "extract_insights.baml": "enum Emotions {\n  Abandoned\n  Accepted\n  Aggressive\n  Amazed\n  Angry\n  Annoyed\n  Anxious\n  Apathetic\n  Appalled\n  Aroused\n  Ashamed\n  Astonished\n  Awe\n  Awful\n  Bad\n  Betrayed\n  Bitter\n  Bored\n  Busy\n  Cheeky\n  Confident\n  Confused\n  Content\n  Courageous\n  Creative\n  Critical\n  Curious\n  Depressed\n  Despair\n  Detestable\n  Disappointed\n  Disapproving\n  Disgusted\n  Disillusioned\n  Dismayed\n  Dismissive\n  Disrespected\n  Distant\n  Eager\n  Embarrassed\n  Empty\n  Energetic\n  Excited\n  Excluded\n  Exposed\n  Fearful\n  Fragile\n  Free\n  Frightened\n  Frustrated\n  Furious\n  Grief\n  Guilty\n  Happy\n  Helpless\n  Hesitant\n  Hopeful\n  Horrified\n  Hostile\n  Humiliated\n  Hurt\n  Inadequate\n  Indifferent\n  Indignant\n  Inferior\n  Infuriated\n  Inquisitive\n  Insecure\n  Insignificant\n  Inspired\n  Interested\n  Intimate\n  Isolated\n  Jealous\n  Joyful\n  Judgmental\n  Let_down\n  Lonely\n  Loving\n  Mad\n  Nauseated\n  Nervous\n  Numb\n  Optimistic\n  Out_of_control\n  Overwhelmed\n  Peaceful\n  Perplexed\n  Persecuted\n  Playful\n  Powerful\n  Powerless\n  Pressured\n  Proud\n  Provoked\n  Rejected\n  Remorseful\n  Repelled\n  Resentful\n  Respected\n  Revolted\n  Ridiculed\n  Rushed\n  Sad\n  Scared\n  Sensitive\n  Shocked\n  Skeptical\n  Sleepy\n  Startled\n  Stressed\n  Successful\n  Surprised\n  Thankful\n  Threatened\n  Tired\n  Trusting\n  Unfocussed\n  Valued\n  Victimized\n  Violated\n  Vulnerable\n  Weak\n  Withdrawn\n  Worried\n  Worthless\n}\n\n\nenum BBValues {\n    Accountability\n    Achievement\n    Adaptability\n    Adventure\n    Altruism\n    Ambition\n    Authenticity\n    Balance\n    Beauty\n    Being_the_best\n    Belonging\n    Career\n    Caring\n    Collaboration\n    Commitment\n    Community\n    Compassion\n    Competence\n    Confidence\n    Connection\n    Contentment\n    Contribution\n    Cooperation\n    Courage\n    Creativity\n    Curiosity\n    Dignity\n    Diversity\n    Environment\n    Efficiency\n    Equality\n    Ethics\n    Excellence\n    Fairness\n    Faith\n    Family\n    Financial_stability\n    Forgiveness\n    Freedom\n    Friendship\n    Fun\n    Future_generations\n    Generosity\n    Giving_back\n    Grace\n    Gratitude\n    Growth\n    Harmony\n    Health\n    Home\n    Honesty\n    Hope\n    Humility\n    Humor\n    Inclusion\n    Independence\n    Initiative\n    Integrity\n    Intuition\n    Job_security\n    Joy\n    Justice\n    Kindness\n    Knowledge\n    Leadership\n    Learning\n    Legacy\n    Leisure\n    Love\n    Loyalty\n    Making_a_difference\n    Nature\n    Openness\n    Optimism\n    Order\n    Parenting\n    Patience\n    Patriotism\n    Peace\n    Perseverance\n    Personal_fulfillment\n    Power\n    Pride\n    Recognition\n    Reliability\n    Resourcefulness\n    Respect\n    Responsibility\n    Risk_taking\n    Safety\n    Security\n    Self_discipline\n    Self_expression\n    Self_respect\n    Serenity\n    Service\n    Simplicity\n    Spirituality\n    Sportsmanship\n    Stewardship\n    Success\n    Teamwork\n    Thrift\n    Time\n    Tradition\n    Travel\n    Trust\n    Truth\n    Understanding\n    Uniqueness\n    Usefulness\n    Vision\n    Vulnerability\n    Wealth\n    Well_being\n    Wholeheartedness\n    Wisdom\n}\n\n\nclass ExtractedInsight {\n\t// While trying to do **GOAL/Desired_outcome**, people struggle with **pain** because **WHY: Details/context**.\n\n\tname string @description(\"Short Text description of the insight in up to 5 words\")\n\tpain string | null @description(\"Pain, discomfort, or friction the user experiences in doing a task\")\n\tdetails string | null @description(\"The why or cause of the pain. Details and background leading to or causing the pain. Multiple sentences or bullet points as needed.\")\n\tevidence string | null @description(\"A verbatim quote from the participant in their own words. Include time stamp at end in parentheses.\")\n\tdesiredOutcome string | null @description(\"Desired outcome or benefit the user wants to achieve\")\n\n\t// Research validation fields\n\tassumptionAlignment string | null @description(\"How this insight relates to existing assumptions: 'SUPPORTS', 'REFUTES', 'NEUTRAL', or 'UNEXPECTED'. Be explicit about which assumption it addresses.\")\n\tresearchQuestionAnswered string | null @description(\"Which specific research or decision question does this insight help answer? Be explicit about the connection.\")\n\tevidenceStrength string | null @description(\"Strength of supporting evidence: 'DIRECT_QUOTE', 'CLEAR_BEHAVIOR', 'IMPLIED', or 'WEAK'. How confident are we in this finding?\")\n\tproductImplication string | null @description(\"What does this mean for product decisions? How should this insight influence our roadmap or strategy?\")\n\tfollowUpQuestions string | null @description(\"What new questions does this insight raise? What should we investigate further?\")\n\n\temotionalResponse Emotions @description(\"describe the emotion the person feels about this using the Emotions enum.\")\n\tunderlyingMotivation string | null @description(\"why do they want to achieve this, or overcome the pain?\")\n\tvalues BBValues[] @description(\"Which values is the person expressing?\")\n\tcategory string @description(\"The topical theme or category of the insight to help us group similar insights\") @@dynamic\n\tjourneyStage string @description(\"User journey stage in the application or process of insight, e.g. Awareness, Onboarding, Planning, Learning, Assessing, Progress, Community, Support, Other\")\n\tjtbd string | null @description(\"The user story or **Job to be done** style phrasing of what the user wants to accomplish, eg When I … I want to … so I can …\")\n\tcontradictions string | null @description(\"Potential contradictions and themes explicitly or implicitly by omission, things that the participant doesn't say, e.g. given an opportunity to discuss A,B,C, they only discussed A. Does the user discuss opposing claims?\")\n\trelatedTags string[] @description(\"Related tags or keywords to the insight. Make tags conceptual, not UI feature names (e.g. social_accountability, not leaderboard)\")\n}\n\nclass InterviewMetadata {\n\ttitle string @description(\"Title of interview\")\n\tdate string | null\t@description(\"Date of interview in ISO format: YYYY-MM-DD, (e.g. 2024-07-23) or Null if unknown\")\n\tinterviewer string | null\t@description(\"Interviewer name, or null if not identifiable\")\n\tdurationMin int | null @description(\"Duration of interview in minutes\")\n}\n// Process\n// upload media (video, audio, etc.) create interview record points to media file\n// get file -> send to AssemblyAI to transcribe -> TEXT FILE -> add into interview record (string)\n// --> extract insights & metadata (about interview)\n// -> save interview wrapper, participant, insights :: Some DB Mapping\n\nclass Participant {\n\tname string | null\t@description(\"Participant name, or null if not identifiable from transcript\")\n\tpersona string | null\t@description(\"A more fine-grained personalization within the segment that captures the participant's specific experiences, behavior, and preferences. up to 3 words. Null if unclear.\")\n\tparticipantDescription string | null @description(\"A concise narrative: who they are, their workflow, top frustrations, aspirations, and any standout quotes that define them. <= 7 sentences. Null if insufficient information.\")\n\tfacetSummary string | null @description(\"Summarize the participant's key persona facets, motivations, and behavioral signals surfaced in the interview. <= 5 sentences. Null if insufficient information.\")\n\tsegment string? @description(\"Participant segment, eg. Teacher, Student, Parent, etc.\")\n\tcontactInfo string? @description(\"Participant contact information if given\")\n}\n\nclass InterviewExtraction {\n\tmetadata InterviewMetadata\n\tparticipant Participant\n\tinsights ExtractedInsight[]\n\trelevantAnswers string[] @description(\"List of participant responses that directly address the research objectives, business goals, and key decisions.\")\n\tobservationsAndNotes string @description(\"Concise participant description capturing their attitude, needs, and why they matter for the research objectives.\")\n\thighImpactThemes string[] @description(\"Interview key takeaways. List the 3 strongest takeaways and explicitly tie each to a decision or research question (e.g., 'Decision Q: Pricing — Customers balk at annual contracts')\")\n\topenQuestionsAndNextSteps string @description(\"What next steps should we take to validate our hypotheses or address our knowledge gaps? Pithy statements.\")\n}\n\n\nclass SetRecord {\n\tterm string @description(\"Short, descriptive name (1 - 5 words usually). These are usually tags or keywords, phases, stages, or themes.\")\n\tdefinition string @description(\"Succinct definition of the term.\")\n}\n\nclass Set {\n\tname string @description(\"Name of the set\")\n\tdescription string @description(\"A succinct description of the set and how it will be used.\")\n\tmembers SetRecord[] @description(\"A set of terms and definitions. These are usually tags or keywords, phases, stages, or themes that can be applied in various situations to force clarity.\")\n}\n\nfunction ExtractInsights(transcript: string, userCustomInstructions: string) -> InterviewExtraction {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    Extract targeted insights from this interview transcript that directly address research questions and validate/refute key assumptions.\n\n    Focus on extracting succinct takeaways that answer:\n    - How do the participant's responses support or challenge our core assumptions?\n    - What specific evidence validates or contradicts our hypotheses?\n    - Which research questions does this interview help answer and how?\n    - What unexpected findings emerged that we didn't anticipate?\n\n    For each insight, be specific about:\n    - Whether it SUPPORTS, REFUTES, or is NEUTRAL toward existing assumptions\n    - The strength of evidence (direct quote vs. implied behavior)\n    - How this finding impacts our understanding of the problem space\n    - What follow-up questions this raises for future research\n\n    Prioritize insights that:\n    1. Directly answer key research/decision questions\n    2. Challenge or validate core product assumptions\n    3. Reveal unexpected user behaviors or needs\n    4. Provide actionable direction for product decisions\n\n    ## Participant Profile Requirements\n    - Populate `participant.participantDescription` with a vivid, objective summary of who the participant is, their workflow, and why they matter for the project (<= 7 sentences).\n    - Populate `participant.facetSummary` with the most important persona facets, motivations, and behavioral signals that emerged. Connect facets to supporting evidence where possible.\n    - Ensure `relevantAnswers` contains verbatim or paraphrased responses that directly answer our research objectives, including timestamps when available.\n\n    ## Key Takeaway Formatting\n- `highImpactThemes` must contain up to three bullets that mention the specific decision or research question they serve (use the exact question text or a concise alias).\n- Write each takeaway as \"Question Label — conclusion\" so the relationship is unambiguous.\n- Do not restate raw facts; synthesize the implication relative to the question.\n- REQUIRED: Always generate at least 1 highImpactTheme, even if it's a general takeaway about the interview.\n\nCustom research focus:\n{{userCustomInstructions}}\n\nInterview transcript:\n{{ transcript }}\n\nOutput format:\n{{ ctx.output_format }}\n  \"#\n}\n\nfunction CreateSet(instructions: string) -> Set {\n\tclient \"CustomGPT4oMini\"\n\tprompt #\"\n\t\tCreate a set of terms with definitions, based on the following instructions.\n\t\tWhen creating the set, try to use simple terms and concise definitions that are easy to understand.\n\t\tTry not to repeat words if not needed. e.g instead of A stage, B stage, C stage. Just A, B, C.\n\n\t\tInstructions:\n\t\t{{ instructions }}\n\t\tOutput format:\n\t\t{{ ctx.output_format }}\n\t\"#\n}\n\nfunction GenerateKeyTakeawaysFromEvidence(evidence: EvidenceTurn[], userCustomInstructions: string) -> InterviewExtraction {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    Generate targeted insights and key takeaways from this structured interview evidence data.\n\n    Focus on extracting succinct takeaways that answer:\n    - How do the participant's responses support or challenge our core assumptions?\n    - What specific evidence validates or contradicts our hypotheses?\n    - Which research questions does this interview help answer and how?\n    - What unexpected findings emerged that we didn't anticipate?\n\n    For each insight, be specific about:\n    - Whether it SUPPORTS, REFUTES, or is NEUTRAL toward existing assumptions\n    - The strength of evidence (direct quote vs. implied behavior)\n    - How this finding impacts our understanding of the problem space\n    - What follow-up questions this raises for future research\n\n    Prioritize insights that:\n    1. Directly answer key research/decision questions\n    2. Challenge or validate core product assumptions\n    3. Reveal unexpected user behaviors or needs\n    4. Provide actionable direction for product decisions\n\n    ## Participant Profile Requirements\n    - Populate `participant.participantDescription` with a vivid, objective summary of who the participant is, their workflow, and why they matter for the project (<= 7 sentences).\n    - Populate `participant.facetSummary` with the most important persona facets, motivations, and behavioral signals that emerged. Connect facets to supporting evidence where possible.\n    - Ensure `relevantAnswers` contains verbatim or paraphrased responses that directly answer our research objectives, including timestamps when available.\n\n    ## Key Takeaway Formatting\n    - `highImpactThemes` must contain up to three bullets that mention the specific decision or research question they serve (use the exact question text or a concise alias).\n    - Write each takeaway as \"Question Label — conclusion\" so the relationship is unambiguous.\n    - Do not restate raw facts; synthesize the implication relative to the question.\n    - REQUIRED: Always generate at least 1 highImpactTheme, even if it's a general takeaway about the interview.\n\n    ## Evidence Analysis Guidelines\n    - Analyze patterns across multiple evidence units, not just individual quotes\n    - Look for contradictions or tensions in the data\n    - Identify themes that emerge from combining different types of evidence\n    - Consider the context and timing of responses (anchors)\n    - Weight evidence by modality (observations > stated preferences > behaviors)\n\n    Custom research focus:\n    {{userCustomInstructions}}\n\n    Structured Evidence Data:\n    {{ evidence }}\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest create_set_Personas {\n\tfunctions [CreateSet]\n\targs {\n\t\tinstructions #\"\n\t\t\tUp to 3 Suggested User Personas for an AI Learning Platform. We will use this to test our hypothesis of user problems with learning, organizing and studying.\n\t\t\tWe suspect many younger students have some kind of learning difference or accomodation, such as dyslexia, ADHD, Autism, etc..\n\t\t\tKeep it fun and personal.\n\t\t\"#\n\t}\n}\n\ntest create_set_JourneyStages {\n\tfunctions [CreateSet]\n\targs {\n\t\tinstructions #\"\n\t\t\tCreate a set of User Journey Stages for an AI Learning App.\n\n\t\t\"#\n\t}\n}\n\ntest extract_insights_Jerad {\n  functions [ExtractInsights]\n  args {\n\t\tuserCustomInstructions #\"\n\t\tGive me at least 4 insights that only a german scientist would notice.\n\t\t\"#\n    transcript #\"\n\t\t\tSpeaker B[0:00 - 0:01]: Hey, so today is June 11th, 2025 and I'm Rick and here speaking with Jerad, a friend and tutor.\n\n      Speaker A [0:01 - 1:34]: AI to like, augment technology and use it to. To show that someone's learned something rather than like, they're all afraid that people are going to use AI to avoid learning or avoid work. Um, so if, if AI can be part of the process, you know, as it is here with. With, um, you know, collecting knowledge and organizing knowledge, um, and then the next step would be like, what are you going to do with that knowledge you've collected and organized? And um. I think you're the one that talked about like, the. Whoa. Oral report. You know, that's. That's a really big one. Um, and just, uh, you know, if you went one step further, what if. What if you could actively exercise that information in form of like a debate? And that's what I really came to is like the, the probably most complicated or sophisticated way to use your. The knowledge that you organize through a tool like this would be to, you know, participate in a debate where you had to defend the knowledge that you organized. Because if you're just organizing it and repeating it, you know, that's is organizing. It's basically automated. Um, repeating it is memorizing it. But then. And it's kind of like your hierarchy too, you know, if, if you can debate it with someone else who maybe organized it and takes a different stance, um, now you have to really understand it to do that.\n\nSpeaker B [1:34 - 1:36]: Exactly. Yeah.\n\nSpeaker A [1:36 - 1:57]: Yeah. So, um, you know, I, I think what, what teachers would like to see is how, um, you could. You could, you know, design with that in. In mind. You know, how. How can this tool be.\n\nSpeaker B [1:58 - 1:58]: Um.\n\nSpeaker A [1:58 - 2:38]: So right now the tool lets them do what they want, right? You can make a report with it, you can get ready for your oral report, you can make, you know, your notes, stuff like that. But how can it help the teacher by saying, like, by preparing them for a debate, you know, um, or preparing them to, uh, to defend this information, um, or to exercise it. Um, and I don't know if that becomes, you know, um, a description, a feature or a perspective, you know, like, like, um, a way of viewing the information.\n\nSpeaker B [2:38 - 2:39]: Yeah, um.\n\nSpeaker A [2:40 - 5:05]: Uh, but I, I think that would really. And if you could get, you know, if you could build it around that exercise, all of a sudden that becomes something like a midterm. You know, it's like, hey, class, um, now. Now we're going to, you know, um, pull up this tool and, and get ready for our, you know, once a semester, um, you know, assignment in which we, you know, pick a topic and pick a perspective and you guys are going to go out, you Know, um, collect information, organize it and prepare yourself to participate in some kind of dialogue with the classroom or participate in a dialogue with a different student. Um, and yeah, I think that's. And also like, you know, as I'm m talking about, you know, dialogue, um, going so far as to be able to um, you know, generate, let's say like um, a ah, metaphor or something like that. Like when you teach, um, you use. You lean heavily on metaphors. And I think that was another part of the hierarchy we were talking about too. Um, you know, repeating information and then getting to the point where you can actually teach something. So that requires the student to understand the perspective of their peers, um, and put themselves back in their own shoes, you know, a week ago before they collected this information. And you know, since they went through the process of not knowing, uh, researching, collecting, organizing and now they're at the point where they can, you know, um, make their own opinion on something. And now then they go to teaching, um, they're going to have to uh, let's say, distribute the knowledge. They're going to have to, to give the information to someone else in a way that they can pick up on it without going through the same process that they went, you know, their, their students aren't going to. Or their peers aren't going to collect the information, study it, go through it like they just did. But if they can give it to them in the form of, you know, uh, an analogy or something that um, even better would be to incorporate what they had all learned in that same class.\n\nSpeaker B [5:06 - 5:07]: Um, yeah.\n\nSpeaker A [5:07 - 5:27]: Um, you know, now they're up there in place of the teacher giving a lecture. Um, so I, I think, yeah, it's, it's really comes down to dialogue. Whether that's a debate or whether that's you know, a giving a lecture. I um, think those are, you know, showing that. That top of the pyramid.\n\nSpeaker B [5:27 - 5:27]: Yeah.\n\nSpeaker A [5:28 - 6:11]: Um, again, I think we kind of right now the tools are, are aimed at, at the student or they're aimed at the person who's trying to learn and then do something with that knowledge. But if we could have it, um, it's still the same tool but pitched in a way where it's like, hey teachers, this is a great tool to help you, um, incorporate AI into your class while still, you know, um, giving the student an opportunity to learn. Yeah, um, it's going to be part of, part of work. You know, it's, it's, you know, it's letting them practice that. So m. Yeah.\n\nSpeaker B [6:12 - 6:52]: Interesting. Now I think that's Because I had shown you a little bit before, and that seems like it sparked, uh, this conversation a little bit. Um, what's new to me is the metaphor and the peer education kind of like, hey, you have one student teaching another student, which I think is indeed novel. Um, at least from my perspective. Could you. Would you mind, like, resetting me, like, on your. Because you're tutoring one on one now, right? Is that correct or.\n\nSpeaker A [6:52 - 8:12]: Yeah, so I, I do some tutoring, but now I mostly work with other tutors and kind of program directors. So right now, like, I'll sit down with a tutor, um, we'll look over, like, videos of them tutoring, and I'll help them be a little more effective. Um, I'll help them with exercises, and sometimes I'll help them with theory. Like here's, you know, theory of learning and teaching and stuff like that. Um, and then on the program, you know, direction and development side, um, we create programs that are designed to help our students. Uh, I'm in the high school department, so basically we're focused on, you know, success in high school. Um, we also do some social, emotional, learning. And then like, the key, the big one, is to get into college. So like, right now we're doing a program on, um, college applications and essays. And I'm not why I did get this when someone wasn't there and they needed someone to fill in. But I'm. I'm basically developing the program. I'm putting resources together, lesson plans, and then I'll meet with tutors once every two weeks just to kind of, uh, again, review videos, talk to them about what's going on.\n\nSpeaker B [8:12 - 8:18]: Oh, wow. Okay. And is this a private company that you work for or.\n\nSpeaker A [8:18 - 8:30]: Uh, yeah, it's a nonprofit. Um, it's a private company. They've been around for, uh, 35 years. I've been there for three years.\n\nSpeaker B [8:31 - 8:37]: Okay, what can, what's it called? I'm curious.\n\nSpeaker A [8:37 - 9:32]: It's called, uh, E.P.A.T. east Palo Alto Tutoring and Tennis. And their philosophy is that, um, just epat.org will show e P A T T. Um, their philosophy is that, um, you know, mental fitness and physical fitness are related. And in that area, there was a pro tennis player a while ago, um, made some money playing tennis. And then he created like an endowment, um, to help students. You know, uh, there's. There's a lot of, you know, um, unserved, uh, students there, um, like lower income communities. And he wanted to create this place for them to, you know, pursue education while, you know, and, and then incorporating the part of, of uh, just being socially active and playing a sport, you know, hanging out with other students.\n\nSpeaker B [9:35 - 9:45]: Yeah. Yeah. Okay, that's, that's coming back to me now. Yeah, that's cool. And the juxtaposition of East Palo Alto and Palo Alto proper.\n\nSpeaker A [9:45 - 10:18]: Yeah, and Palo Alto. Yeah. And so a lot of the, their parents are the ones that are, you know, working, uh, the, the worker, the service class to the Palo Alto group. And I mean, anytime you get a lot of, you know, hyper focused, um, you know, high income areas, you're going to have some low income, dense areas kind of thing where it's like a small area that, you know, is this able to service a lot of people that take care of more spread out area of money.\n\nSpeaker B [10:18 - 10:46]: Yeah, it makes sense. Like, and so do you find like that these students, um, you know, they obviously have like a range of challenges, but like, how would you, how would you, would you be able to prioritize them or say, like, they're mostly like cognitive or they like time management or a mix or emotional.\n\nSpeaker A [10:46 - 14:09]: Yeah, a lot of them just, they're not exposed to other ways of how the world works. You know, they're, they're just basically what they see as with most students. And um, a lot of what they see is just, you know, their parents in the service community. Like I, my first student I worked with, we did an exercise on, you know, how education is the path to anywhere that you want to go. You know, I say, here you are now, you know, you know where you are. You can look around, um, and imagine where you want to be. Imagine, you know, do you want a family? Where do you want to live? What kind of life do you want? And we're going to find a path from here to there through education and academia. And I said, okay, you know, what kind of, you know, if you could do anything, what would you do? And she was like, uh, I don't know. And he came up with, you know, I want to be landscaper. All right? And I was like, let's, let's try and get creative. Let's think of something crazy come back to me. And then when he came back, he's like, what about a baker? And it turns out that his mother was a baker and his father was a landscaper. And he couldn't even think of, of a different career to get into or something that he might want to try out. Um, they just, they don't have access to worldviews. Like, you know, uh, I feel like we do where it's like, oh, what about this. What about that? I think that we're also raised like, you can do anything you want, you can do this, you can do that. The way that they're raised, know, unfortunately, is what you have to do in order to survive. You know, we're like, hey, I can do anything I want, I can thrive. And you know, they're a high school student that ah, can't even go to school because they have to stay home and take care of their younger sister or brother, you know, because their parents have to go to work, uh, or they have to do homework late at night because they, they sleep on a couch. And there's multiple families in the home so they can't work in the daytime because there's a lot of families in the living room. Um, it's, it's these challenging situations that, you know, kind of force them to physically live some way. And then by doing that they're limiting their mental perspective on what they can do because they're used to being limited. You know, it's like, well, what can I do? You know, rather than thinking, um, what do I want to do? Is what can I do? And that's where I see or I, you know, experience that, that limitation. And so, um, you know, that's where we get to eventually is, is opening them up to like, you know, there's all these ways of living that, that ah, you can get to, um, but to increase the probability of you reaching that dream or that ideal life, um, it's, it's a lot more probable you'll get there if you start looking at it now, you know, like, uh, you can rent, you can end up. Which often happens in a situation that, oh, this is great, you know, but if you're going to wait on chance you can end up somewhere else too. Um, so if, if you want to be a doctor when you're a kid, it's a lot easier to get there than if you want to become a doctor when you're in college, you know.\n\nSpeaker B [14:11 - 14:16]: Yeah. And you're working mostly with high school age students now.\n\nSpeaker A [14:17 - 15:03]: So, um, sometimes I'll pick up like a junior high student and then this fall I'm going to do an elementary school student just to see what it's like. But, um, I, I've always worked, even before I was here, I've always worked with, you know, either college students or high school students, um, just because I can. The conversations I'm interested in are conversations like this, are conversations that involve potential. Um, they involve kind of this like, you know, bootstrap Mentality where it's like, how can I get somewhere or achieve something great with what I have on hand? Um, those are the conversations I like to have. And high school and you know, early college is a great place to have, have those conversations.\n\nSpeaker B [15:06 - 15:10]: Yeah, well, those are, that's where they're really forced to make these bigger decisions.\n\nSpeaker A [15:11 - 15:11]: Mhm.\n\nSpeaker B [15:12 - 15:14]: If they have those opportunities.\n\nSpeaker A [15:14 - 15:54]: Yeah, yeah, yeah. When I work with my junior high students, it's more about discipline and attention. You know, it's like, hey, sit down and we're going to work on this and we can't think about anything else. We got to think about this, uh, juxtaposed to high school where it's like, what I'm doing has to do with what I'm going to be doing and what I'm going to be doing has to do with where I want to be. So you have, you know, where you want to be. You know, you got to figure out what do I got to get to doing. And then to get there you got to say, what do I need to focus on now? So it's, you know, it becomes a little more complicated. M which requires more, more planning, um, you know, more sophistication.\n\nSpeaker B [15:54 - 15:55]: Yeah.\n\nSpeaker A [15:55 - 16:05]: You know, uh, that's when it requires a conversation. You know, when you're younger, it's more like you're instructed to do something, you know. So that's discipline.\n\nSpeaker B [16:05 - 16:18]: Yeah, yeah. Can you tell me a little bit more about how these students, um, you know, on the planning side that you just mentioned, how do they go about do that, doing that? What does that look like for them?\n\nSpeaker A [16:19 - 20:00]: Okay, so let's see. I, I, it's really a mentorship program. Um, so we uh, work with Stanford a lot. Um, we're usually looking for college students at Stanford to pair up with our high school students. And that's where I come in. I'll talk with the Stanford students, I'll see their experience, their interests. Um, I know all my high school students and I'll try and pair these people up in ways that, you know, uh, makes sense for where the student is interested in where their strengths and weaknesses are sense from like a cultural or like, uh, somewhere where the student's gonna have respect for that college student. Because in high school you get to this point where, um, you know, there's, there's two things. One is like, you think you know a lot or you think you know it all, you don't need help from someone else. But what I see more with our students is, um, they've become so accustomed to, um, not succeeding or like they've gotten F's in a class for so long or on assignments that they're very timid and they're afraid to ask for help either because they don't know what they need help in. It's just like I'm. I went to class, I was so confused. I don't even know what questions to ask or because they're similarly ashamed that the tutor's going to ask them a question that they don't know the answer to and they don't want to seem foolish. So you kind of have this balance of someone who is successful in a way the student's interested in, but also that the student can feel comfortable with. Um, ah. And connect with. Um, and then let's see the planning and then the exercises this the they're gonna do. That's where my program, um, you know, program comes into where it's like I'm, I'm creating either exercises for the tutor to do with the student. Like right now we have a worksheet where they're writing up any extracurricular activities, any experience interests, and then they're going to turn that into a resume. Um, and then they're going to work next week on uh, essay prompts. So just like practice essays for college applications. Um, and then when it's more in school, it's a lot about, it's about theory and stuff like that. Like, um, there's this thing we call like the 5050 rule where you want to try and get your student to speak as a much as you are, because the student is in a classroom, in classrooms all day getting lectured to. Um. And so a tutoring session shouldn't be about lecture. It should be more about conversation and, and practicing. Um, and so we try and get the, the students to talk as much as they can because since we have college tutors, usually they're pretty interested in the subjects that they're teaching. So they can just keep going and keep going and pour it out. But the student doesn't really need another lecture. They need someone that can meet them where they are. And this is where those metaphors come in a lot, you know, where the student has to talk about how they see things and then the tutor has to kind of put themselves in that, in that mindset and say, okay, how can I use um, words that they're familiar with or concepts they're familiar with to get them from where they are to where we need them to be?\n\nSpeaker B [20:02 - 20:25]: Yeah, no, that makes a lot of sense. That's where it comes into like the importance of the dialogue that you're talking about. So all this social, this social financial, like family unit stuff, um, is a big stage for backdrop for how you approaching and working with the students.\n\nSpeaker A [20:28 - 21:29]: Exactly. Yeah. And that, that often takes a meeting before it starts with me and, and the, the tutors just to talk about a few things so they understand where their student is coming from. Because um, they'll, I've seen them. Well, I've, I've lost a couple tutors walking into sessions and they're like, you know, I'm trying to work with my students but they're just, you know, not responsive. I feel like I'm wasting my time. And they leave and they don't understand, you know, that their student is, you know, he's been through a lot of, you know, like, you know, semi traumatic experiences of trying to do something really hard. And then it turns out that what he was doing wasn't what the requirement was. And so it just kind of really, um, you know, makes them kind of suppress their own uh, I don't know, enthusiasm to try and succeed or try and be creative with, with their um, schoolwork. Mhm.\n\nSpeaker B [21:32 - 21:34]: Got it. Okay.\n\nSpeaker A [21:34 - 23:38]: Yeah. And the, and the meeting students where they are part that the tutor has to do, that's something unique to tutoring. Um, and that's really how education started. You know, like the first school was, you know, I guess like Plato was, was doing stuff too, but you know, Aristotle was like the original tutor. And that's kind of how education used to be. It was like one person, um, teaching another person. They didn't have classrooms. And what's great about that is when you're, when you talk to someone, you know who they are. And humans have empathy so we can understand that person. And that's how communication works. If we didn't have empathy, I would just be spitting numbers and it would be computers talking to each other. You know, and if computers don't have a shared syntax or a shared language, they can't speak to each other. You know, the communication doesn't work. And we through empathy can create that syntax on the spot. You know, uh, we can come up with our own, you know, like lexicon or whatever it is and, and share information with each other. In school they basically have to like find the average, like this is how I can reach this perspective, is how I'm going to reach the most amount of students. Um, tutoring is, they've already got that, you know, generalized perspective. Now I have to see where they actually are and give them a specialized perspective. And usually a student going to tutoring didn't really pick up on that generalized perspective. We have a lot of like, um, iep, which is like, it's called individualized Education program, I think. And if they just, they need to learn something a certain way, you know, they, they just have a different way of acquiring information, uh, which was, you know, ah, a lot of my experience, you know, I, I failed through school until I, you know, got a little bit older and I realized that I had to find my own way to, to, you know, acquire knowledge in a useful way, you know.\n\nSpeaker B [23:38 - 23:39]: Yeah.\n\nSpeaker A [23:39 - 24:13]: Um, but I, I almost wonder how, how a tool could provide that individualized perspective, you know, because, um, I'm guessing, you know, the way that AI collects a lot of information and organizes it is based off how information is usually organized online, uh, or usually organized in textbooks or whatever. Whatever they collect from. So that's, that's just another idea of, you know, how can information be.\n\nSpeaker B [24:14 - 24:16]: Hey Jen, do you want me to put my headphones on?\n\nSpeaker A [24:16 - 24:35]: Or it's like, like you had the, the knowledge graph, you know, or there's the bullet points or there's index cards. So, um, all those different ways to organize and view the knowledge can definitely reach different students in more effective or less effective ways.\n\nSpeaker B [24:39 - 24:45]: Yes, yes indeed. I've actually, um, just time check. How much time do you have?\n\nSpeaker A [24:46 - 24:55]: Um, I've got about maybe 10 minutes. Okay, thanks for checking. Yeah, I wasn't watching. I start talking about this stuff and I'll get into it all day long.\n\nSpeaker B [24:55 - 25:01]: I know, I know. Um, let, let me do. Are you, you on your computer right now?\n\nSpeaker A [25:01 - 25:02]: Yeah. Yeah.\n\nSpeaker B [25:02 - 25:10]: Okay, let me, let me share a screen because I want to jump um, for it and we might not have enough time for this right now.\n\nSpeaker A [25:11 - 25:11]: Yeah.\n\nSpeaker B [25:11 - 25:34]: Um, but. Okay. Mhm.\n\nSpeaker A [25:54 - 26:39]: Mhm. Okay, I can see your screen. Ask anything.\n\nSpeaker B [26:39 - 27:29]: Okay, super. Um, and I don't think we'll be able to get through the whole thing right now, but this will probably take a little bit longer. But I feel like what the conversation is leading to and what we've come up with is a new set of concepts. Um, kind of like trying to get deeper into m. The more holistic situation of a student, not just here's some information. So let me walk you through this and what I'd like to do is show you a screen and then have you respond to it and say, okay, do you understand what it's asking you to do? Does it make sense? And we'll just kind of go through m that got it. And you just tell me when you're out of time and then maybe we can pick up again later some other time.\n\nSpeaker A [27:30 - 27:30]: All right, perfect.\n\nSpeaker B [27:30 - 27:35]: All right, so let's start with this screen.\n\nSpeaker A [27:40 - 27:43]: Um, you're, let's see, asking me to.\n\nSpeaker B [27:43 - 28:01]: Oh, okay, so there's two options, right? Like, it's like, this is like the onboarding part of. Okay, I want to learn something. I could either type in a question or I can upload some content. And there's two different ways to start.\n\nSpeaker A [28:02 - 29:06]: Yeah, that's, that's, that's how I saw it. I see it as, um, you know, almost. Yeah, yeah, I see it. Yeah. I walk up, ask, um, me something and then the. What would you like to learn? I think is actually kind of important here. I mean, if I was directed here by, by someone who had used this for a certain, like, they're like, hey, if you want to do that, do this, you know. But if I was exploring on my own, like, hey, like, what's a good tool for doing something? Blah, blah, blah. If I saw this without the what would you like to learn? I wouldn't be, I wouldn't think it's, it's so like, you know, based on like, you know, learning something versus like an Ask Jeeves type thing. Like, um, getting. Ah, so learning something versus like being directed somewhere. Like as there's asking for directions and then there's, you know, like, hey, how do I get to like Big Ben to talk in London? And then there's like, hey, what is big? Like what's the history behind it? So what would you like to learn? I think is actually pretty important.\n\nSpeaker B [29:06 - 29:09]: Okay, so maybe even elevate that over the asking.\n\nSpeaker A [29:10 - 29:22]: Oh yeah, that's a good, that is a, that's a good question. That's a good thought. Yeah. To put what would you like to learn? And then, you know, if you need the subtext like ask here or something like that, or that's kind of in your, uh.\n\nSpeaker B [29:23 - 29:45]: Interesting. Okay, super. All right. And then if you. I'll just explain this part. So this is a mock up right now. It doesn't entirely work, but if you were, if you had like course material or an, you know, a reading assignment or something, you could put it in here all and that would, and then the next, if you click next, you'd get to here.\n\nSpeaker A [29:53 - 30:40]: Yeah, this, this, this feels a lot, Yeah, I, I feel a lot more like what we're talking about, you know, what do you want to learn? Um, mhm. Okay, so I, I'm, I, I Feel like, what do you want to learn? I'm feeling a lot more the, the first picture because the, the learning goal. Um, I get, I feel a little confused on that. So let's see, like right now, um, I want to learn about, um, certain drawing techniques, you know, and I would look at this. Okay, what do I learn? I want to learn about a certain drawing technique. Um, and my goal would be. I just feel like there's something in between here.\n\nSpeaker B [30:41 - 30:41]: Yeah.\n\nSpeaker A [30:41 - 31:02]: Okay, what do I want to learn? And then your learning goal. I feel like this is where someone explains to you, hey, so what do you want to learn? I want to learn this. All right, so in order to learn, you got to create a goal or create this. Um, it's, this is tough because I also don't want too much here. Um, what do you want to learn to find your learning goal.\n\nSpeaker B [31:04 - 31:13]: So it's feeling a little vague, right? Like maybe some better examples. Like, maybe like be able to be able to write an essay about the.\n\nSpeaker A [31:13 - 32:08]: Topic or well, also if, if it's a lot less. Um, so right here it says, what do you want to learn? Once I read underneath. So again, I look at it, I just, I, I read the black text. What do you want to learn? Learning gold, your background. But then once I looked again at, ah, at the, um, the lighter text. What do you want to learn? Define your learning goal and we'll create a personalized learning path. Um, it's, you know, I, I, I would want to do some more looking at this, but it would, what do you want to learn? Um, something that explains that, um, you know, by creating a goal, that it's a lot easier to, to organize the information for you. Or the first part about learning is defining where you want to go. Um, uh, it seems more, more human.\n\nSpeaker B [32:09 - 32:09]: Yeah. Yeah.\n\nSpeaker A [32:11 - 32:19]: Hey, what do you want to learn? Oh, I want to learn how to water. You know, I want, I want to learn how to, to draw with pastel.\n\nSpeaker B [32:19 - 32:20]: That.\n\nSpeaker A [32:20 - 33:16]: Okay, well, the first step of learning is, you know, to create a goal or to, you know, what, what is that first step? Something like that. I think it's, yeah. So to start to get you there, let's set a goal, you know, and I be like, okay, so to get to drawing with pastels, I need a goal. I'd like to, you know, know, do a portrait. Ah, with pastels. Yeah. I, it's, and it depends on the environment. Like, if I'm doing this during a classroom exercise, uh, I feel like you're being walked through it. But if I'm Doing this on my own and I'm just using this tool. I feel like the, the, the smaller text could be a little more, um, helpful with understanding why I'm doing it or what I'm doing rather than in telling me what to do.\n\nSpeaker B [33:17 - 33:20]: Um, yeah, the why. The why.\n\nSpeaker A [33:20 - 33:21]: Yeah, the why. The why.\n\nSpeaker B [33:21 - 33:22]: Okay.\n\nSpeaker A [33:22 - 33:22]: Yeah.\n\nSpeaker B [33:24 - 33:25]: Okay, that's good. There's some good insight.\n\nSpeaker A [33:26 - 33:53]: Yeah. Because, because it starts like a conversation, right? It starts like, hey, what do you want to learn? And then it turns into direction and, and I don't know, I don't want to like jump too far, but it could be towards that whole like giving an instruction versus having someone meet you there, like a tutor. And since this is like a one to one thing, it's a person to a tool, maybe it should be a little more meeting you.\n\nSpeaker B [33:55 - 34:04]: Yes. Yeah, well, that, that's, that's definitely the sense we're trying to capture. Um, yeah, but okay, this is also.\n\nSpeaker A [34:04 - 34:55]: Very concise, which is good too, because, like, you don't want a paragraph of text saying like, you know, according to this theory of learning, it's better for you to create goals and we can go step by step. You definitely want to keep it short like this. And if this is the second time I'm using the tool, this is perfect. You know, so we also got to think about, are we, um, using this tool all the time? In which case this is perfectly designed for that. Probably because you're working on this all the time. Um, and then maybe the first time you go through it, there might be a tutorial or something like that that explains I, you know, by setting goals, this and that. So it, there's, there's a good argument for having a tutorial. I mean, yes, even the most simple apps have a tutorial. So, yeah, um, that's. If we're going to assume there's a tutorial. This is great.\n\nSpeaker B [34:56 - 35:00]: Okay, that is the, that is the, the goal to have a tutorial.\n\nSpeaker A [35:00 - 35:04]: Uh, yeah, so let's, let's work on, on the tutorial. Let's, let's work with that assumption.\n\nSpeaker B [35:04 - 35:04]: Yeah.\n\nSpeaker A [35:04 - 35:07]: And yeah, this is perfect. This is exactly super.\n\nSpeaker B [35:08 - 35:43]: And then we're asking for your background and I think we could probably reword this, but the, the goal is like, get these students to, and make some kind of a commitment, investment and say, well, I don't know much about water management, but, you know, uh, I know it comes, we get water from Colorado river or something somehow. Right? So now they, they have a starting point as opposed to like, so to your point earlier, they're starting to produce, you know, information instead of just consume it.\n\nSpeaker A [35:43 - 35:43]: Yeah.\n\nSpeaker B [35:44 - 35:44]: And then we can.\n\nSpeaker A [35:44 - 36:17]: And what really quick. What provides more value to. To your, you know, back end? Someone saying, like, um. Like, let's say I know a little bit about the water, like, where the water comes from. Or is it better to say, like, how does a city get its water from the state? Like, is it better for them to ask small questions here? Like, if the big question or the big idea is learning goal, does the background part. Do they want to know small questions or they want to know, uh, small facts?\n\nSpeaker B [36:19 - 36:46]: I think for the background, I was intending it to be small facts so that we could say, okay, great, since you know, about the Colorado river, you know, let's start with that to get them invested, maybe, um, as a touch point to find some commonality so they're not immediately getting overwhelmed with a whole bunch of new stuff. But like, a little bit of. Here's what you know. And let's tell you something in addition to that.\n\nSpeaker A [36:46 - 37:07]: Um, that's. That's what I get out of this. I get small facts. That's. That's the. And your background is actually, it's, you know, I can't think of two words that are. That are better right now. Like, okay, yeah, even what do you know? Doesn't. That sounds like I'm writing a paper. Your background sounds pretty like. I. I see the. The desire for something more accurate, but it's pretty good.\n\nSpeaker B [37:08 - 37:17]: Okay. Yeah. We. And we can. And all this is like, up for debate and change and all that. Like, I'm not invested.\n\nSpeaker A [37:17 - 38:54]: I'll keep. And I'll keep thinking too. Yeah. So, uh, I see. Yeah. I, I think of this almost like, um, how much information do I want to get and how complicated is it going to be? I guess how complicated is it going to be is kind of, uh. The first thing that was the first thought and the second thought was how much. So if I just want something quick and something easy, it would. It would be inner. Uh, it'd be introductory. Introductory. But if I wanted a little more information, like, you know, um, I'm not an expert on the water, but let's say like, um, waves. Uh, introductory level would say like, storms create waves that, you know, wind that blows waves to shore. Intermediate would say, um, you know, something like changes in temperature, uh, create weather, which blows waves to shore. And then as you get further up, it would be like, you know, sun sends energy to the earth that heats up different areas at different rates. And that change and the difference between those changes in temperature creates storms and weather, which then creates waves. So I, I see it not just as a complexity but also as an amount thing. So I don't know if those are separate or if that's kind of put together here.\n\nSpeaker B [38:54 - 39:13]: Interesting. Um, this was a little bit more, uh, I think what you're addressing is what's on the next page. Um, but this is, um, more. You see these levels down here? These are actually correlating to the Bloom taxonomy levels.\n\nSpeaker A [39:13 - 39:14]: Okay.\n\nSpeaker B [39:14 - 39:15]: And so that was.\n\nSpeaker A [39:16 - 39:21]: Oh, that's nice. Yeah, I didn't, I didn't see you clicking through that. The. Yeah, apply, analyze that.\n\nSpeaker B [39:22 - 40:59]: So that, that's what I had started with. Um, and so let me jump to the next page because I'm trying to figure out the best way to organize this. Um, and so here it gets a little bit, this gets a little more complicated. Right. Um, which might be overwhelming for students, but now we get into a phase of like, tell me, um, how much of this do you want to get into? And so this might be an alternate way of dealing with it. What I was thinking is the user could look, uh, at this and maybe draw a circle around how much. Or they could say, all right, they could add a plus. They could say, give me more on this area, less on this. Maybe even kind of prune a tree, if you will, of content to direct, uh, the AI on the topics it wants to cover. Mhm. The idea is maybe you would interact with this tree. You could add topics here and maybe remove some m. You know, so that was kind of like the idea and it would show you. Okay, well this is pretty focused on one side of the knowledge or it's pretty balanced. And I'm not even sure that's super. Uh, this bottom part is something the student need, average student needs to see. Um, so it's all very exploratory.\n\nSpeaker A [41:01 - 44:06]: Yeah, this, that's interesting because. And, and this is tough because I have a bias. I, um, I don't know where I, I from, what I remember. So like I have a really strong bias against like network graphs and node structures. Um, and, and I spent a lot of time with them because, um, when I study cognitive science, it's a lot of, you know, network information. Um, the mind as an embedded system and machine learning is really big on these. And I, um, think still now, but for you know, the early, like 2010 to 2020, there was a lot of products like this too. You know, creating your notes into nodes like this. And I think from someone who thinks like a systems Perspective like me. And I'm guessing you node graphs are great. Like I, you know, I was the same way. Oh, so cool. But, um, in, in, um. I don't know if this is like, studies or what. It just seems like it hasn't really hit like there was that node, um, or graph note app for a while that was. I was taking off and it just seems like a lot of these kind of flare out. Um, and when I look at this, as soon as. And here's the thing, it required you to click on those things. I love the bottom piece, but what I love about it is how it changes. I love that when you're adding or subtracting from it that it's giving me. Ah, yeah, an adapting summary. I really, really like that. And I can't think of another way to add or subtract without that graph, you know, so it's, it's tough. Like, um, you know, and maybe, maybe having a graph as an interface rather than as the organizational piece, you know, because, like, um, we had like tools where there's like note cards in place of all of those nodes. Right. And it takes up a lot of space for the amount of information that it holds versus, like a bullet chart. Bullet chart. I love bullet charts. Like, it's just like, like look at how people write their notes by hand. Anyways. People do bullets. Boom, boom, boom, boom. People on computers, we love to put them in these, these graphs. But when we do it by hand, we're usually doing that. I know there's like brainstorming, and I think that's where a lot of this kind of like, how do I get a brainstorm and put it on a computer? Um, um, but. And I see this bottom piece kind of like that bullet point. You know, it's like, let's look at the depths. Boom, boom, boom. You know, let's look at the topics. Boom, boom, boom. Let's look at how balanced it is and what the learning style is. Like. I, that is how I want to read information. So that's great. How I want to interact with the information. Um, yeah, like I said, I can't think of a better way than the node one, but I am a little, um, I have, I just have a personal issue, I guess, with, with uh, information graphs and, and, or like node graphs like that. But I've never used them as an interface. So, um, I, I would want to play with this.\n\nSpeaker B [44:06 - 44:06]: Yeah.\n\nSpeaker A [44:06 - 44:10]: So, you know, in a couple weeks, you know, when you're back, I want to touch this.\n\nSpeaker B [44:11 - 44:11]: Okay.\n\nSpeaker A [44:12 - 44:36]: Um, and yeah, it's it's hard for me to think too deeply into it, but um, it makes sense once you touch it, you know, and I'm sure once you know about it. I, um, do wonder how you would know what these topics are. You know, if I'm, if I'm reading this on my, my laptop, like I guess you'd have to put just like a one word description for, for each of these nodes or.\n\nSpeaker B [44:37 - 44:47]: Yeah. The way. So this isn't perfect representation of like we instead of circles. So just the prototyping tool I'm using, it came up with circles. But what.\n\nSpeaker A [44:47 - 44:49]: I've got like two minutes.\n\nSpeaker B [44:49 - 44:50]: Okay.\n\nSpeaker A [44:50 - 44:53]: So if you want to keep talking about this, let me know.\n\nSpeaker B [44:53 - 45:04]: Yeah, let me just, uh. There's one. Yeah. It would look different than this. It would look different than this where there'd be like two to three words and it's ah, more of a box.\n\nSpeaker A [45:05 - 45:11]: But we'll have to create like a more accurate representation or a more accurate situation.\n\nSpeaker B [45:12 - 45:21]: Exactly. Yeah. Yeah. This is, this is total mock up. But after that the final step is you go, okay, now pick the mode you want to interact with the tool.\n\nSpeaker A [45:23 - 46:12]: Yeah, just, just looking at the left column, mode. Exam prep, mentor chart, think tank, Creative Explorer. I love it. You know that, that makes me feel like right away I look at this and go, wow, I'm saving so much time. Like, and that's what students are trying to do, right? That's what anyone's trying to do is what, you know, um, you know, manage my most, uh, sacred resource of time. Like, wow, great. Boom, boom, boom. And it also feels personal. You know, that's the one on one. And, and I'm gonna, I think I'm just gonna to champion that perspective. You know, the tutor's role like this. I'm gonna think of this tool not as a teacher, but as a tutor. You know, someone who's going to reach you where you are and build that bridge to where you want to go. Um, so I re. I love the left column. I'm gonna look at those.\n\nSpeaker B [46:12 - 46:54]: Super. And just the last thing I'll show you and we can come back and talk about it later. Um, is that, that was the. Tell me what you want to achieve and we'll create. Now what's happening is the system's going to create a learning plan and you're going to. And now you're in the interface for the app and we can kind of go through this at another time because I know you got to run, but you would actually jump into the learning here and Go through things and you'd have a chance to discuss, um, and then you could practice with quizzes. But this is where the learning would happen. And we'd show you the learning plan here of. Here's the things you need to do to get through here.\n\nSpeaker A [46:55 - 47:15]: Um, so I. I also want to play with the idea of putting that, um. Um, you know, um, what is it? Like exam test prep? Like, what. What are you trying to do with this towards the beginning, you know, even before. What do you want to learn?\n\nSpeaker B [47:15 - 47:16]: Yeah, I.\n\nSpeaker A [47:16 - 47:58]: Or at least next to it. Um, it's. It's an interesting thought that I think. I think the difference on putting that somewhere, uh, comes into, uh, in the enthusiasm level. Um, just because, like, when I saw it, I'm like, wow, this is cool. If that was, you know, the first thing that I saw that, whoa, this is great. Let me use this tool versus, like, what do you want to learn? Um, you know, like I said, there's. What do you want to learn? There's Google, you know, there's, uh, Wikipedia. There's all these things I can type in something. You haven't really set yourself apart, you know, at least from my eyes. My eyes don't notice difference.\n\nSpeaker B [47:58 - 47:59]: Difference.\n\nSpeaker A [48:00 - 48:09]: Um, but when I see that exam, whatever, all these different things, my eyes are seeing something. They're seeing a tool that they haven't seen before.\n\nSpeaker B [48:10 - 48:12]: Uh, that's good point.\n\nSpeaker A [48:13 - 48:45]: Yeah. It's like, if we were going to test that out, the question would be, how much more excited are you to use this tool? You know, how much more interested are you in this tool based on these two different ways of starting it, rather than like, which one do you think is going to get you where you want to go? I think the question is how much more interested in using the tool are you? Because that's what that's going to manipulate. True M. All right, well, I gotta. I gotta get to church.\n\nSpeaker B [48:45 - 48:46]: Yeah.\n\nSpeaker A [48:46 - 48:50]: Really cool talking to you. Uh, we can. We can just keep talking more and more.\n\nSpeaker B [48:50 - 48:51]: Yeah, let's do it.\n\nSpeaker A [48:52 - 49:29]: Um, I'll keep thinking about it, especially this summer. It's pretty interesting because I'm, you know, working with these tutors on trying to get students so it's not so much like, hey, I need help with this homework assignment. It's like, hey, how can I get you to, um, do like, some bigger stuff, you know, working on college essay prompts, um, know, exploring ideas and, you know, ultimately, you know, building a life of, uh, fulfillment. You know, that's. That's kind of my thing is how do I build a fulfilling life for the students or how do I help them? Give them the tools they need.\n\nSpeaker B [49:29 - 49:31]: Awesome. All right, Jed, I'll let you run.\n\nSpeaker A [49:32 - 49:32]: All right?\n\nSpeaker B [49:33 - 49:36]: Okay. Take care. Thank you.\n\n    \"#\n  }\n}\n",
  "extract_insights.tests.baml": "// Tests for GenerateKeyTakeawaysFromEvidence\n\n// ── Research interview evidence ──────────────────────────────────────\ntest KeyTakeaways_ResearchEvidence {\n  functions [GenerateKeyTakeawaysFromEvidence]\n  args {\n    evidence [\n      {\n        person_key \"participant-1\"\n        speaker_label \"PARTICIPANT\"\n        gist \"Bounces between learning platforms\"\n        chunk \"I signed up for three different platforms — Codecademy, Coursera, and YouTube tutorials. I kept bouncing between them because none of them felt right. Each one assumed a different starting point.\"\n        verbatim \"none of them felt right\"\n        anchors {\n          start_ms 5000\n          end_ms 18000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"pain\"\n            value \"mismatched skill level across learning platforms\"\n            quote \"none of them felt right\"\n          },\n          {\n            person_key \"participant-1\"\n            kind_slug \"tool\"\n            value \"Codecademy\"\n            quote null\n          },\n          {\n            person_key \"participant-1\"\n            kind_slug \"tool\"\n            value \"Coursera\"\n            quote null\n          }\n        ]\n        isQuestion false\n        says [\"none of them felt right\"]\n        does [\"bounces between 3 learning platforms\"]\n        thinks [\"existing platforms don't understand my level\"]\n        feels [\"frustrated with wasted time\"]\n        pains [\"When trying to learn Python, blocked by platforms assuming wrong starting point\"]\n        gains null\n      },\n      {\n        person_key \"participant-1\"\n        speaker_label \"PARTICIPANT\"\n        gist \"Wastes learning time on navigation\"\n        chunk \"I have maybe 30 minutes a day to learn and I was spending half of it figuring out which lesson to do next instead of actually coding. After two weeks I just gave up.\"\n        verbatim \"spending half figuring out which lesson\"\n        anchors {\n          start_ms 43000\n          end_ms 55000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"pain\"\n            value \"time wasted on lesson selection instead of learning\"\n            quote \"spending half figuring out which lesson\"\n          },\n          {\n            person_key \"participant-1\"\n            kind_slug \"behavior\"\n            value \"allocates 30 minutes daily to learning\"\n            quote \"maybe 30 minutes a day\"\n          }\n        ]\n        isQuestion false\n        says null\n        does [\"allocates 30 min daily to learning\"]\n        thinks null\n        feels [\"defeated after two weeks\"]\n        pains [\"When time-constrained, blocked by poor lesson sequencing\"]\n        gains [\"so I can spend all 30 minutes actually coding\"]\n      },\n      {\n        person_key \"participant-1\"\n        speaker_label \"PARTICIPANT\"\n        gist \"Wants adaptive skill assessment\"\n        chunk \"Something that asks me what I already know, gives me a quick assessment, and then builds a path from there. And it would track what I've actually retained, not just what videos I watched.\"\n        verbatim \"asks me what I already know\"\n        anchors {\n          start_ms 60000\n          end_ms 72000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"goal\"\n            value \"personalized learning path based on existing knowledge\"\n            quote \"asks me what I already know\"\n          },\n          {\n            person_key \"participant-1\"\n            kind_slug \"requirements\"\n            value \"retention tracking over completion tracking\"\n            quote \"track what I've actually retained\"\n          }\n        ]\n        isQuestion false\n        says [\"track what I've actually retained, not just what videos I watched\"]\n        does null\n        thinks [\"completion metrics are meaningless for real learning\"]\n        feels [\"hopeful about adaptive approaches\"]\n        pains null\n        gains [\"so I can learn efficiently in limited time\"]\n      },\n      {\n        person_key \"interviewer-1\"\n        speaker_label \"INTERVIEWER\"\n        gist \"Probes for ideal learning experience\"\n        chunk \"If you could design the perfect learning experience, what would it look like?\"\n        verbatim \"design the perfect learning experience\"\n        anchors {\n          start_ms 55000\n          end_ms 60000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions []\n        isQuestion true\n        says null\n        does null\n        thinks null\n        feels null\n        pains null\n        gains null\n      }\n    ]\n    userCustomInstructions \"Focus on onboarding and initial user experience. What does this tell us about how new users should be greeted?\"\n  }\n}\n\n// ── Sales call evidence ──────────────────────────────────────────────\ntest KeyTakeaways_SalesEvidence {\n  functions [GenerateKeyTakeawaysFromEvidence]\n  args {\n    evidence [\n      {\n        person_key \"participant-1\"\n        speaker_label \"SPEAKER B\"\n        gist \"High spend on underutilized tool\"\n        chunk \"We're paying about 120k a year for 30 Looker seats but honestly only 10 people actually use it regularly. The rest gave up because the learning curve was too steep.\"\n        verbatim \"only 10 people actually use it\"\n        anchors {\n          start_ms 22500\n          end_ms 35000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"pain\"\n            value \"low adoption due to steep learning curve\"\n            quote \"learning curve was too steep\"\n          },\n          {\n            person_key \"participant-1\"\n            kind_slug \"tool\"\n            value \"Looker\"\n            quote null\n          }\n        ]\n        isQuestion false\n        says [\"only 10 people actually use it regularly\"]\n        does null\n        thinks null\n        feels null\n        pains [\"When onboarding team to analytics, blocked by steep learning curve\"]\n        gains null\n      },\n      {\n        person_key \"participant-1\"\n        speaker_label \"SPEAKER B\"\n        gist \"Gut decisions from data access gap\"\n        chunk \"We end up making gut calls more than I'd like. Last quarter we launched a feature based on assumptions and it flopped. If we'd had the usage data faster we would have caught it.\"\n        verbatim \"making gut calls more than I'd like\"\n        anchors {\n          start_ms 40000\n          end_ms 55000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"pain\"\n            value \"data access gap causing poor product decisions\"\n            quote \"launched a feature based on assumptions and it flopped\"\n          }\n        ]\n        isQuestion false\n        says null\n        does [\"makes product decisions without data\"]\n        thinks null\n        feels [\"regretful about recent feature flop\"]\n        pains null\n        gains [\"so I can catch product issues before launch\"]\n      },\n      {\n        person_key \"participant-1\"\n        speaker_label \"SPEAKER B\"\n        gist \"Hard deadline for tool switch\"\n        chunk \"Our Looker contract renews in March. I'd want to have something in place by February so we can run both in parallel for a month.\"\n        verbatim \"contract renews in March\"\n        anchors {\n          start_ms 80000\n          end_ms 90000\n          chapter_title null\n          char_span null\n        }\n        facet_mentions [\n          {\n            person_key \"participant-1\"\n            kind_slug \"context\"\n            value \"Looker contract renewal March, needs replacement by February\"\n            quote \"contract renews in March\"\n          }\n        ]\n        isQuestion false\n        says null\n        does null\n        thinks null\n        feels null\n        pains null\n        gains null\n      }\n    ]\n    userCustomInstructions \"\"\n  }\n}\n",
  "extract_persona.baml": "class Persona1 {\n  // Demographics\n  name string @description(\"Persona name: up to 3 words\")\n  description string | null @description(\"Persona Archetype description: 3-7 sentences summarizing behavior, pain, motivations, and preferences\")\n  age string | null @description(\"Most common age or age range, e.g. '25-34'\")\n  gender string | null @description(\"Most common gender for this persona\")\n  location string | null @description(\"Most common location(s) for this persona\")\n  education string | null @description(\"Most common education level(s)\")\n  occupation string | null @description(\"Most common occupation(s)\")\n  income string | null @description(\"Most common income range or level\")\n  languages string | null @description(\"Most common languages spoken\")\n  segment string | null @description(\"Segment or group this persona belongs to\")\n  role string | null @description(\"Role or job title\")\n  color_hex string | null @description(\"Hex color for persona visualization\")\n  image_url string | null @description(\"URL to persona avatar/profile image\")\n\n  // Psychographics\n  motivations string[] | null @description(\"Key motivations for this persona\")\n  values string[] | null @description(\"Core values for this persona\")\n  frustrations string[] | null @description(\"Top frustrations or pain points\")\n  preferences string | null @description(\"Notable preferences\")\n  learning_style string | null @description(\"Preferred learning style\")\n  tech_comfort_level string | null @description(\"Comfort level with technology\")\n\n  // Behavior\n  frequency_of_purchase string | null @description(\"How often this persona purchases relevant products/services\")\n  frequency_of_use string | null @description(\"How often this persona uses relevant products/services\")\n  key_tasks string[] | null @description(\"Key tasks this persona performs\")\n  tools_used string[] | null @description(\"Tools or products commonly used by this persona\")\n  primary_goal string | null @description(\"Primary goal for this persona\")\n  secondary_goals string[] | null @description(\"Secondary goals for this persona\")\n  sources string[] | null @description(\"Main sources of information or influence\")\n  quotes string[] | null @description(\"Representative quotes from this persona\")\n  percentage float | null @description(\"Estimated percentage of users represented by this persona\")\n}\n\n// baml_src/personas.baml\n// Rolling persona refinement with single‑interview safeguards\n\nclass Persona {\n  // === IDENTITY & CORE ===\n  name string @description(\"Persona name: up to 4 words. Plain, memorable, captures essence. Example: The Reluctant Power User, Last-minute shopper\")\n  name_and_tagline string @description(\"2–4 words + optional quoted tagline. Plain, memorable, captures essence. Example: The Reluctant Power User — 'Wants outcomes, hates setup'.\")\n  description string | null @description(\"Persona Archetype description: 3-7 sentences summarizing behavior, pain, motivations, and preferences\")\n  role_context string @description(\"Role/life stage/situation as it relates to the product problem. Example: 'HS junior juggling AP classes' or 'Ops lead at 20‑person startup'.\")\n\n  // === DEMOGRAPHICS ===\n  age string | null @description(\"Most common age or age range, e.g. '25-34'\")\n  gender string | null @description(\"Most common gender for this persona\")\n  location string | null @description(\"Most common location(s) for this persona\")\n  education string | null @description(\"Most common education level(s)\")\n  occupation string | null @description(\"Most common occupation(s)\")\n  income string | null @description(\"Most common income range or level\")\n  languages string | null @description(\"Most common languages spoken\")\n  segment string | null @description(\"Segment or group this persona belongs to\")\n  role string | null @description(\"Role or job title\")\n\n  // === VISUAL IDENTITY ===\n  color_hex string | null @description(\"Hex color for persona visualization\")\n  image_url string | null @description(\"URL to persona avatar/profile image\")\n  percentage float | null @description(\"Estimated percentage of users represented by this persona\")\n\n  // === GOALS & MOTIVATIONS ===\n  goals string[] @description(\"3–5 user outcomes (not features). Example: 'Finish assignments faster'; 'Reduce rework'.\")\n  primary_goal string | null @description(\"Primary goal for this persona\")\n  secondary_goals string[] | null @description(\"Secondary goals for this persona\")\n  motivations string[] | null @description(\"Key motivations for this persona\")\n  values string[] | null @description(\"Core values for this persona\")\n  success_definition string @description(\"Crisp success statement in this domain. Example: 'Submits work a day early without anxiety'.\")\n\n  // === BEHAVIORS & PATTERNS ===\n  behaviors_habits string[] @description(\"Observable patterns (work/learn/decide/communicate) + tools/channels/frequency. Keep concrete & falsifiable. Example: 'Checks app daily; prefers SMS'.\")\n  key_tasks string[] | null @description(\"Key tasks this persona performs\")\n  tools_used string[] | null @description(\"Tools or products commonly used by this persona\")\n  frequency_of_purchase string | null @description(\"How often this persona purchases relevant products/services\")\n  frequency_of_use string | null @description(\"How often this persona uses relevant products/services\")\n  triggers_decision_drivers string[] @description(\"What causes action + how choices are made. Example: 'Deadline pressure; peer proof'.\")\n\n  // === PAIN POINTS & CHALLENGES ===\n  pain_points string[] @description(\"Top 3–5 blockers or unmet needs that are actionable for product/design. Example: 'Lack of visibility'; 'Difficulty with setup'.\")\n  frustrations string[] | null @description(\"Top frustrations or pain points\")\n\n  // === PREFERENCES & STYLE ===\n  preferences string | null @description(\"Notable preferences\")\n  learning_style string | null @description(\"Preferred learning style\")\n  tech_comfort_level string | null @description(\"Comfort level with technology\")\n\n  // === EVIDENCE & INSIGHTS ===\n  key_quotes string[] @description(\"1–3 verbatim interview quotes (lightly cleaned). Real language only.\")\n  sources string[] | null @description(\"Main sources of information or influence\")\n  differentiators string[]\n    @description(\"≥3 concrete, behavior/motivation‑based ways this persona differs from others.\")\n    @assert(min_three_diffs, {{ this|length >= 3 }})\n\n  // === RESEARCH METADATA ===\n  confidence string @description(\"Overall confidence: use one of 'Low', 'Medium', 'High'. If evidence_count < 2, MUST be 'Low'.\")\n  evidence_count int @description(\"Distinct interviews supporting this persona. Usually 1 in single‑interview mode.\")\n  hypothesis_notes string @description(\"Brief, falsifiable assumptions awaiting validation. Do not restate facts.\")\n  key_open_questions string[] @description(\"3–5 questions that would confirm/refute this persona in the next interview.\")\n}\n\nclass PersonaSet {\n  personas Persona[]\n    @description(\"Prefer 3–5 active personas; never exceed 5 without explicit authorization.\")\n    @assert(cap_5, {{ this|length <= 5 }})\n\n  version string @description(\"Version vX.Y: X=merges/splits/framework changes; Y=incremental tweaks.\")\n\n  change_log string @description(\"What changed & why: added/removed/merged personas; major field edits; cite evidence counts (e.g., '≥2 interviews').\")\n\n  // When any persona has evidence_count < 2, produce a single contrast persona to probe next.\n  contrast_persona Persona? @description(\"A deliberately different, testable counter‑hypothesis at the opposite end of the salient spectrum. Required if any persona has evidence_count < 2.\")\n}\n\n\n//// Pass 0 — Ingest & Normalize\n\nclass NoteSnippet {\n  tag string @description(\"One of: FACT | QUOTE | GOAL | PAIN | BEHAVIOR | TRIGGER | SUCCESS | IRRELEVANT\")\n  text string @description(\"Cleaned snippet text; QUOTE must be verbatim with minor fixes only.\")\n  speaker string? @description(\"Optional speaker label (e.g., 'User', 'Interviewer', name).\")\n  timestamp string? @description(\"Optional timestamp from source, e.g., '00:13:21'.\")\n}\n\nclass InterviewDoc {\n  source string @description(\"Brief identifier for the interview (file, session id, or date).\")\n  snippets NoteSnippet[] @description(\"Structured, de‑duplicated snippets. Exclude pleasantries and off‑topic content.\")\n}\n\nfunction NormalizeNotes(raw_notes: string) -> InterviewDoc {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Normalize raw interview notes into labeled, concise snippets for UX research.\n\n    Rules:\n    - Keep only domain-relevant content.\n    - Label each snippet with one of: FACT | QUOTE | GOAL | PAIN | BEHAVIOR | TRIGGER | SUCCESS | IRRELEVANT.\n    - QUOTE must be verbatim (light punctuation/grammar fixes allowed).\n    - Merge duplicates; prefer the strongest phrasing.\n    - Preserve any timestamps/speakers if present in the text.\n    - Exclude IRRELEVANT snippets from the final output.\n\n    {{ _.role(\"user\") }}\n    RAW_NOTES:\n    {{ raw_notes }}\n\n    Produce {{ ctx.output_format }} with snippets excluding IRRELEVANT.\n  \"#\n}\n\n//// Pass 1 — Evidence Extract (no synthesis)\n\nclass EvidenceSet {\n  facts string[] @description(\"Objective observations derived from FACT and BEHAVIOR.\")\n  goals string[] @description(\"User outcomes from GOAL only; no features.\")\n  pains string[] @description(\"Actionable problems from PAIN.\")\n  behaviors string[] @description(\"Observable patterns/tools/frequency from BEHAVIOR.\")\n  triggers string[] @description(\"Action triggers + choice drivers from TRIGGER.\")\n  success string[] @description(\"Definitions of success from SUCCESS.\")\n  quotes string[] @description(\"1–5 verbatim quotes representative of the above.\")\n}\n\nfunction ExtractEvidence(doc: InterviewDoc) -> EvidenceSet {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Extract only verifiable evidence from a normalized interview doc.\n    Do NOT invent or generalize beyond provided snippets.\n\n    Rules:\n    - Each output item must map to one or more input snippets.\n    - Use QUOTE text verbatim (light cleanup allowed).\n    - Ignore demographics unless causally tied to use/decisions.\n    - Prefer fewer, stronger items over many weak ones.\n\n    {{ _.role(\"user\") }}\n    INTERVIEW_DOC:\n    {{ doc }}\n\n    Return {{ ctx.output_format }}.\n  \"#\n}\n\n//// Pass 2 — Spectrum Detection\n\nclass Spectrum {\n  axis string @description(\"Primary axis of variation to test next, formatted as 'X ↔ Y', e.g., 'Autonomy ↔ Guidance'.\")\n  rationale string @description(\"Why this axis matters for product decisions (onboarding, content, help, messaging).\")\n  supporting_evidence string[] @description(\"Bullets referencing facts/quotes that point to this axis.\")\n  alternatives string[] @description(\"Up to 2 runner-up axes considered (same 'X ↔ Y' format) with a 1‑line reason each.\")\n}\n\nfunction FindSpectrum(evidence: EvidenceSet) -> Spectrum {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Select the strongest behavioral/motivational spectrum to anchor a contrast persona.\n\n    Candidate axes (examples; choose the most decision-impacting):\n    - Autonomy ↔ Guidance\n    - Planner ↔ Sprinter\n    - Depth ↔ Speed\n    - Social proof ↔ Solo\n    - Exploration ↔ Checklists\n\n    Rules:\n    - Pick ONE primary axis that most changes the product/design choices now.\n    - Provide concise rationale and cite the most relevant evidence items.\n    - List up to 2 alternatives only if close contenders.\n\n    {{ _.role(\"user\") }}\n    EVIDENCE_SET:\n    {{ evidence }}\n\n    Return {{ ctx.output_format }} with a single primary axis.\n  \"#\n}\n\n//// Pass 3 — Draft Provisional Persona (N=1 discipline)\n\nfunction DraftProvisionalPersona(evidence: EvidenceSet, spectrum: Spectrum) -> Persona {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Draft a provisional persona from evidence only (no invention).\n    Single‑interview discipline: confidence must be \"Low\" and evidence_count = 1.\n\n    Rules:\n    - Populate fields ONLY with content grounded in the EvidenceSet (facts, goals, pains, behaviors, triggers, success, quotes).\n    - Use 1–3 verbatim quotes (light cleanup allowed). If none fit, leave key_quotes empty.\n    - Provide ≥3 differentiators (behavior/motivation‑based), tied to the chosen spectrum: {{ spectrum.axis }}.\n    - Do NOT include demographics unless causally relevant to use/decisions.\n    - Fill hypothesis_notes with crisp, falsifiable assumptions (what you would expect to hold if this persona is real).\n    - Provide 3–5 key_open_questions that will confirm/refute this persona next interview.\n    - Set confidence = \"Low\" and evidence_count = 1.\n\n    {{ _.role(\"user\") }}\n    EVIDENCE_SET:\n    {{ evidence }}\n\n    PRIMARY_SPECTRUM:\n    {{ spectrum }}\n\n    Produce {{ ctx.output_format }}.\n  \"#\n}\n\n//// Pass 4 — Draft Contrast Persona (counter‑hypothesis at opposite spectrum end)\n\nfunction DraftContrastPersona(provisional: Persona, spectrum: Spectrum) -> Persona {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    Create ONE contrast persona positioned at the opposite end of the primary spectrum.\n    This is a counter‑hypothesis used to disambiguate in the next interview.\n\n    Rules:\n    - Place this persona at the OPPOSITE end of {{ spectrum.axis }} relative to the provisional persona.\n    - Provide ≥3 differentiators that DO NOT overlap with the provisional’s differentiators.\n    - Keep it lean: include only fields necessary to design a test (but return a valid Persona object).\n    - Do NOT invent quotes; key_quotes can be empty.\n    - Set confidence = \"Low\" and evidence_count = 1.\n    - key_open_questions should focus on disambiguating THIS contrast from the provisional.\n\n    {{ _.role(\"user\") }}\n    PROVISIONAL_PERSONA:\n    {{ provisional }}\n\n    PRIMARY_SPECTRUM:\n    {{ spectrum }}\n\n    Produce {{ ctx.output_format }}.\n  \"#\n}\n\n\nfunction RefinePersonas(existing_persona_set: PersonaSet, new_interview_notes: string) -> PersonaSet {\n  client \"openai/gpt-5-mini\"\n\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a UX researcher updating a living persona set from new interview notes.\n    Return ONLY a valid PersonaSet JSON per the schema; no extra commentary.\n\n    Hard rules:\n    1) Evidence threshold: Add/change traits only if supported by ≥2 independent interview findings.\n    2) Max differentiation: Each persona must include ≥3 behavior/motivation differentiators.\n    3) Merge overlap: If two personas share >70% core needs/motivations, MERGE and keep strongest diffs.\n    4) Count cap: Keep ≤5 personas unless explicitly authorized.\n    5) Spectrum strategy: When patterns form a continuum (e.g., DIY ↔ Guided), place personas at distinct ends; add one middle only if necessary.\n    6) Demographics: Include only when they causally affect use/decisions; otherwise omit.\n    7) Actionability filter: Omit details that won’t change product, design, or messaging decisions.\n    8) Versioning: Bump version (vX.Y). Major bump (X) for merges/splits/framework changes; minor bump (Y) for incremental tweaks.\n    9) Change log: Summarize additions/removals/merges and key edits with brief evidence references (e.g., “3/5 interviews mention …”).\n\n    Single‑interview mode:\n    - If any resulting persona has evidence_count < 2:\n      * Set confidence=\"Low\" for that persona.\n      * Provide exactly one contrast_persona at the opposite end of the primary behavioral/motivational spectrum.\n      * Populate hypothesis_notes with crisp, falsifiable assumptions.\n      * Provide 3–5 key_open_questions to disambiguate in the next interview.\n      * Prefer leaving fields empty over guessing beyond notes/first‑party telemetry.\n\n    {{ _.role(\"user\") }}\n    CURRENT_SET:\n    {{ existing_persona_set }}\n\n    NEW_INTERVIEW_NOTES:\n    {{ new_interview_notes }}\n\n    Produce the updated persona set strictly as per the schema below.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\nfunction ExtractPersona(people: string, insights: string, interviews: string, evidence: string) -> Persona {\n  client \"CustomGPT5Mini\"\n  prompt #\"\n    You are an expert UX researcher. Given the following people records and their insights, generate a detailed persona profile.\n\n    1. Create a UX persona that represents the people records and insights.\n       - Use up to 3 words for a catchy name.\n       - Write a 3-7 sentence description summarizing behavior, pain, motivations, and preferences.\n    2. For each of the following fields, aggregate and summarize the most common or representative value(s) from the data:\n       - age, gender, location, education, occupation, income, languages, segment, role, color_hex, image_url\n       - motivations, values, frustrations, preferences, learning_style, tech_comfort_level\n       - frequency_of_purchase, frequency_of_use, key_tasks, tools_used, primary_goal, secondary_goals, sources, quotes, percentage\n    3. For array fields, provide 2-5 representative items. For string fields, provide the most common or relevant value.\n    4. Use direct quotes from the data where possible for the 'quotes' field.\n    5. If a field is not present in the data, return null.\n\n\t\tInterview records:\n\t\t{{ interviews }}\n\n\t\tEvidence records:\n\t\t{{ evidence }}\n\n    People records:\n    {{ people }}\n\n    Insights:\n    {{ insights }}\n\n\t  Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GeneratePersonas(interviews: string | null, people: string | null, insights: string | null, evidence: string | null) -> Persona[] {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    You are an expert UX researcher and strategist. Below are a mixture of transcribed conversations, interviews, notes, and insights.\n\t\tYour task is to generate 4 personas based on the data.\n\n\t\t1. Find each distinct persona in the data, summarizing each as a Persona object in a descriptive manner to help us identify other people like them.\n    - For each persona, fill out all fields in the Persona schema, using the most representative or common values.\n    - For array fields, provide 2-5 representative items. For string fields, provide the most common or relevant value.\n    - Use direct quotes from the data where possible for the 'quotes' field.\n    - If a field is not present in the data, return null.\n\n    2. Generate a up to 3 additional personas that are not present but would be expected in this context, based on gaps or patterns in the data. Mark these as 'projected' in the description.\n\n\t\tDo not group people into personas that are too different from each other.\n\n\t\tDO Not generate personas that are too similar to each other.\n\n\t\tInterview records:\n\t\t{{ interviews }}\n\n\t\tEvidence records:\n\t\t{{ evidence }}\n\n    People records:\n    {{ people }}\n\n    Insights:\n    {{ insights }}\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// New intelligent persona assignment decision\nclass PersonaAssignmentDecision {\n  action string @description(\"Either 'assign_existing' or 'create_new'\")\n  persona_id string | null @description(\"ID of existing persona if action is 'assign_existing', null if creating new\")\n  persona_name string | null @description(\"Name of existing persona if assigning, or proposed name for new persona\")\n  confidence_score float @description(\"Confidence in this decision from 0.0 to 1.0\")\n  reasoning string @description(\"Detailed explanation of why this decision was made\")\n  new_persona_data Persona | null @description(\"Complete persona data if action is 'create_new', null otherwise\")\n}\n\nfunction AssignPersonaToInterview(\n  interview_transcript: string,\n  participant_info: string,\n  existing_personas: string\n) -> PersonaAssignmentDecision {\n  client \"CustomGPT4oMini\"\n  prompt #\"\n    You are an expert UX researcher tasked with intelligently assigning an interview participant to either an existing persona or creating a new one.\n\n    DECISION CRITERIA:\n    1. ASSIGN TO EXISTING if the participant shows >70% alignment with an existing persona in:\n       - Core motivations and goals\n       - Key behaviors and patterns\n       - Primary pain points and frustrations\n       - Decision-making triggers\n       - Tech comfort level and preferences\n\n    2. CREATE NEW if the participant represents a distinct archetype that:\n       - Has fundamentally different motivations or goals\n       - Shows unique behavioral patterns not captured by existing personas\n       - Has different pain points or success definitions\n       - Represents a new segment or user type\n\n    ANALYSIS PROCESS:\n    1. Extract key characteristics from the interview transcript and participant info\n    2. Compare against each existing persona systematically\n    3. Calculate alignment percentage for each existing persona\n    4. If highest alignment is >70%, assign to that persona\n    5. If all alignments are <70%, create a new persona\n\n    INTERVIEW TRANSCRIPT:\n    {{ interview_transcript }}\n\n    PARTICIPANT INFO:\n    {{ participant_info }}\n\n    EXISTING PERSONAS:\n    {{ existing_personas }}\n\n    Return a PersonaAssignmentDecision with:\n    - Clear action (assign_existing or create_new)\n    - Persona ID/name if assigning to existing\n    - Confidence score (0.0-1.0)\n    - Detailed reasoning for the decision\n    - Complete new persona data if creating new (following the Persona schema)\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "extract_persona.tests.baml": "// Tests for persona extraction and assignment functions\n\n// ── NormalizeNotes: raw interview notes ──────────────────────────────\ntest NormalizeNotes_RawFieldNotes {\n  functions [NormalizeNotes]\n  args {\n    raw_notes #\"\n      Interview with Maria, 34, product manager at a mid-size SaaS company\n      Date: 2026-01-15\n\n      She said \"I spend more time in meetings about the roadmap than actually building the roadmap\"\n\n      Uses Notion for specs, Linear for tracking, Figma for design reviews\n      Checks Linear 8-10 times per day\n      Frustrated that stakeholder requests come through Slack DMs instead of a formal process\n\n      When asked about her biggest challenge:\n      \"Honestly the hardest part is saying no. Every team thinks their feature is the most important\n      and I don't have good data to back up prioritization decisions.\"\n\n      Goal: wants to make data-driven prioritization decisions\n      Currently relies on gut feel and loudest voice in the room\n\n      Interviewer note: She seemed really energized when talking about using customer evidence\n      to push back on HiPPO decisions. This is clearly a pain point she's passionate about.\n\n      Off-topic: discussed lunch plans, weather\n    \"#\n  }\n}\n\n// ── NormalizeNotes: messy voice memo transcript ──────────────────────\ntest NormalizeNotes_VoiceMemo {\n  functions [NormalizeNotes]\n  args {\n    raw_notes #\"\n      ok so just got off the call with the acme team, few things to note...\n      um they're using spreadsheets for everything, like literally tracking\n      customer health scores in google sheets... the CS lead, Jamie, said\n      quote \"we know we need a real tool but every time we evaluate something\n      it's either too expensive or too complicated to set up\" end quote.\n      Also interesting - they have 200 customers but only 3 CS reps.\n      That's wild. ratio is way off. they're basically firefighting all day.\n      Jamie mentioned she stays late most nights just to keep up.\n      oh and they want something that integrates with hubspot, that's a must-have.\n    \"#\n  }\n}\n\n// ── ExtractEvidence from normalized doc ──────────────────────────────\ntest ExtractEvidence_FromNormalizedDoc {\n  functions [ExtractEvidence]\n  args {\n    doc {\n      source \"Interview with Maria, PM at SaaS Co - 2026-01-15\"\n      snippets [\n        {\n          tag \"QUOTE\"\n          text \"I spend more time in meetings about the roadmap than actually building the roadmap\"\n          speaker \"Maria\"\n          timestamp \"00:03:21\"\n        },\n        {\n          tag \"PAIN\"\n          text \"Stakeholder requests come through Slack DMs instead of a formal intake process, making prioritization impossible\"\n          speaker \"Maria\"\n          timestamp null\n        },\n        {\n          tag \"BEHAVIOR\"\n          text \"Checks Linear 8-10 times per day for status updates\"\n          speaker \"Maria\"\n          timestamp null\n        },\n        {\n          tag \"GOAL\"\n          text \"Wants to make data-driven prioritization decisions instead of relying on gut feel\"\n          speaker \"Maria\"\n          timestamp null\n        },\n        {\n          tag \"QUOTE\"\n          text \"The hardest part is saying no. Every team thinks their feature is the most important and I don't have good data to back up prioritization decisions.\"\n          speaker \"Maria\"\n          timestamp \"00:12:45\"\n        },\n        {\n          tag \"TRIGGER\"\n          text \"Gets energized by the idea of using customer evidence to push back on HiPPO decisions\"\n          speaker null\n          timestamp null\n        },\n        {\n          tag \"FACT\"\n          text \"Uses Notion for specs, Linear for tracking, Figma for design reviews\"\n          speaker \"Maria\"\n          timestamp null\n        }\n      ]\n    }\n  }\n}\n\n// ── AssignPersonaToInterview: should assign existing ─────────────────\ntest AssignPersona_MatchExisting {\n  functions [AssignPersonaToInterview]\n  args {\n    interview_transcript #\"\n      Interviewer: Tell me about your role.\n      Participant: I'm a product manager at a 50-person startup. I own the roadmap for our core platform.\n      Interviewer: What's your biggest challenge?\n      Participant: Prioritization. Everyone wants their feature built first and I don't have enough data to make objective trade-offs. I end up relying on whoever is loudest.\n      Interviewer: What tools do you use?\n      Participant: Linear for tracking, Notion for specs. I check Linear probably 10 times a day. We do weekly stakeholder reviews but honestly most requests come through Slack DMs.\n      Interviewer: What would make your job easier?\n      Participant: Real customer evidence I can point to. Like, here's what 15 customers said about this problem. That would change how I prioritize completely.\n    \"#\n    participant_info \"Sarah Chen, Product Manager, 32, Series B startup, 50 employees\"\n    existing_personas #\"\n      [\n        {\n          \"id\": \"persona-001\",\n          \"name\": \"The Data-Hungry PM\",\n          \"description\": \"Mid-career product manager at growth-stage startup who struggles with evidence-based prioritization. Drowning in stakeholder requests via informal channels. Wants objective data to defend roadmap decisions.\",\n          \"goals\": [\"Make data-driven prioritization decisions\", \"Reduce time in status meetings\", \"Build credibility with stakeholders\"],\n          \"pain_points\": [\"No formal request intake\", \"Gut-feel prioritization\", \"Too many meetings\"],\n          \"behaviors_habits\": [\"Checks project tracker 8-10x daily\", \"Uses Notion + Linear stack\", \"Weekly stakeholder reviews\"],\n          \"evidence_count\": 3,\n          \"confidence\": \"Medium\"\n        },\n        {\n          \"id\": \"persona-002\",\n          \"name\": \"The Firefighting CS Lead\",\n          \"description\": \"Customer success manager at understaffed team managing 60+ accounts solo. Reactive by necessity, wants proactive health monitoring.\",\n          \"goals\": [\"Proactive churn prevention\", \"Scale without hiring\"],\n          \"pain_points\": [\"Too many accounts per rep\", \"Manual health scoring\", \"No early warning system\"],\n          \"behaviors_habits\": [\"Spreadsheet-based tracking\", \"Stays late most nights\", \"Triages by gut feel\"],\n          \"evidence_count\": 1,\n          \"confidence\": \"Low\"\n        }\n      ]\n    \"#\n  }\n}\n\n// ── AssignPersonaToInterview: should create new ──────────────────────\ntest AssignPersona_CreateNew {\n  functions [AssignPersonaToInterview]\n  args {\n    interview_transcript #\"\n      Interviewer: What's your role?\n      Participant: I'm head of sales engineering. I lead a team of 8 SEs who do demos and technical evaluations for enterprise deals.\n      Interviewer: What's the biggest bottleneck in your process?\n      Participant: Creating custom demo environments. Each prospect wants to see their specific use case and it takes us 2-3 days to spin up a tailored demo. We lose deals because competitors can show something faster.\n      Interviewer: How do you decide which deals to prioritize?\n      Participant: Deal size and close probability. But honestly we're guessing on probability. We don't have good signals from the sales calls about how serious a prospect is.\n      Interviewer: What would help most?\n      Participant: Two things - a way to create demo environments in hours not days, and better intelligence from discovery calls so we know what to demo.\n    \"#\n    participant_info \"James Park, Head of Sales Engineering, Enterprise SaaS, 45 employees\"\n    existing_personas #\"\n      [\n        {\n          \"id\": \"persona-001\",\n          \"name\": \"The Data-Hungry PM\",\n          \"description\": \"Mid-career product manager at growth-stage startup who struggles with evidence-based prioritization.\",\n          \"goals\": [\"Make data-driven prioritization decisions\"],\n          \"pain_points\": [\"No formal request intake\", \"Gut-feel prioritization\"],\n          \"behaviors_habits\": [\"Checks project tracker 8-10x daily\"],\n          \"evidence_count\": 3,\n          \"confidence\": \"Medium\"\n        }\n      ]\n    \"#\n  }\n}\n",
  "generate_lens_template.baml": "// Generate a lens template from natural language description\n// Used for custom lens creation\n\nclass GeneratedLensField {\n  field_key string @description(\"Lowercase snake_case identifier, e.g. 'pain_points', 'budget_range'\")\n  field_name string @description(\"Human-readable field label, e.g. 'Pain Points', 'Budget Range'\")\n  field_type \"text\" | \"text_array\" | \"numeric\" | \"date\" | \"boolean\" @description(\"Data type for this field\")\n  description string? @description(\"Brief explanation of what this field captures\")\n}\n\nclass GeneratedLensSection {\n  section_key string @description(\"Lowercase snake_case identifier, e.g. 'problem_space', 'qualification'\")\n  section_name string @description(\"Human-readable section title, e.g. 'Problem Space', 'Qualification'\")\n  description string? @description(\"Brief explanation of what this section captures\")\n  fields GeneratedLensField[] @description(\"2-6 fields in this section\")\n}\n\nclass GeneratedLensTemplate {\n  template_name string @description(\"Short, descriptive name for the lens (2-5 words), e.g. 'Competitive Analysis', 'HR Interview'\")\n  summary string @description(\"One sentence describing what this lens extracts\")\n  primary_objective string @description(\"The main goal of applying this lens\")\n  sections GeneratedLensSection[] @description(\"2-5 sections grouping related fields\")\n  entities string[] @description(\"Entity types to extract. Valid values: 'stakeholders', 'next_steps', 'objections'. Use empty array if none apply.\")\n  recommendations_enabled bool @description(\"Whether to generate actionable recommendations\")\n}\n\nfunction GenerateLensTemplate(\n  user_description: string,\n  example_context: string?\n) -> GeneratedLensTemplate {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert at designing conversation analysis frameworks.\n    Create a structured lens template based on the user's description.\n\n    ## User's Description\n    {{ user_description }}\n\n    {% if example_context %}\n    ## Additional Context About Their Use Case\n    {{ example_context }}\n    {% endif %}\n\n    ## Guidelines\n\n    1. **Naming**: Create a short, clear template_name (2-5 words). Use Title Case.\n\n    2. **Sections**: Design 2-5 logical sections that group related information.\n       - Each section should have a clear purpose\n       - Use snake_case for section_key\n       - Use Title Case for section_name\n\n    3. **Fields**: Each section should have 2-6 fields.\n       - Use appropriate field types:\n         - `text`: Single value or summary (budget amount, main pain point, timeline)\n         - `text_array`: Multiple items (features requested, competitors mentioned, objections raised)\n         - `numeric`: Numbers or scores (satisfaction rating 1-10, team size, budget amount)\n         - `date`: Dates (deadline, next meeting, contract renewal)\n         - `boolean`: Yes/no flags (has budget approved, is decision maker)\n       - Use snake_case for field_key\n       - Use Title Case for field_name\n\n    4. **Entities**: Only include entity types if genuinely relevant:\n       - `stakeholders`: Include if the lens should track people, their roles, and influence\n       - `next_steps`: Include if action items and follow-ups are important\n       - `objections`: Include if concerns, blockers, or risks should be tracked\n       - Use empty array [] if none of these apply\n\n    5. **Recommendations**: Enable if actionable insights would be valuable (usually true for sales, research, product lenses)\n\n    ## Examples of Good Section Design\n\n    For a **Sales Discovery** lens:\n    - sections: qualification, pain_points, current_state, decision_process\n    - entities: [\"stakeholders\", \"next_steps\", \"objections\"]\n\n    For a **User Research** lens:\n    - sections: user_context, pain_points, current_workflow, desired_outcomes\n    - entities: [\"stakeholders\"]\n\n    For a **Competitive Intel** lens:\n    - sections: competitor_mentions, feature_comparisons, switching_factors, pricing_intel\n    - entities: []\n\n    For an **HR Interview** lens:\n    - sections: candidate_background, role_fit, culture_fit, concerns\n    - entities: [\"next_steps\"]\n\n    Return a well-structured template that will extract meaningful, actionable insights.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.218.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "goal_lens_extraction.baml": "// Goal-Oriented Lens Extraction\n//\n// Answers specific research goals, decision questions, and unknowns defined in project setup\n\n// ============================================================================\n// Core Goal Classes\n// ============================================================================\n\nclass GoalAnswer {\n  goal_statement string @description(\"The original research goal or question\")\n  answer_summary string @description(\"Direct answer to this goal/question\")\n  confidence string @description(\"Confidence: 'high', 'medium', 'low', 'inconclusive'\")\n  supporting_findings string[] @description(\"Key findings that support this answer\")\n  counterpoints string[] @description(\"Any evidence that contradicts or qualifies the answer\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this answer\")\n}\n\nclass DecisionInsight {\n  decision_question string @description(\"The decision question from project setup\")\n  recommendation string @description(\"Recommended decision based on interview evidence\")\n  rationale string @description(\"Why this recommendation based on evidence\")\n  risks string[] @description(\"Risks or caveats to consider\")\n  confidence string @description(\"Confidence: 'high', 'medium', 'low'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this recommendation\")\n}\n\nclass UnknownResolution {\n  unknown_statement string @description(\"The unknown or uncertainty from project setup\")\n  status string @description(\"Status: 'resolved', 'partially_resolved', 'still_unknown'\")\n  findings string? @description(\"What we learned about this unknown\")\n  remaining_uncertainty string? @description(\"What's still unclear\")\n  suggested_follow_up string? @description(\"How to further explore this\")\n  evidence_ids string[] @description(\"IDs of evidence related to this unknown\")\n}\n\nclass TargetFitAssessment {\n  criterion_type string @description(\"Type: 'org' for organization, 'role' for role/title\")\n  criterion_value string @description(\"The specific org type or role from target criteria\")\n  fit_assessment string @description(\"Fit: 'strong_fit', 'moderate_fit', 'weak_fit', 'not_fit'\")\n  reasoning string @description(\"Why this is/isn't a good fit based on interview\")\n  signals string[] @description(\"Specific signals that indicate fit or lack thereof\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this assessment\")\n}\n\nclass ResearchLearning {\n  learning_statement string @description(\"What we learned from this interview\")\n  relevance_to_goals string @description(\"How this relates to research goals\")\n  actionability string @description(\"What action this suggests\")\n  priority string @description(\"Priority: 'high', 'medium', 'low'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this learning\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass GoalLensExtraction {\n  goal_answers GoalAnswer[] @description(\"Answers to research goals\")\n  decision_insights DecisionInsight[] @description(\"Insights for decision questions\")\n  unknown_resolutions UnknownResolution[] @description(\"Resolution of unknowns/uncertainties\")\n  target_fit TargetFitAssessment[] @description(\"Assessment of fit with target orgs/roles\")\n  research_learnings ResearchLearning[] @description(\"Key learnings relevant to goals\")\n  goal_completion_score float @description(\"Overall score: how well did this interview address goals? (0.0 to 1.0)\")\n  recommended_follow_ups string[] @description(\"Follow-up questions or interviews recommended\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractGoalLens(\n  evidence_json: string,\n  interview_context: string,\n  project_goals: string,\n  decision_questions: string,\n  unknowns: string,\n  target_orgs: string,\n  target_roles: string\n) -> GoalLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are analyzing interview evidence against specific research goals and decision criteria defined for this project.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Project Research Goals\n    {{ project_goals }}\n\n    ## Decision Questions to Answer\n    {{ decision_questions }}\n\n    ## Unknowns/Uncertainties to Resolve\n    {{ unknowns }}\n\n    ## Target Organization Types\n    {{ target_orgs }}\n\n    ## Target Roles/Titles\n    {{ target_roles }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Your task is to directly answer the research goals and decision questions based on the interview evidence.\n\n    ### Goal Answers\n    - For each research goal, provide a direct answer\n    - Summarize key findings that address this goal\n    - Note confidence level based on strength of evidence\n    - Include any counterpoints or qualifications\n\n    ### Decision Insights\n    - For each decision question, provide a recommendation\n    - Explain the rationale based on interview evidence\n    - Note risks or caveats\n    - Assess confidence in the recommendation\n\n    ### Unknown Resolutions\n    - For each unknown/uncertainty, assess if it was resolved\n    - What did we learn?\n    - What's still unclear?\n    - Suggest how to further explore unresolved unknowns\n\n    ### Target Fit Assessment\n    - Assess how well the interviewee fits target org/role criteria\n    - Note specific signals from the interview\n    - Consider: do they exhibit the characteristics we're looking for?\n    - This helps determine if we should interview more people like them\n\n    ### Research Learnings\n    - Key learnings that are relevant to research goals\n    - Prioritize learnings by actionability\n    - Connect learnings back to goals\n\n    ### Goal Completion Score\n    - Calculate how well this interview addressed the research goals\n    - 1.0 = fully addressed all goals, 0.0 = addressed none\n    - Consider coverage and depth\n\n    ### Recommended Follow-Ups\n    - What follow-up questions emerged?\n    - What should we explore in future interviews?\n    - Who else should we talk to?\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "infer_person_segments.baml": "// Infer job_function and seniority_level from a person's title\n\nenum JobFunction {\n  Engineering @description(\"Software engineering, development, DevOps, SRE, QA\")\n  Product @description(\"Product management, product owner, product design\")\n  Design @description(\"UX/UI design, graphic design, creative\")\n  Sales @description(\"Sales, account executive, business development\")\n  Marketing @description(\"Marketing, growth, demand gen, content\")\n  CustomerSuccess @description(\"Customer success, support, account management\")\n  Operations @description(\"Operations, RevOps, BizOps, procurement\")\n  Finance @description(\"Finance, accounting, FP&A\")\n  HR @description(\"Human resources, people ops, recruiting, talent\")\n  Legal @description(\"Legal, compliance, contracts\")\n  Executive @description(\"CEO, founder, general management\")\n  Data @description(\"Data science, analytics, BI, data engineering\")\n  IT @description(\"IT, infrastructure, systems admin\")\n  Research @description(\"User research, market research, insights\")\n  Other @description(\"Does not fit other categories\")\n}\n\nenum SeniorityLevel {\n  CLevel @description(\"CEO, CTO, CFO, CMO, CRO, COO, Chief\")\n  VP @description(\"VP, Vice President, SVP, EVP\")\n  Director @description(\"Director, Senior Director, Head of\")\n  Manager @description(\"Manager, Senior Manager, Team Lead\")\n  Senior @description(\"Senior individual contributor, Staff, Principal\")\n  IC @description(\"Individual contributor, Associate, Analyst, Junior\")\n  Intern @description(\"Intern, Trainee, Apprentice\")\n  Unknown @description(\"Cannot determine seniority from title\")\n}\n\nclass PersonSegmentInput {\n  title string | null @description(\"Job title like 'VP of Engineering' or 'Senior Product Manager'\")\n  role string | null @description(\"DEPRECATED: No longer populated. Will always be null. Kept for schema compatibility.\")\n  company string | null @description(\"Company name for additional context\")\n}\n\nclass InferredPersonSegments {\n  job_function JobFunction @description(\"Primary job function inferred from title\")\n  seniority_level SeniorityLevel @description(\"Seniority level inferred from title\")\n  confidence float @description(\"0-1 confidence in the inference, lower if title is ambiguous\")\n}\n\nfunction InferPersonSegments(input: PersonSegmentInput) -> InferredPersonSegments {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a job title classifier. Given a person's title, infer their:\n    1. Job function (Engineering, Product, Sales, Marketing, etc.)\n    2. Seniority level (C-Level, VP, Director, Manager, Senior IC, IC, etc.)\n\n    Rules:\n    - Use the title as the primary signal, role as backup context\n    - \"Head of X\" typically maps to Director level\n    - \"Lead\" without manager typically maps to Senior IC\n    - Founders/Co-founders map to Executive function and C-Level seniority\n    - When uncertain, use the closest match with lower confidence\n\n    {{ _.role(\"user\") }}\n    Classify this person:\n    Title: {{ input.title or \"(none)\" }}\n    Role: {{ input.role or \"(none)\" }}\n    Company: {{ input.company or \"(unknown)\" }}\n\n    Respond with {{ ctx.output_format }}.\n  \"#\n}\n",
  "map_spreadsheet_columns.baml": "// Map spreadsheet columns to CRM fields using LLM intelligence\n// This provides accurate column mapping for contact/people imports\n//\n// 2-Step Validation Flow:\n// 1. parseSpreadsheet → MapSpreadsheetColumns (this function) → saves to project_assets\n// 2. User reviews/confirms → importPeopleFromTable → creates CRM records\n//\n// The LLM analysis provides:\n// - column_mapping: Standard CRM field mappings\n// - suggested_facets: Custom columns (event signups, surveys) to import as facets\n// - unmapped_columns: Columns that couldn't be classified\n// - warnings: Data quality issues to review before import\n\nclass SpreadsheetColumnMapping {\n  // Name fields - IMPORTANT: Only set ONE of these based on the actual column structure\n  // If there's a single \"Name\" column with full names like \"John Smith\", set `name` and leave firstname/lastname null\n  // If there are separate \"First Name\" and \"Last Name\" columns, set those and leave `name` null\n  name string? @description(\"Column containing FULL NAME (e.g., 'John Smith'). Only set if there's a single combined name column.\")\n  firstname string? @description(\"Column containing FIRST NAME ONLY (e.g., 'John'). Only set if there's a separate first name column.\")\n  lastname string? @description(\"Column containing LAST NAME ONLY (e.g., 'Smith'). Only set if there's a separate last name column.\")\n\n  // Primary contact info\n  email string? @description(\"Column containing email address\")\n  phone string? @description(\"Column containing phone number\")\n  website string? @description(\"Column containing personal or company website URL\")\n  address string? @description(\"Column containing full mailing/street address\")\n\n  // Social profiles\n  linkedin string? @description(\"Column containing LinkedIn URL or profile handle\")\n  twitter string? @description(\"Column containing Twitter/X URL or @handle\")\n  instagram string? @description(\"Column containing Instagram URL or handle\")\n  tiktok string? @description(\"Column containing TikTok URL or handle\")\n\n  // Professional info\n  title string? @description(\"Column containing job title (e.g., 'VP of Sales', 'Software Engineer')\")\n  company string? @description(\"Column containing company/organization name\")\n  role string? @description(\"Column containing role or job function (if different from title)\")\n  industry string? @description(\"Column containing industry or sector\")\n  location string? @description(\"Column containing location, city, or region (not full address)\")\n\n  // Company context\n  company_stage string? @description(\"Column containing company stage (Startup, Growth, Enterprise) or funding stage\")\n  company_size string? @description(\"Column containing employee count or size range (1-10, 11-50, etc.)\")\n\n  // Company metrics\n  company_url string? @description(\"Column containing company website URL or domain\")\n  annual_revenue string? @description(\"Column containing company annual revenue (ARR, revenue, etc.)\")\n  market_cap string? @description(\"Column containing company market capitalization\")\n  funding_stage string? @description(\"Column containing funding stage (Seed, Series A, Series B, Pre-IPO, etc.)\")\n  total_funding string? @description(\"Column containing total funding raised amount\")\n\n  // Segmentation\n  segment string? @description(\"Column containing customer segment or type\")\n  lifecycle_stage string? @description(\"Column containing lifecycle stage or lead status\")\n}\n\nclass SpreadsheetAnalysis {\n  column_mapping SpreadsheetColumnMapping @description(\"Mapping of spreadsheet columns to CRM fields\")\n  confidence float @description(\"Confidence score 0-1 for the mapping accuracy\")\n  unmapped_columns string[] @description(\"Columns that don't map to standard CRM fields - these could be custom facets\")\n  suggested_facets SuggestedFacet[] @description(\"Suggestions for unmapped columns that could be imported as facets\")\n  warnings string[] @description(\"Any warnings or issues detected with the data\")\n}\n\nclass SuggestedFacet {\n  column string @description(\"The column name from the spreadsheet\")\n  facet_kind string @description(\"Suggested facet kind slug: 'event' (event signups), 'survey_response' (form answers), 'preference' (interests/choices), 'tool' (software used), 'custom' (other)\")\n  sample_values string[] @description(\"2-3 example values from the column to help understand the data\")\n  reason string @description(\"Why this column should be a facet\")\n}\n\nfunction MapSpreadsheetColumns(\n  headers: string[],\n  sample_rows: string[][],\n  data_context: string?\n) -> SpreadsheetAnalysis {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert at analyzing spreadsheet data and mapping columns to CRM fields.\n\n    CRITICAL RULES FOR NAME MAPPING:\n    1. If there is ONE column with full names (like \"Name\" containing \"John Smith\"), map it to `name` ONLY\n    2. If there are TWO separate columns for first and last name, map them to `firstname` and `lastname`\n    3. NEVER map the same column to multiple name fields\n    4. NEVER map a full name column to firstname or lastname - that causes data corruption\n\n    Look at the ACTUAL DATA VALUES to determine the column type:\n    - \"John Smith\" = full name → use `name`\n    - \"John\" in one column, \"Smith\" in another = separate → use `firstname` and `lastname`\n\n    SOCIAL PROFILE DETECTION:\n    - twitter: Twitter, X, @handle columns → look for twitter.com URLs or @handles\n    - instagram: Instagram, IG columns → look for instagram.com URLs or handles\n    - tiktok: TikTok columns → look for tiktok.com URLs or handles\n    - linkedin: LinkedIn columns → look for linkedin.com URLs\n\n    ADDRESS vs LOCATION:\n    - address: Full mailing address with street, city, zip (e.g., \"123 Main St, NYC 10001\")\n    - location: City, region, or country only (e.g., \"New York\", \"US\", \"EMEA\")\n\n    COMPANY CONTEXT:\n    - company_stage: Startup, Growth, Series A, Enterprise, etc.\n    - company_size: Employee counts or ranges (1-10, 50-200, etc.)\n\n    COMPANY METRICS (important for B2B data):\n    - company_url: Company website, domain, URL columns\n    - annual_revenue: Revenue, ARR, Annual Revenue columns → look for dollar amounts or revenue figures\n    - market_cap: Market Cap, Valuation columns → look for large dollar figures\n    - funding_stage: Funding Stage, Round columns → Seed, Series A, Series B, Pre-IPO, etc.\n    - total_funding: Total Funding, Funding Raised columns → look for dollar amounts\n\n    Given these spreadsheet headers and sample data, analyze and map the columns.\n\n    Headers: {{ headers }}\n\n    Sample rows (first 5):\n    {% for row in sample_rows %}\n    Row {{ loop.index }}: {{ row }}\n    {% endfor %}\n\n    {% if data_context %}\n    Additional context: {{ data_context }}\n    {% endif %}\n\n    Instructions:\n    1. Examine each column header AND the sample data values\n    2. Map columns to the appropriate CRM fields based on BOTH header names AND actual values\n    3. For name columns: Look at the VALUES to determine if it's full name or first/last\n    4. Identify columns that don't fit standard fields but could be valuable as facets\n    5. For custom columns (event questions, survey answers, preferences), suggest as facets with:\n       - facet_kind: 'event' for event signups, 'survey_response' for form answers, 'preference' for interests, 'custom' for other\n       - sample_values: Include 2-3 example values from the data\n    6. Flag any data quality issues or ambiguities in warnings\n\n    Return your analysis as a SpreadsheetAnalysis object.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "opportunity_advisor.baml": "// AI Advisor for Opportunity Progression\n// Analyzes opportunity context and provides actionable recommendations\n\nclass DealAdvisorRecommendation {\n  status_assessment string @description(\"One-line assessment of current deal status and momentum\")\n  recommendations string[] @description(\"2-3 specific, actionable recommendations for moving the deal forward. Each should be concrete and time-bound.\")\n  risks string[] @description(\"1-2 key risks or blockers that could derail the deal\")\n  confidence string @description(\"Confidence level: high, medium, or low\")\n}\n\nfunction AnalyzeOpportunity(\n  opportunity_title: string,\n  stage: string?,\n  amount: string?,\n  close_date: string?,\n  product_description: string?,\n  notes: string?,\n  stakeholders: string, // JSON string of stakeholder data\n  next_steps: string, // JSON string of next steps\n  linked_interviews: string, // JSON string of interview titles and dates\n) -> DealAdvisorRecommendation {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert sales strategist analyzing an opportunity to provide actionable guidance.\n\n    OPPORTUNITY CONTEXT:\n    - Title: {{ opportunity_title }}\n    {% if stage %}- Stage: {{ stage }}{% endif %}\n    {% if amount %}- Deal Value: ${{ amount }}{% endif %}\n    {% if close_date %}- Expected Close: {{ close_date }}{% endif %}\n    {% if product_description %}- Product: {{ product_description }}{% endif %}\n    {% if notes %}- Notes: {{ notes }}{% endif %}\n\n    STAKEHOLDER MATRIX:\n    {{ stakeholders }}\n\n    NEXT STEPS:\n    {{ next_steps }}\n\n    {% if linked_interviews %}\n    RECENT INTERVIEWS:\n    {{ linked_interviews }}\n    {% endif %}\n\n    YOUR TASK:\n    Analyze this opportunity and provide strategic guidance on how to advance it toward close.\n\n    Focus on:\n    1. STAKEHOLDER COVERAGE: Are we engaging the right people? Do we have access to decision makers?\n    2. MOMENTUM: Are next steps clear, owned, and time-bound? Is there forward progress?\n    3. QUALIFICATION: Is this a real opportunity? Do we understand their buying process?\n    4. RISKS: What could prevent this from closing? What's missing?\n\n    CRITICAL REQUIREMENTS:\n    - Status assessment should be ONE sentence that captures the current state and momentum\n    - Recommendations should be 2-3 SPECIFIC, ACTIONABLE items with clear next steps\n    - Each recommendation should indicate WHO should do WHAT by WHEN (or suggest timing)\n    - Risks should be 1-2 concrete blockers or red flags, not generic concerns\n    - Be direct and prescriptive - this is for the sales team to take action on\n    - Don't hedge or be vague - commit to a perspective based on the data\n\n    EXAMPLES OF GOOD RECOMMENDATIONS:\n    - \"Schedule a technical deep-dive with Engineering VP within 2 weeks to validate feasibility\"\n    - \"Request introduction to CFO by June 15th to discuss budget approval process\"\n    - \"Send ROI analysis to Champion by EOW to arm them for internal advocacy\"\n\n    EXAMPLES OF BAD RECOMMENDATIONS:\n    - \"Continue building relationships\" (too vague)\n    - \"Stay in touch\" (no action or timing)\n    - \"Be patient\" (not actionable)\n\n    Return a structured response with:\n    - status_assessment: one clear sentence\n    - recommendations: array of 2-3 specific actions\n    - risks: array of 1-2 concrete blockers\n    - confidence: \"high\", \"medium\", or \"low\" based on data quality and deal momentum\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "pain_matrix_insights.baml": "// Pain Matrix Insights Generation\n\nclass PainMatrixInsightsInput {\n  total_pains int @description(\"Total number of pain themes identified\")\n  total_groups int @description(\"Total number of user segments/groups\")\n  total_evidence int @description(\"Total evidence items analyzed\")\n  high_impact_cells int @description(\"Number of high-impact pain×segment combinations (impact ≥2.0)\")\n\n  top_pains TopPainCell[] @description(\"Top 5-10 pain×segment combinations by impact score\")\n}\n\nclass TopPainCell {\n  pain_name string @description(\"Name of the pain theme\")\n  user_group string @description(\"Name of the user segment\")\n  impact_score float @description(\"Impact score (person_count × intensity × willingness_to_pay)\")\n  frequency float @description(\"Frequency as decimal (0.0-1.0)\")\n  intensity string @description(\"Intensity level: low, medium, high, critical\")\n  willingness_to_pay string @description(\"WTP level: low, medium, high\")\n  person_count int @description(\"Number of people affected\")\n  evidence_count int @description(\"Number of evidence items\")\n  sample_quote string | null @description(\"Sample verbatim quote from evidence\")\n}\n\nclass PainMatrixInsights {\n  summary string @description(\"1-2 sentence summary of the biggest opportunity (most impactful pain). Be specific with numbers.\")\n  top_3_actions string[] @description(\"Exactly 3 bullet points: what to build/fix first, based on impact scores. Format: '[Pain] for [segment]: [score] impact'\")\n}\n\nfunction GeneratePainMatrixInsights(\n  matrix_data: PainMatrixInsightsInput\n) -> PainMatrixInsights {\n  client CustomGPT4oMini\n  prompt #\"\n    Analyze this pain matrix and provide actionable insights.\n\n    Data:\n    - {{ matrix_data.total_pains }} pains, {{ matrix_data.total_groups }} segments, {{ matrix_data.total_evidence }} evidence items\n    - {{ matrix_data.high_impact_cells }} high-impact cells (≥1.0)\n\n    Top pains by impact:\n    {{ matrix_data.top_pains }}\n\n    Rules:\n    - Be direct. No corporate speak.\n    - If sample size is small (< 30 evidence items) or segments have < 3 people, call it out as low confidence and recommend more interviews\n    - Use actual pain names and segment names from the data\n    - Include impact scores (1 decimal) in your recommendations\n    - Focus on the top 3 highest-impact opportunities\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "parse_survey_guideline.baml": "// Parse natural language survey guidelines into structured branching rules\n// Input: User's natural language + survey questions\n// Output: Structured rules the branching engine can execute\n\nenum ConditionOperator {\n  EQUALS\n  NOT_EQUALS\n  CONTAINS\n  NOT_CONTAINS\n  SELECTED\n  NOT_SELECTED\n  ANSWERED\n  NOT_ANSWERED\n}\n\nenum GuidelineAction {\n  SKIP_TO\n  END_SURVEY\n}\n\nenum RuleConfidence {\n  HIGH\n  MEDIUM\n  LOW\n}\n\nclass SurveyQuestionInput {\n  id string\n  prompt string\n  type string\n  options string[]?\n}\n\nclass ParsedCondition {\n  questionId string @description(\"ID of the question this condition checks\")\n  questionPrompt string @description(\"The question text, for verification\")\n  operator ConditionOperator\n  value string? @description(\"Value to compare against, if applicable\")\n}\n\nclass ParsedGuideline {\n  id string @description(\"Unique identifier like 'gl1', 'gl2'\")\n  naturalLanguage string @description(\"Original user input, preserved for display\")\n  summary string @description(\"Human-readable: 'When sponsors respond, skip to budget questions'\")\n  condition ParsedCondition\n  action GuidelineAction\n  targetQuestionId string? @description(\"For SKIP_TO: which question to jump to\")\n  targetQuestionPrompt string? @description(\"The target question text, for verification\")\n  guidance string? @description(\"AI hint for chat mode: 'Probe on approval process'\")\n  reasoning string @description(\"Why this interpretation makes sense\")\n  confidence RuleConfidence\n  ambiguityNotes string? @description(\"If medium/low confidence, what's unclear\")\n}\n\nclass GuidelineParseResult {\n  guidelines ParsedGuideline[]\n  unparseableSegments string[] @description(\"Parts of input that couldn't be mapped to rules\")\n  suggestedClarifications string[] @description(\"Questions to ask user if ambiguous\")\n  overallConfidence RuleConfidence\n}\n\nfunction ParseSurveyGuidelines(\n  userInput: string,\n  questions: SurveyQuestionInput[],\n  existingGuidelineSummaries: string[]\n) -> GuidelineParseResult {\n  client CustomGPT4oMini\n  prompt #\"\n    You are parsing natural language survey guidelines into structured branching rules.\n\n    USER'S GUIDELINE INPUT:\n    \"{{ userInput }}\"\n\n    AVAILABLE QUESTIONS IN SURVEY:\n    {% for q in questions %}\n    - ID: {{ q.id }} | Type: {{ q.type }} | Prompt: \"{{ q.prompt }}\"\n      {% if q.options %}Options: {{ q.options | join(\", \") }}{% endif %}\n    {% endfor %}\n\n    EXISTING GUIDELINES (avoid conflicts):\n    {% for g in existingGuidelineSummaries %}\n    - {{ g }}\n    {% endfor %}\n\n    PARSING RULES:\n\n    1. IDENTIFY TRIGGER CONDITIONS:\n       - \"If they're a sponsor\" -> condition on a question about role/relationship\n       - \"For enterprise companies\" -> condition on company size question\n       - \"When they mention X\" -> CONTAINS operator on text response\n       - \"If they select Y\" -> EQUALS operator on select question\n       - \"For respondents who...\" -> Look for qualifying question\n\n    2. IDENTIFY ACTIONS:\n       - \"focus on X questions\" -> SKIP_TO the first X-related question\n       - \"skip the budget questions\" -> SKIP_TO question after budget section\n       - \"end the survey\" -> END_SURVEY\n       - \"ask about Y\" -> SKIP_TO the Y question\n\n    3. MATCH TO ACTUAL QUESTIONS:\n       - Map referenced topics to actual question IDs from the list above\n       - If user says \"budget questions\" find questions about budget\n       - If ambiguous, note low confidence and suggest clarification\n\n    4. GENERATE HUMAN-FRIENDLY SUMMARY:\n       - Use natural phrasing: \"When sponsors respond, skip to budget questions\"\n       - Use \"For respondents who...\", \"When...\", \"If...\"\n       - Never say \"rule\" - say \"guideline\" or just describe the behavior\n\n    5. ADD GUIDANCE FOR CHAT MODE:\n       - If the condition implies a persona (sponsor, enterprise, etc.)\n       - Add guidance like \"Probe on ROI expectations\" or \"Focus on scale challenges\"\n\n    6. HANDLE AMBIGUITY:\n       - If multiple questions could match, pick most likely and note uncertainty\n       - If no question matches, add to unparseableSegments\n       - Suggest specific clarifications the user could provide\n\n    7. CONFLICT DETECTION:\n       - Check against existing guidelines for contradictions\n       - Flag if new guideline would make questions unreachable\n\n    OUTPUT HIGH CONFIDENCE WHEN:\n    - User explicitly references question text or options\n    - Clear action verb (skip, end, focus, ask)\n    - Unambiguous condition\n\n    OUTPUT MEDIUM CONFIDENCE WHEN:\n    - Topic references are vague but inferable\n    - Multiple questions could be the trigger (picked most likely)\n\n    OUTPUT LOW CONFIDENCE WHEN:\n    - Cannot confidently match to any question\n    - Action is very unclear\n\n    Return only valid JSON matching the schema:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test for the parser\ntest ParseSponsorGuideline {\n  functions [ParseSurveyGuidelines]\n  args {\n    userInput \"If they're a sponsor, focus on ROI and budget questions\"\n    questions [\n      { id: \"q1\", prompt: \"What's your relationship with us?\", type: \"single_select\", options: [\"Member\", \"Sponsor\", \"Board Member\", \"Attendee\"] },\n      { id: \"q2\", prompt: \"What value do you get from membership?\", type: \"long_text\", options: null },\n      { id: \"q3\", prompt: \"What's your budget for sponsorship?\", type: \"short_text\", options: null },\n      { id: \"q4\", prompt: \"How do you measure ROI?\", type: \"long_text\", options: null }\n    ]\n    existingGuidelineSummaries []\n  }\n}\n",
  "person_facet_lens.baml": "// Summarize a person's facet clusters into short takeaways for lens UI\n\nclass FacetSignalInput {\n  label string @description(\"Human-readable facet label or alias\")\n  source string | null @description(\"Where this facet came from: transcript-derived, manual, survey, etc.\")\n  confidence float | null @description(\"0-1 confidence about this facet\")\n}\n\nclass FacetGroupInput {\n  kind_slug string @description(\"Facet kind, e.g., demographic, task, workflow, pain, goal, value\")\n  kind_label string | null @description(\"Pretty label for the kind\")\n  facets FacetSignalInput[] @description(\"Distinct facets belonging to this kind\")\n}\n\nclass PersonLensMetadata {\n  person_id string @description(\"People table id\")\n  name string | null @description(\"Display name\")\n  title string | null @description(\"Job title/role label\")\n  company string | null @description(\"Company or organization\")\n  segment string | null @description(\"Segment or cohort label\")\n  persona string | null @description(\"Assigned persona name, if any\")\n  quick_facts string[] @description(\"Short factual strings to seed context (role, segment, company, etc.)\")\n}\n\nclass LensEvidenceHighlight {\n  gist string @description(\"<=200 char gist or quote; keep literal wording from source\")\n  interview_title string | null @description(\"Interview title or label\")\n  interview_date string | null @description(\"ISO timestamp of evidence interview\")\n  journey_stage string | null @description(\"Journey stage, if present\")\n  topic string | null @description(\"Tagged topic name\")\n  support string | null @description(\"supports | refutes | neutral\")\n}\n\nclass PersonFacetLensRequest {\n  person PersonLensMetadata @description(\"Person context for anchoring tone\")\n  facet_groups FacetGroupInput[] @description(\"All facet groups to summarize\")\n  evidence_highlights LensEvidenceHighlight[] @description(\"Optional evidence snippets to ground claims\")\n}\n\nclass FacetGroupSummary {\n  kind_slug string @description(\"Facet group being summarized\")\n  summary string @description(\"Concise summary capturing key points; can include multiple items if important, avoid fluff\")\n}\n\nclass PersonFacetLensResponse {\n  summaries FacetGroupSummary[]\n}\n\nfunction SummarizePersonFacetLens(payload: PersonFacetLensRequest) -> PersonFacetLensResponse {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a research summarizer. For each facet group, write a concise summary capturing the most important signals.\n    Style: Similar to pain/gain statements - punchy, concrete, action-oriented, NO FLUFF.\n\n    Rules:\n    - Capture ALL key points, even if it means multiple items (e.g., \"Struggles with data integration • Needs real-time sync • Limited by legacy APIs\")\n    - Use bullet separators (•) for multiple distinct points\n    - Lead with concrete specifics: actions, pains, goals, workflows, constraints\n    - Skip generic qualifiers and filler words\n    - Use evidence to ground claims but stay tight\n    - Never invent details. If thin, write what you know factually\n    - Length: Whatever it takes to capture important signals without fluff (typically 10-40 words)\n    - Each group should feel complete, not artificially truncated\n\n    {{ _.role(\"user\") }}\n    PERSON CONTEXT:\n    {{ payload.person }}\n\n    FACET GROUPS:\n    {{ payload.facet_groups }}\n\n    EVIDENCE HIGHLIGHTS:\n    {{ payload.evidence_highlights }}\n\n    Respond with {{ ctx.output_format }} containing summaries for every facet group.\n  \"#\n}\n",
  "person_next_steps.baml": "// Generate AI-powered recommended next steps for a specific person\n// Based on their profile, conversation history, themes, and relationship context\n\nclass PersonNextStepsInput {\n  name string | null @description(\"Person's name\")\n  title string | null @description(\"Job title\")\n  company string | null @description(\"Company or organization name\")\n  description string | null @description(\"AI-generated person summary, if available\")\n  icp_band string | null @description(\"ICP match band: HIGH, MEDIUM, LOW, or null\")\n  icp_score float | null @description(\"ICP match score 0-1\")\n  days_since_last_contact int | null @description(\"Days since last interaction, null if never contacted\")\n  conversation_count int @description(\"Total number of conversations/interviews\")\n  survey_count int @description(\"Total number of survey responses\")\n  themes string[] @description(\"Theme names this person's evidence supports, ordered by evidence count\")\n  recent_evidence string[] @description(\"Up to 5 recent evidence gists/quotes from this person\")\n  facets string[] @description(\"Person facet labels (e.g., pain points, goals, workflows)\")\n}\n\nclass PersonNextStep {\n  action string @description(\"Concrete, actionable recommendation in imperative form. 10-15 words max. E.g., 'Schedule a follow-up to explore their pricing concerns'\")\n  reasoning string @description(\"Brief context explaining WHY this step matters for this specific person. 1 sentence, under 20 words.\")\n  priority int @description(\"1 = most urgent, 2 = important, 3 = nice to have\")\n}\n\nclass PersonNextStepsOutput {\n  steps PersonNextStep[] @description(\"Exactly 3 recommended next steps, ordered by priority (1 first)\")\n}\n\nfunction GeneratePersonNextSteps(input: PersonNextStepsInput) -> PersonNextStepsOutput {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a customer research advisor helping a product team decide what to do next with a specific contact.\n\n    Your recommendations must be:\n    - SPECIFIC to this person's data (reference their themes, pain points, or quotes)\n    - ACTIONABLE with a clear verb (schedule, send, review, ask, share, investigate)\n    - PRIORITIZED by impact and urgency\n    - VARIED — do not suggest 3 versions of the same action\n\n    Consider these factors when prioritizing:\n    1. RECENCY: Stale relationships (>14 days) need re-engagement\n    2. DEPTH: Few conversations = need more discovery; many = ready for validation\n    3. ICP FIT: High-fit contacts deserve more investment\n    4. THEMES: Unresolved pain points or goals are opportunities\n    5. EVIDENCE GAPS: Missing survey data or shallow theme coverage\n\n    Do NOT suggest:\n    - Generic actions like \"stay in touch\" or \"keep building the relationship\"\n    - Actions that require data you don't have\n    - More than one follow-up/scheduling action\n\n    {{ _.role(\"user\") }}\n    PERSON CONTEXT:\n    {{ input }}\n\n    Return exactly 3 next steps ordered by priority.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "person_profile_summary.baml": "// Generate concise participant descriptions from facet + scale data\n\nclass PersonFacetInput {\n  label string @description(\"Facet label or alias that should be echoed in the summary when relevant\")\n  kind_slug string @description(\"Facet kind slug such as demographic, task, workflow, preference, pain, goal, or value\")\n  source string | null @description(\"Source of the facet (e.g., transcript-derived, manual)\")\n  confidence float | null @description(\"0-1 confidence of the facet\")\n}\n\nclass PersonScaleInput {\n  kind_slug string @description(\"Scale identifier, e.g., adoption_stage, urgency, satisfaction\")\n  score float | null @description(\"Numeric scale score if available\")\n  band string | null @description(\"Qualitative band derived from the score (e.g., high, medium, low)\")\n  source string | null @description(\"Source of the scale reading\")\n  confidence float | null @description(\"0-1 confidence in this measurement\")\n}\n\nclass PersonEvidenceHighlight {\n  gist string @description(\"<=200 character gist or quote taken directly from interview evidence. No embellishment.\")\n  interview_title string | null @description(\"Interview title or internal label for context\")\n  interview_date string | null @description(\"ISO timestamp for when the interview occurred\")\n  journey_stage string | null @description(\"Journey stage noted on the evidence, if any\")\n  topic string | null @description(\"Tagged topic for the evidence snippet\")\n  support string | null @description(\"Support classification: supports | refutes | neutral\")\n}\n\nclass PersonProfileInput {\n  person_id string @description(\"Database ID for the person record\")\n  name string | null @description(\"Preferred name\")\n  title string | null @description(\"Job title or role label\")\n  role string | null @description(\"Functional role if distinct from title\")\n  company string | null @description(\"Company or organization\")\n  segment string | null @description(\"Segment or cohort label\")\n  persona string | null @description(\"Assigned persona name, if any\")\n  quick_facts string[] @description(\"Short factual statements derived from demographics or metadata\")\n  facets PersonFacetInput[] @description(\"Distinct persona facets for the participant\")\n  scales PersonScaleInput[] @description(\"Quantitative scale signals such as adoption, urgency, or satisfaction\")\n  evidence_highlights PersonEvidenceHighlight[] @description(\"Up to 6 concise interview gists that add color to the profile\")\n}\n\nclass PersonDescriptionSummary {\n  summary string @description(\"Describe the type of person in 3-5 short sentences. Each sentence should convey a concrete behavioral, motivational, or contextual point without fluff. Just the facts, as clearly as possible.\")\n}\n\nfunction SummarizePersonProfile(profile: PersonProfileInput) -> PersonDescriptionSummary {\n  client CustomGPT4oMini\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a product researcher summarizing a single participant using curated persona facets.\n    Produce 3-5 crisp sentences that capture the most decision-relevant facts:\n    - Reference the strongest facets (tasks, pains, motivations, workflows, constraints).\n    - Tie in scale bands or scores when they clarify urgency or maturity.\n    - Fold quick_facts into the first sentence for fast context (role, segment, company, persona).\n    - Weave in 1-2 evidence_highlights so each summary has a concrete anecdote or quote; keep them short and attribute context (stage, topic, or interview title) when possible.\n    - Avoid flowery language, filler, and assumptions not supported by the data.\n    - Prefer concrete verbs/nouns over adjectives. Mention only what appears in the input.\n\n    {{ _.role(\"user\") }}\n    PARTICIPANT PROFILE:\n    {{ profile }}\n\n    Respond with {{ ctx.output_format }}.\n  \"#\n}\n",
  "persona_advisor.baml": "// Generate persona story reports that mirror the Opportunity AI Advisor structure.\n\nclass PersonaAdvisorFacetInput {\n  label string @description(\"Facet label or alias that should be echoed in the persona copy\")\n  kind_slug string @description(\"Facet kind such as motivation, value, pain, goal, habit, constraint, preference\")\n  confidence float | null @description(\"Normalized 0-1 confidence score\")\n  source string | null @description(\"Source of the signal, e.g., transcript, survey, manual\")\n}\n\nclass PersonaAdvisorScaleInput {\n  kind_slug string @description(\"Scale slug such as adoption_stage, urgency, satisfaction, readiness\")\n  score float | null @description(\"Numeric score, if available\")\n  band string | null @description(\"Qualitative band like high, medium, low, early, late\")\n  source string | null @description(\"Where the scale comes from\")\n  confidence float | null @description(\"0-1 confidence for this measurement\")\n}\n\nclass PersonaAdvisorThemeInput {\n  title string @description(\"Theme or insight title\")\n  description string | null @description(\"Brief summary or details of the insight\")\n  pain string | null @description(\"Pain description captured by the theme\")\n  desired_outcome string | null @description(\"Desired outcome or benefit\")\n  emotional_response string | null @description(\"Emotional language attached to the insight, if any\")\n  journey_stage string | null @description(\"Journey stage such as discovery, evaluation, use\")\n  category string | null @description(\"Business or product category label\")\n  evidence string[] | null @description(\"Supporting evidence snippets or quotes\")\n  persona_count int | null @description(\"How many personas reference this theme\")\n  priority int | null @description(\"Priority score for ordering the theme\")\n}\n\nclass ResearchInsightInput {\n  title string\n  summary string\n  source string | null\n  evidence string[] | null\n}\n\nclass PersonaAdvisorPersonaInput {\n  name string\n  tagline string | null\n  description string | null\n  quick_facts string[]\n  people_count int\n  percent float | null\n  motivations string[] | null\n  frustrations string[] | null\n  values string[] | null\n  goals string[] | null\n  primary_goal string | null\n  secondary_goals string[] | null\n  preferences string | null\n  tech_comfort_level string | null\n  key_tasks string[] | null\n  tools_used string[] | null\n  quotes string[] | null\n  facets PersonaAdvisorFacetInput[]\n  scales PersonaAdvisorScaleInput[]\n  themes PersonaAdvisorThemeInput[]\n}\n\nclass PersonaAdvisorContext {\n  project_name string\n  project_description string | null\n  personas PersonaAdvisorPersonaInput[]\n  research_insights ResearchInsightInput[]\n  shared_themes PersonaAdvisorThemeInput[]\n  total_personas int\n  total_people int\n}\n\nclass PersonaAdvisorReport {\n  markdown string\n}\n\nfunction GeneratePersonaAdvisorReport(context: PersonaAdvisorContext) -> PersonaAdvisorReport {\n  client CustomGPT4o\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a senior research partner embedded with a product team. Your job is to translate persona data into a crisp, structured markdown report that mirrors the example structure below.\n\n    {{ _.role(\"user\") }}\n    Use the data below to synthesize Persona narratives, shared insights, feature priorities, and positioning guidance.\n\n    PROJECT CONTEXT:\n    - name: {{ context.project_name }}\n    {% if context.project_description %}- description: {{ context.project_description }}{% endif %}\n\n    PERSONAS:\n    {{ context.personas }}\n\n    SHARED THEMES:\n    {{ context.shared_themes }}\n\n    RESEARCH INSIGHTS:\n    {{ context.research_insights }}\n\n    TOTAL PERSONAS: {{ context.total_personas }}\n    TOTAL PARTICIPANTS: {{ context.total_people }}\n\n    REPORT FORMAT (match this structure as closely as possible; use markdown headings, bullet lists, and tables):\n\n    Persona #1 The Name\n    \"Optional representative quote.\"\n\n    Who They Are: <1 short paragraph that references quick facts, the description, and any relevant scale bands.\n\n    Pain Points:\n    - ... (extract 3-4 pains from frustrations, facets, scales, or theme pain strings)\n\n    Motivations:\n    - ... (use motivations, values, and facets that read as drivers)\n\n    What They Love in the product:\n    - ... (tie to themes or positive facets, mention desired outcomes or emotional language)\n\n    User Quotes for recent interviews:\n    - \"Quote 1\"\n    - \"Quote 2\"\n\n    Repeat the persona block for each persona, numbering them in order.\n\n    💡Shared Insights Across Personas - What they both want\n    Shared Values:\n    - ... (use common values or motivation language across personas)\n    Top Feature Priorities:\n    - ... (draw from the shared themes and persona facets)\n    Positioning Guidance:\n    - \"Two supporting positioning lines that reframe the product narrative\"\n\n    🎯 Key Themes to Prioritize in Product & Messaging\n    Priority | Theme | Why It Matters\n    --- | --- | ---\n    High | Theme name | Tie in pain, desired outcome, or emotional response (include persona_count when helpful)\n    Medium | ...\n\n    🧩 Summary: Overlap in Features & Values\n    [Summarize 3 rows in table form or short bullets about reliability, reflection, meaning, privacy, etc.]\n\n    ---\n\n    Research Insights: The Performative Nature of Social Media\n    1. Title of research insight\n    Summary and evidence (cite source)\n\n    Problem Framing\n    <1-2 paragraphs that spotlight the shared tensions revealed by the data and tie back to your product narrative>\n\n    Pull quotes from context.quotes when possible and cite research_insights evidence when you can. Mention scale bands when they explain urgency or readiness. Frame the report around privacy, emotion, and meaningful capture, but do not invent data that is not present. If a section cannot be supported by the data, explain that it is speculative.\n\n    Return only valid markdown in the report string and nothing else.\n\n    Respond with {{ ctx.output_format }}.\n  \"#\n}\n",
  "personalized_survey.baml": "// Personal Touch AI - Personalized Survey Question Generation\n// Generates context-aware questions based on person attributes and project research goals\n\n// ============================================================================\n// CONTEXT CLASSES\n// ============================================================================\n\nclass PersonFacets {\n  pains string[] @description(\"Known pain points from conversations\")\n  goals string[] @description(\"Stated goals and desired outcomes\")\n  workflows string[] @description(\"Current workflows and processes\")\n  tools string[] @description(\"Tools and systems they use\")\n}\n\nclass PersonContext {\n  name string @description(\"Person's full name\")\n  title string? @description(\"Job title (e.g., 'VP Engineering')\")\n  company string? @description(\"Company name\")\n  role string? @description(\"Job function (e.g., 'Engineering', 'Product')\")\n  seniority_level string? @description(\"Seniority (e.g., 'VP', 'IC', 'C-Level')\")\n\n  icp_band string? @description(\"ICP match band: 'Strong', 'Moderate', 'Weak'\")\n  icp_score float? @description(\"ICP match score 0-1\")\n\n  facets PersonFacets @description(\"Known attributes from past conversations\")\n  missing_fields string[] @description(\"Fields we don't have data for (gaps to fill)\")\n  conversation_themes string[] @description(\"Key themes from past interviews\")\n  last_interaction_date string? @description(\"Date of last contact\")\n\n  sparse_mode bool @description(\"True if person has minimal data (discovery mode)\")\n}\n\nclass ThemeValidation {\n  theme_name string @description(\"Name of theme needing validation\")\n  evidence_count int @description(\"Current number of evidence pieces\")\n  target_count int @description(\"Target number for confidence\")\n  confidence string @description(\"Theme confidence: 'low', 'medium', 'high'\")\n}\n\nclass ProjectContext {\n  research_goals string[] @description(\"Project research objectives\")\n  themes_needing_validation ThemeValidation[] @description(\"Themes with low evidence counts\")\n  decision_questions string[] @description(\"Key decisions project needs to make\")\n}\n\nclass SurveyGoal {\n  goal \"validate\" | \"discover\" | \"deep_dive\" | \"pricing\" @description(\"Primary survey objective\")\n  focus_theme string? @description(\"Specific theme to validate (if goal=validate)\")\n  target_segment string? @description(\"Target persona segment\")\n}\n\n// ============================================================================\n// OUTPUT CLASSES\n// ============================================================================\n\nclass PersonalizedQuestion {\n  text string @description(\"The survey question text (conversational, open-ended)\")\n  rationale string @description(\"Why this question for this person (shown to user)\")\n  uses_attributes string[] @description(\"Which person attributes influenced this question\")\n  evidence_type string @description(\"Expected evidence type: pain, goal, workflow, tool, context\")\n  order int @description(\"Priority/order ranking\")\n}\n\n// ============================================================================\n// MAIN GENERATION FUNCTION\n// ============================================================================\n\nfunction GeneratePersonalizedQuestions(\n  person_context: PersonContext,\n  project_context: ProjectContext,\n  survey_goal: SurveyGoal,\n  question_count: int\n) -> PersonalizedQuestion[] {\n  client CustomGPT4o\n\n  prompt #\"\n    You are a research expert generating personalized survey questions for customer research.\n\n    Your goal: Create {{question_count}} questions that feel PERSONAL but not CREEPY,\n    leveraging what we know about this person while filling knowledge gaps.\n\n    ═══════════════════════════════════════════════════════════════════════\n    PERSON CONTEXT\n    ═══════════════════════════════════════════════════════════════════════\n\n    Name: {{person_context.name}}\n    {% if person_context.title %}Title: {{person_context.title}}{% if person_context.company %} at {{person_context.company}}{% endif %}{% endif %}\n    {% if person_context.role %}Role/Function: {{person_context.role}}{% if person_context.seniority_level %}, {{person_context.seniority_level}}{% endif %}{% endif %}\n    {% if person_context.icp_band %}ICP Match: {{person_context.icp_band}}{% if person_context.icp_score %} (Score: {{person_context.icp_score}}){% endif %}{% endif %}\n\n    {% if person_context.sparse_mode %}\n    ⚠️ SPARSE DATA MODE: Person has minimal information. Focus on DISCOVERY questions.\n    {% endif %}\n\n    Known Attributes (from past conversations):\n    {% if person_context.facets.pains %}\n    - Pains: {{person_context.facets.pains | join(\", \")}}\n    {% endif %}\n    {% if person_context.facets.goals %}\n    - Goals: {{person_context.facets.goals | join(\", \")}}\n    {% endif %}\n    {% if person_context.facets.workflows %}\n    - Workflows: {{person_context.facets.workflows | join(\", \")}}\n    {% endif %}\n    {% if person_context.facets.tools %}\n    - Tools: {{person_context.facets.tools | join(\", \")}}\n    {% endif %}\n\n    {% if person_context.missing_fields %}\n    Missing Data (opportunities to fill gaps): {{person_context.missing_fields | join(\", \")}}\n    {% endif %}\n\n    {% if person_context.conversation_themes %}\n    Past Conversation Themes: {{person_context.conversation_themes | join(\", \")}}\n    {% endif %}\n\n    {% if person_context.last_interaction_date %}\n    Last Contact: {{person_context.last_interaction_date}}\n    {% endif %}\n\n    ═══════════════════════════════════════════════════════════════════════\n    PROJECT CONTEXT\n    ═══════════════════════════════════════════════════════════════════════\n\n    {% if project_context.research_goals %}\n    Research Goals:\n    {% for goal in project_context.research_goals %}\n    - {{goal}}\n    {% endfor %}\n    {% endif %}\n\n    {% if project_context.themes_needing_validation %}\n    Themes Needing Validation (low evidence):\n    {% for theme in project_context.themes_needing_validation %}\n    - \"{{theme.theme_name}}\": {{theme.evidence_count}}/{{theme.target_count}} evidence ({{theme.confidence}} confidence)\n    {% endfor %}\n    {% endif %}\n\n    ═══════════════════════════════════════════════════════════════════════\n    SURVEY GOAL\n    ═══════════════════════════════════════════════════════════════════════\n\n    Primary Goal: {{survey_goal.goal | upper}}\n    {% if survey_goal.focus_theme %}Focus Theme: \"{{survey_goal.focus_theme}}\"{% endif %}\n    {% if survey_goal.target_segment %}Target Segment: {{survey_goal.target_segment}}{% endif %}\n\n    ═══════════════════════════════════════════════════════════════════════\n    YOUR TASK\n    ═══════════════════════════════════════════════════════════════════════\n\n    Generate {{question_count}} personalized survey questions following these principles:\n\n    1. LEVERAGE WHAT WE KNOW:\n       - Reference their specific role/context naturally (e.g., \"As a {{person_context.title}}...\")\n       - Build on past conversations when relevant (e.g., \"You mentioned X in our last call...\")\n       - Address their known pains/goals directly\n       - BUT: Don't say \"Based on your profile\" or \"Our system shows\" - be natural\n\n    2. FILL KNOWLEDGE GAPS:\n       - Ask about missing fields when relevant (title, company, role)\n       - Validate themes with low evidence (< 3 pieces)\n       - Support project research goals\n\n    3. FEEL PERSONAL, NOT CREEPY:\n       - Use conversational, friendly tone\n       - Reference attributes naturally, woven into the question\n       - Ask open-ended questions (avoid yes/no unless necessary)\n       - Be curious, not interrogative\n\n    4. STRATEGIC VALUE:\n       - Each question should generate evidence for themes/goals\n       - Prioritize questions for high-ICP people (they're valuable)\n       - Support decision-making (not just data collection)\n\n    ═══════════════════════════════════════════════════════════════════════\n    EXAMPLES OF GOOD VS BAD QUESTIONS\n    ═══════════════════════════════════════════════════════════════════════\n\n    ❌ BAD (too generic):\n    \"What challenges do you face at work?\"\n\n    ✅ GOOD (personalized to context):\n    \"As a VP Engineering at a Series B company, what's your biggest challenge with research tools?\"\n    Rationale: References title, company stage, and research tool context\n    Uses: [title, company_stage, domain]\n\n    ❌ BAD (creepy, robotic):\n    \"Based on your profile, you mentioned budget concerns. Can you elaborate?\"\n\n    ✅ GOOD (natural reference to past):\n    \"In our last conversation, you brought up budget constraints. Has that changed at all, or is pricing still a key factor in your evaluation?\"\n    Rationale: References past conversation naturally, asks for update\n    Uses: [conversation_themes]\n\n    ❌ BAD (sparse data, still generic):\n    \"Tell me about your role.\"\n\n    ✅ GOOD (sparse data, gap-filling):\n    \"I'd love to understand your role better - what does a typical day look like for you?\"\n    Rationale: Fills missing title/role data, conversational\n    Uses: [missing_fields: title, role]\n\n    ═══════════════════════════════════════════════════════════════════════\n    OUTPUT FORMAT\n    ═══════════════════════════════════════════════════════════════════════\n\n    Return exactly {{question_count}} PersonalizedQuestion objects with:\n\n    - text: The question text (conversational, 1-2 sentences max)\n    - rationale: Why this question for THIS person (1 sentence, shown to user)\n    - uses_attributes: List of person attributes that informed this question\n        Examples: [\"title\", \"company_stage\", \"past_pain_points\", \"icp_score\", \"missing_role\"]\n    - evidence_type: What type of evidence this question will generate\n        Options: \"pain\", \"goal\", \"workflow\", \"tool\", \"context\"\n    - order: Priority ranking (1 = highest priority)\n\n    ═══════════════════════════════════════════════════════════════════════\n\n    Generate {{question_count}} questions now:\n  \"#\n}\n\n// ============================================================================\n// EVIDENCE EXTRACTION (for survey responses)\n// ============================================================================\n\nclass ExtractedEvidence {\n  gist string @description(\"12-word max essence of the insight\")\n  verbatim string @description(\"Direct quote from survey response (preserve exact wording)\")\n  context_summary string @description(\"1-2 sentence summary explaining why this matters\")\n  category \"pain\" | \"goal\" | \"workflow\" | \"tool\" | \"context\" @description(\"Type of evidence\")\n  confidence float @description(\"Confidence score 0-1\")\n\n  // Empathy map facets (optional, based on category)\n  says string[] @description(\"What they explicitly said (quotes)\")\n  thinks string[] @description(\"What they might be thinking (inferred)\")\n  feels string[] @description(\"Emotional state (inferred)\")\n  pains string[] @description(\"Pain points mentioned\")\n  gains string[] @description(\"Gains/benefits mentioned\")\n\n  theme_matches string[] @description(\"Themes this evidence relates to (names)\")\n}\n\nfunction ExtractEvidenceFromAnswer(\n  question_text: string,\n  answer_text: string,\n  question_metadata: string,\n  question_index: int\n) -> ExtractedEvidence[] {\n  client CustomGPT4o\n\n  prompt #\"\n    Extract structured evidence from this survey response.\n\n    IMPORTANT: Long answers may contain MULTIPLE distinct insights. Extract each as a separate evidence piece.\n\n    Question #{{question_index}}: {{question_text}}\n\n    Question Context (from generation): {{question_metadata}}\n\n    Person's Answer:\n    \"{{answer_text}}\"\n\n    ═══════════════════════════════════════════════════════════════════════\n    YOUR TASK\n    ═══════════════════════════════════════════════════════════════════════\n\n    Extract 1-5 evidence pieces from this answer. For EACH distinct insight:\n\n    1. **gist**: 12-word max summary (punchy, specific)\n       - Good: \"Struggles to align stakeholders without visual evidence\"\n       - Bad: \"Has challenges with stakeholders\"\n\n    2. **verbatim**: EXACT quote from answer (preserve their words)\n       - If answer is 1-2 sentences, use the full answer\n       - If longer, extract the most relevant 1-3 sentences per insight\n       - NEVER paraphrase - use their exact words\n\n    3. **context_summary**: 1-2 sentences explaining why this matters\n       - Connect to broader patterns or implications\n       - Example: \"This reflects common B2B pain point around evidence-based selling. Visual proof materials help overcome stakeholder skepticism.\"\n\n    4. **category**: pain, goal, workflow, tool, or context\n       - pain: Problems, frustrations, blockers\n       - goal: Desired outcomes, objectives\n       - workflow: How they work, processes\n       - tool: Software/tools they use\n       - context: Background info (role, company, situation)\n\n    5. **confidence**: 0-1 score\n       - 0.9-1.0: Explicit, clear, specific\n       - 0.7-0.89: Clear but slightly vague\n       - 0.5-0.69: Implied or requires interpretation\n       - < 0.5: Too vague, don't extract\n\n    6. **Empathy map facets** (optional arrays):\n       - says: Direct quotes (if different from verbatim)\n       - thinks: What they might be thinking (careful inference)\n       - feels: Emotional state (if expressed)\n       - pains: Pain points (if category=pain)\n       - gains: Benefits/gains mentioned (if category=goal)\n\n    7. **theme_matches**: Theme names this relates to\n       - Leave empty if unsure - we'll link later\n\n    ═══════════════════════════════════════════════════════════════════════\n    EXTRACTION RULES\n    ═══════════════════════════════════════════════════════════════════════\n\n    ✅ DO:\n    - Extract multiple pieces if answer covers multiple topics\n    - Preserve exact wording in verbatim (quotes matter!)\n    - Be specific in gist (actionable insights)\n    - Include context_summary to explain significance\n\n    ❌ DON'T:\n    - Paraphrase verbatim (use their words!)\n    - Extract vague/generic statements\n    - Create evidence from off-topic rambling\n    - Extract if confidence < 0.5\n\n    ═══════════════════════════════════════════════════════════════════════\n    EXAMPLES\n    ═══════════════════════════════════════════════════════════════════════\n\n    Example 1: Single insight answer\n    Question: \"What's your biggest challenge with customer research?\"\n    Answer: \"I spend 3-4 hours per week manually tagging interview notes, and I still miss important patterns.\"\n\n    Output (1 evidence piece):\n    [{\n      gist: \"Spends 3-4 hrs/week manually tagging notes, still misses patterns\",\n      verbatim: \"I spend 3-4 hours per week manually tagging interview notes, and I still miss important patterns.\",\n      context_summary: \"Manual tagging is time-consuming and error-prone. Reflects need for automated analysis tools.\",\n      category: \"pain\",\n      confidence: 0.95,\n      says: [\"I spend 3-4 hours per week manually tagging interview notes\"],\n      pains: [\"Time-consuming manual work\", \"Missing important patterns\"],\n      theme_matches: []\n    }]\n\n    Example 2: Multiple insights in one answer\n    Question: \"How do you currently validate pricing with customers?\"\n    Answer: \"We usually do email surveys after demos, but response rates are terrible (maybe 10%). When we do get feedback, it's often vague like 'too expensive' without specifics. I've been thinking we should do live pricing walkthroughs instead.\"\n\n    Output (3 evidence pieces):\n    [\n      {\n        gist: \"Email surveys after demos get ~10% response rate\",\n        verbatim: \"We usually do email surveys after demos, but response rates are terrible (maybe 10%).\",\n        context_summary: \"Low engagement with async email surveys. Timing and format may be wrong for pricing feedback.\",\n        category: \"workflow\",\n        confidence: 0.9,\n        says: [\"response rates are terrible (maybe 10%)\"],\n        pains: [\"Low survey response rates\"],\n        theme_matches: []\n      },\n      {\n        gist: \"Pricing feedback is vague ('too expensive') without details\",\n        verbatim: \"When we do get feedback, it's often vague like 'too expensive' without specifics.\",\n        context_summary: \"Survey format doesn't elicit actionable pricing feedback. Need deeper qualitative exploration.\",\n        category: \"pain\",\n        confidence: 0.85,\n        says: [\"it's often vague like 'too expensive' without specifics\"],\n        pains: [\"Vague feedback\", \"Lack of actionable pricing data\"],\n        theme_matches: []\n      },\n      {\n        gist: \"Considering live pricing walkthroughs as alternative\",\n        verbatim: \"I've been thinking we should do live pricing walkthroughs instead.\",\n        context_summary: \"Exploring synchronous methods for better pricing validation. Shows willingness to experiment with format.\",\n        category: \"goal\",\n        confidence: 0.75,\n        thinks: [\"Live walkthroughs would work better than async surveys\"],\n        gains: [\"More detailed pricing feedback\", \"Real-time clarification\"],\n        theme_matches: []\n      }\n    ]\n\n    ═══════════════════════════════════════════════════════════════════════\n\n    Now extract evidence from the answer above. Return 1-5 pieces.\n  \"#\n}\n",
  "product_lens_extraction.baml": "// Product Lens Extraction (JTBD + Feature Discovery)\n//\n// Extracts Jobs-to-be-Done, feature requests, product gaps, and competitive insights\n\n// ============================================================================\n// Core JTBD Classes\n// ============================================================================\n\nclass JobToBeDone {\n  job_description string @description(\"The core 'job' the user is trying to accomplish\")\n  situation string? @description(\"The situation or context when this job arises\")\n  desired_outcome string @description(\"What success looks like for this job\")\n  current_solution string? @description(\"How they currently try to accomplish this job\")\n  frustrations string[] @description(\"What frustrates them about current solutions\")\n  importance string @description(\"Importance level: 'critical', 'high', 'medium', or 'low'\")\n  satisfaction string @description(\"Current satisfaction: 'very_unsatisfied', 'unsatisfied', 'neutral', 'satisfied'\")\n  frequency string @description(\"How often: 'daily', 'weekly', 'monthly', 'occasionally', 'rarely'\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this JTBD\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass FeatureRequest {\n  feature_name string @description(\"Name or short description of the requested feature\")\n  description string @description(\"Detailed description of what the feature should do\")\n  use_case string @description(\"The specific use case or problem this solves\")\n  priority string @description(\"User-indicated priority: 'must_have', 'should_have', 'nice_to_have'\")\n  related_job_description string? @description(\"Which job-to-be-done this feature helps with\")\n  competitive_alternative string? @description(\"Existing product/feature they compare this to\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this request\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass ProductGap {\n  gap_description string @description(\"Description of the missing capability or unmet need\")\n  impact string @description(\"Impact of this gap: 'blocking', 'significant', 'moderate', 'minor'\")\n  affected_workflow string? @description(\"Which workflow or process is affected\")\n  workaround string? @description(\"Current workaround if any\")\n  competitive_advantage string? @description(\"Competitor that has solved this\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this gap\")\n}\n\nclass CompetitiveInsight {\n  competitor_name string @description(\"Name of competitive product mentioned\")\n  context string @description(\"Context in which competitor was mentioned\")\n  comparison_type string @description(\"Type: 'positive' (they like it), 'negative' (they don't), 'neutral' (just mentioned)\")\n  specific_features string[] @description(\"Specific features mentioned\")\n  switching_consideration bool @description(\"Are they considering switching to/from this competitor?\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this insight\")\n}\n\nclass FeaturePrioritization {\n  feature_theme string @description(\"High-level feature theme or category\")\n  user_segments string[] @description(\"Which user segments care about this\")\n  evidence_count int @description(\"Number of evidence items supporting this\")\n  urgency_score float @description(\"Urgency score based on frequency and importance (0.0 to 1.0)\")\n  recommended_action string @description(\"Recommended next step for this feature\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass ProductLensExtraction {\n  jobs JobToBeDone[] @description(\"Jobs-to-be-Done identified in conversation\")\n  feature_requests FeatureRequest[] @description(\"Explicit feature requests\")\n  product_gaps ProductGap[] @description(\"Identified gaps in current product\")\n  competitive_insights CompetitiveInsight[] @description(\"Mentions of competitors or alternatives\")\n  feature_priorities FeaturePrioritization[] @description(\"Prioritized feature themes\")\n  key_insights string[] @description(\"Top 3-5 strategic product insights\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractProductLens(\n  evidence_json: string,\n  interview_context: string\n) -> ProductLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert product manager analyzing customer interview evidence to identify Jobs-to-be-Done (JTBD), feature requests, and product gaps.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence and extract comprehensive product insights:\n\n    ### Jobs-to-be-Done (JTBD)\n    - Identify the core \"jobs\" users are trying to accomplish\n    - Look for statements about goals, objectives, tasks they need to complete\n    - Capture the situation/context when this job arises\n    - Note their desired outcome and how they currently try to solve it\n    - Rate importance, satisfaction, and frequency based on evidence\n    - JTBD should be outcome-focused, not solution-focused\n\n    ### Feature Requests\n    - Explicit asks for specific features or capabilities\n    - \"I wish it could...\", \"It would be great if...\", \"I need to be able to...\"\n    - Capture the use case and why they need it\n    - Infer priority from their language (must have vs nice to have)\n    - Note any competitive alternatives they mention\n\n    ### Product Gaps\n    - Unmet needs or missing capabilities\n    - Workflows that are broken or inefficient\n    - Pain points that indicate missing features\n    - Note the impact and any workarounds they're using\n\n    ### Competitive Insights\n    - Mentions of other products, tools, or solutions\n    - What they like/dislike about alternatives\n    - Features they wish you had from competitors\n    - Switching considerations\n\n    ### Feature Prioritization\n    - Group related feature requests into themes\n    - Calculate urgency based on frequency and importance\n    - Provide actionable recommendations\n\n    ### Key Insights\n    - 3-5 strategic product insights for the product team\n    - Focus on high-impact opportunities\n    - Connect insights to business value\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "project_name_description.baml": "// Generate a concise project name and a two-sentence description\n\nclass ProjectNameDescription {\n  name string @description(\"3–5 word, concise project name without company names or PII\")\n  description string @description(\"Exactly 2 sentences summarizing goal, audience, and focus\")\n}\n\nfunction GenerateProjectNameDescription(\n  signup_data: string\n) -> ProjectNameDescription {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a product research strategist. Create a crisp project name and a short description\n    from messy signup inputs.\n\n    RULES:\n    - Name: 3–5 words. Title case. Avoid vague buzzwords.\n    - Description: Exactly 2 sentences. First: the goal and who it's for.\n      Second: the focus/constraints (e.g., channels or artifacts like recordings/notes).\n    - Prefer clarity over flair. Do not invent details. If info is missing, keep it generic.\n\n    INPUT:\n    signup_data (JSON):\n    {{ signup_data }}\n\n    OUTPUT FORMAT:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "project_template_fill.baml": "// Project Template Fill\n// General LLM contract to map signup_data and optional hints to\n// a concrete project template filled with helpful, specific defaults.\n\nclass ProjectTemplateOut {\n  template_key string @description(\"Identifier of the template, e.g. 'understand_customer_needs'\")\n  target_orgs string[]\n  target_roles string[]\n  research_goal string\n  research_goal_details string\n  decision_questions string[]\n  assumptions string[]\n  unknowns string[]\n  custom_instructions string\n}\n\n// This function should be general enough to fill any template in the future\n// using the template_key. For now, we primarily support 'understand_customer_needs'.\nfunction FillProjectTemplate(\n  template_key: string,\n  signup_data: string,\n  project_name: string\n) -> ProjectTemplateOut {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a senior UX research strategist. Convert messy signup inputs into a\n    clean, opinionated project setup tailored to the given template.\n\n    Templates (current + future):\n    - understand_customer_needs — Focus on jobs-to-be-done, outcomes, pains, contexts.\n    - improve_ecommerce_conversion — Focus on funnel blockers, intent, decision criteria. (future)\n    - consulting_stakeholder_interviews — Focus on stakeholder goals, risks, alignment. (future)\n\n    RULES:\n    - Be concrete, specific, and helpful. Prefer actionable phrasing over vague terms.\n    - Use the user's signup_data when relevant. If data is missing, fill with strong defaults\n      for the template.\n    - Keep target_orgs and target_roles concise and representative of the likely audience.\n    - decision_questions: 3–6 sharp questions the team must decide.\n    - assumptions: 3–6 current beliefs to test.\n    - unknowns: 3–6 gaps that would change decisions.\n    - custom_instructions: short guidance for downstream AI (tone, biases to avoid, focus).\n    - Never include PII. Do not invent company names.\n\n    INPUTS:\n    - template_key: {{ template_key }}\n    - project_name: {{ project_name }}\n    - signup_data (JSON string):\n    {{ signup_data }}\n\n    OUTPUT FORMAT:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "qa_lens.baml": "// Q&A Lens - Extract question-answer pairs from interviews\n// This lens pairs interviewer questions with participant responses\n// to create a structured Q&A summary document\n\nclass QAPair {\n  question string @description(\"The interviewer's question, cleaned up for readability\")\n  question_evidence_id string @description(\"Evidence ID (8-char prefix) of the question turn\")\n  answer string @description(\"Synthesized 1-3 sentence answer from participant response\")\n  answer_evidence_ids string[] @description(\"Evidence IDs (8-char prefixes) supporting the answer\")\n  answer_verbatim string? @description(\"Best direct quote from response (≤30 words)\")\n  answer_start_ms int? @description(\"Start timestamp in milliseconds for the answer\")\n  confidence float @description(\"0.0-1.0: How complete/clear the answer is\")\n  follow_up_needed bool @description(\"True if answer was incomplete, unclear, or needs elaboration\")\n  topic string? @description(\"Short topic label for grouping (e.g., 'workflow', 'pain points', 'tools')\")\n}\n\nclass QALensResult {\n  executive_summary string @description(\"2-3 sentence summary of the key learnings from this Q&A session\")\n  qa_pairs QAPair[] @description(\"Question-answer pairs in chronological order\")\n  unanswered_questions string[] @description(\"Questions that weren't answered or were deflected\")\n  key_takeaways string[] @description(\"3-5 main learnings distilled from all Q&A pairs\")\n  topics_covered string[] @description(\"List of main topics discussed\")\n  overall_confidence float @description(\"Average confidence across all Q&A pairs\")\n}\n\nfunction ExtractQAPairs(\n  evidence_json: string,\n  interview_context: string,\n  focus_areas: string?\n) -> QALensResult {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert at extracting structured Q&A pairs from interview transcripts.\n    Your goal is to create a clean, scannable Q&A document that captures the essence of the conversation.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    {% if focus_areas %}\n    ## Focus Areas\n    Prioritize questions related to: {{ focus_areas }}\n    {% endif %}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    ### 1. Identify Question-Answer Pairs\n    - Look for evidence marked with is_question=true OR from speakers with role=\"interviewer\"\n    - Match each question to the subsequent response(s) from the participant\n    - A single question may have answers spread across multiple evidence items\n    - Skip procedural questions (\"Can you hear me?\", \"Should we continue?\")\n    - Skip social pleasantries (\"How are you?\", \"Nice to meet you\")\n\n    ### 2. For Each Q&A Pair\n    - **question**: Clean up the question for readability (fix grammar, remove filler words)\n    - **question_evidence_id**: Use the 8-character ID prefix of the question evidence\n    - **answer**: Synthesize a clear 1-3 sentence answer that captures the key point\n    - **answer_evidence_ids**: Include ALL evidence IDs that contribute to the answer\n    - **answer_verbatim**: Pick the single best quote that captures the essence (if impactful)\n    - **answer_start_ms**: Use the start_ms from the first answer evidence for timestamp linking\n    - **confidence**: Rate how complete/clear the answer is:\n      - 0.9+: Clear, complete answer with specific details\n      - 0.7-0.9: Good answer but could use more detail\n      - 0.5-0.7: Partial answer or somewhat vague\n      - <0.5: Unclear, deflected, or barely answered\n    - **follow_up_needed**: True if the answer is incomplete or raises more questions\n    - **topic**: Assign a short topic label for grouping similar Q&As\n\n    ### 3. Identify Unanswered Questions\n    - List questions that were asked but not answered\n    - Include questions that were deflected or answered with \"I don't know\"\n\n    ### 4. Generate Key Takeaways\n    - Distill 3-5 main learnings from the entire Q&A session\n    - Focus on actionable insights, not just summaries\n    - Format: \"[Topic]: [Specific learning]\"\n\n    ### 5. Executive Summary\n    - Write 2-3 sentences capturing the most important findings\n    - Lead with the biggest insight or most surprising finding\n    - Be concrete and specific, not generic\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test case for Q&A extraction\ntest ExtractQAPairs_Basic {\n  functions [ExtractQAPairs]\n  args {\n    evidence_json #\"\n    [\n      {\"id\": \"abc12345\", \"verbatim\": \"What tools do you currently use?\", \"is_question\": true, \"gist\": \"Question about tools\"},\n      {\"id\": \"def67890\", \"verbatim\": \"We mainly use Notion for docs and Slack for communication\", \"is_question\": false, \"gist\": \"Uses Notion and Slack\", \"anchors\": [{\"start_ms\": 45000}]},\n      {\"id\": \"ghi11111\", \"verbatim\": \"What's your biggest frustration with these tools?\", \"is_question\": true, \"gist\": \"Question about frustrations\"},\n      {\"id\": \"jkl22222\", \"verbatim\": \"The biggest issue is that nothing is connected. I have to copy-paste between tools constantly.\", \"is_question\": false, \"gist\": \"Frustrated by disconnected tools\", \"anchors\": [{\"start_ms\": 78000}]}\n    ]\n    \"#\n    interview_context \"User research interview about productivity tools\"\n    focus_areas null\n  }\n}\n",
  "question_evaluation.baml": "// Question Quality Evaluation - evaluates custom questions for research best practices\n\nclass QuestionIssue {\n  type \"leading\" | \"closed_ended\" | \"too_vague\" | \"compound\" | \"biased\" | \"jargon\" | \"assume_knowledge\"\n  description string @description(\"Brief explanation of the issue\")\n  severity \"high\" | \"medium\" | \"low\" @description(\"How problematic this issue is\")\n}\n\nclass QuestionImprovement {\n  original_question string\n  suggested_rewrite string @description(\"Improved version of the question\")\n  explanation string @description(\"Why this version is better\")\n}\n\nclass QuestionEvaluation {\n  overall_quality \"green\" | \"yellow\" | \"red\" @description(\"Traffic light indicator of question quality\")\n  score int @description(\"0-100 quality score\")\n  strengths string[] @description(\"What makes this question effective\")\n  issues QuestionIssue[] @description(\"Problems identified with the question\")\n  improvement QuestionImprovement? @description(\"Suggested improvement if needed\")\n  recommendation \"proceed\" | \"revise\" @description(\"Should user proceed or revise the question\")\n  quick_feedback string @description(\"One-sentence summary of the assessment\")\n}\n\nfunction EvaluateInterviewQuestion(\n  question: string,\n  research_context: string\n) -> QuestionEvaluation {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher evaluating the quality of an interview question for exploratory research.\n\n    QUESTION TO EVALUATE:\n    \"{{ question }}\"\n\n    RESEARCH CONTEXT:\n    {{ research_context }}\n\n    EVALUATION CRITERIA (be encouraging, practical, and not nit‑picky):\n    \n    1. OPEN-ENDED: Encourage detailed, story-based responses (primary goal in exploratory).\n    2. NON-LEADING: Avoid suggestive or binary phrasing.\n    3. CLEAR & SPECIFIC: One topic, understandable in plain language.\n    4. CONVERSATIONAL: Friendly, natural tone.\n    5. ACTIONABLE: Likely to produce useful insights about the goal.\n\n    COMMON ISSUES TO FLAG (but don’t over-penalize if the question is broadly open‑ended):\n\n    HIGH SEVERITY:\n    - Leading questions that bias responses (\"Don't you think X is better?\")\n    - Yes/no or closed-ended questions\n    - Multiple questions in one (compound questions)\n    - Assumes knowledge the interviewee may not have\n\n    MEDIUM SEVERITY:\n    - Too vague or broad (\"Tell me about your experience\")\n    - Contains jargon or technical terms inappropriate for audience\n    - Potentially sensitive or awkward phrasing\n\n    LOW SEVERITY:\n    - Could be more conversational\n    - Minor clarity improvements possible\n\n    QUALITY SCORING (be lenient for exploratory mode):\n    - GREEN (75-100): Open-ended, non-leading, and broadly clear/conversational — proceed as-is\n    - YELLOW (55-74): Good direction; offer a small rewrite to be more specific/clear\n    - RED (0-54): Only if clearly leading, yes/no, or compound; provide a simple rewrite\n\n    PROVIDE (keep feedback calm, consistent, and practical):\n    1. Overall quality rating (green/yellow/red)\n    2. Numeric score (0-100)\n    3. Specific strengths of the question\n    4. Any issues found with severity levels\n    5. Suggested improvement if yellow/red — a single clear rewrite; prefer “Tell me about…”/“Walk me through…” patterns with a concrete example\n    6. Clear recommendation (proceed/revise)\n    7. One-sentence quick feedback (casual tone; avoid moving goalposts)\n\n    Be encouraging but honest. Focus on what makes questions effective for generating rich insights.\n    If the user’s latest version already addresses prior feedback, do not suggest a different change. Prefer stability and clarity.\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Batch evaluation for multiple questions\nclass BatchEvaluationResult {\n  evaluations QuestionEvaluation[]\n  overall_summary string @description(\"Summary of the question set quality\")\n  top_priorities string[] @description(\"Most important improvements to make\")\n}\n\nfunction EvaluateQuestionSet(\n  questions: string[],\n  research_context: string\n) -> BatchEvaluationResult {\n  client CustomGPT4oMini\n  prompt #\"\n    You are evaluating a set of interview questions for research quality.\n\n    QUESTIONS TO EVALUATE:\n    {% for question in questions %}\n    {{ loop.index }}. \"{{ question }}\"\n    {% endfor %}\n\n    RESEARCH CONTEXT:\n    {{ research_context }}\n\n    Evaluate each question individually using the same criteria as single question evaluation, then provide:\n    \n    1. Individual evaluation for each question\n    2. Overall summary of the question set's strengths and weaknesses\n    3. Top 2-3 priorities for improvement across the entire set\n\n    Look for issues like:\n    - Too many similar questions (redundancy)\n    - Missing important question types (no behavioral questions, etc.)\n    - Inconsistent tone or style\n    - Overall flow and progression\n\n    Output format:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "research_analysis.baml": "// Research Question Analysis - matches insights to user's research goals\n\nclass ResearchQuestion {\n  question string\n  priority int @description(#\" 1 - 3 with 1 being highest \"#)\n}\n\nclass ResearchGoal {\n  goal string\n  icp string // Target customer profile\n  role string // User segment\n  questions ResearchQuestion[]\n}\n\nclass InsightMatch {\n  question string\n  insights_found string[] // Insight names/summaries that answer this question\n  confidence int @description(#\" 1 - 3 with 1 being highest \"#)\n  answer_summary string // Clear, concise answer based on insights\n  evidence string[] // Supporting quotes/evidence from insights\n}\n\nclass GapAnalysis {\n  unanswered_questions string[]\n  partially_answered_questions string[]\n  follow_up_recommendations string[]\n  suggested_interview_topics string[]\n}\n\nclass ProjectAnalysis {\n  research_goal ResearchGoal\n  question_answers InsightMatch[]\n  gap_analysis GapAnalysis\n  key_discoveries string[] // Unexpected insights not related to original questions\n  confidence_score int // 0-100 overall confidence in findings\n  next_steps string[]\n}\n\nclass EvidenceItem {\n  id string\n  verbatim string\n  support \"supports\" | \"refutes\" | \"neutral\"\n  interview_id string?\n  context_summary string?\n}\n\nclass QuestionContext {\n  id string\n  kind \"decision\" | \"research\"\n  decision_question_id string?\n  text string\n  rationale string?\n}\n\nclass EvidenceQuestionLink {\n  question_id string\n  question_kind \"decision\" | \"research\"\n  decision_question_id string?\n  relationship \"supports\" | \"refutes\" | \"neutral\"\n  confidence float\n  answer_summary string\n  rationale string\n  next_steps string?\n}\n\nclass ResearchQuestionAnswer {\n  research_question_id string\n  findings string[] @description(\"2-5 specific findings from evidence, each a clear statement\")\n  evidence_ids string[] @description(\"IDs of evidence that support these findings\")\n  confidence float\n  reasoning string @description(\"Brief explanation of how evidence supports these findings\")\n}\n\nclass DecisionQuestionAnswer {\n  decision_question_id string\n  strategic_insight string @description(\"High-level strategic answer synthesized from research findings\")\n  supporting_findings string[] @description(\"Key findings from research questions that inform this decision\")\n  research_question_ids string[] @description(\"IDs of research questions that contributed to this answer\")\n  confidence float\n  reasoning string @description(\"How the research findings lead to this strategic insight\")\n  recommended_actions string[] @description(\"Specific next steps based on this insight\")\n}\n\nclass EvidenceLinkResult {\n  evidence_id string\n  links EvidenceQuestionLink[]\n}\n\nclass QuestionAnalysisSummary {\n  question_id string\n  question_kind \"decision\" | \"research\"\n  decision_question_id string?\n  confidence float\n  summary string\n  goal_achievement_summary string?\n  next_steps string?\n}\n\nclass EvidenceAnalysisResponse {\n  evidence_results EvidenceLinkResult[]\n  research_question_answers ResearchQuestionAnswer[] @description(\"Evidence-based findings for each research question\")\n  decision_question_answers DecisionQuestionAnswer[] @description(\"Strategic insights synthesized from research findings\")\n  global_goal_summary string?\n  recommended_actions string[]\n}\n\nfunction AnalyzeProjectInsights(\n  research_goal: string,\n  insights_data: string,\n  interview_summary: string,\n  custom_instructions: string\n) -> ProjectAnalysis {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing research findings against stated research goals and questions.\n\n    RESEARCH GOAL:\n    {{ research_goal }}\n\n    EXTRACTED INSIGHTS:\n    {{ insights_data }}\n\n    INTERVIEW SUMMARY:\n    {{ interview_summary }}\n\n    TASK: Analyze how well the insights answer each research question:\n\n    If we have custom_instructions, use them, otherwise follow the guidlines below.\n\n    CUSTOM_INSTRUCTIONS:\n    {{ custom_instructions }}\n\n    GUIDELINES:\n\n    1. For each question, produce a concise, actionable answer:\n       - insights_found: names/summaries of insights that directly or indirectly answer it (2-4 items if available)\n       - confidence: NUMERIC 1-3 where 1 = high, 2 = medium, 3 = low (no words)\n       - answer_summary: 1-2 sentence synthesis that a PM can act on; no preamble\n       - evidence: 1-3 short quotes or paraphrased snippets from interviews/insights. Prefer direct quotes. Keep each to <140 chars.\n\n    2. Gap Analysis (be specific and scoped to the research goal):\n       - Which questions remain unanswered or only partially answered\n       - What follow-up research is needed\n       - Suggest specific interview topics to fill gaps\n\n    3. Key Discoveries:\n       - Important insights that emerged beyond the original questions\n       - Unexpected findings that could redirect research focus\n\n    4. Next Steps:\n       - Concrete recommendations for the researcher\n       - Priority areas for additional interviews\n       - Suggested changes to research approach if needed\n\n    QUALITY BAR:\n    - Provide concise, evidence-backed answers with explicit numeric confidence (1-3).\n    - Include 1-3 relevant evidence quotes per answer, and reference related insights.\n    - Be specific, honest, and grounded in the provided data.\n    - Avoid generic or boilerplate phrasing, and do not repeat the question.\n    - Prefer concrete, falsifiable statements.\n\n\t    \tOutput format:\n    \t{{ ctx.output_format }}\n  \"#\n}\n\nfunction LinkEvidenceToResearchStructure(\n  evidence: EvidenceItem[],\n  questions: QuestionContext[],\n  custom_instructions: string\n) -> EvidenceAnalysisResponse {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert research analyst linking raw evidence to structured research questions and decisions.\n\n    EVIDENCE ITEMS (array of JSON objects with id, verbatim, support, interview_id, context_summary when available):\n    {{ evidence }}\n\n    QUESTION CONTEXT (each includes id, kind=decision/research, text, optional decision_question_id when kind='research'):\n    {{ questions }}\n\n    CUSTOM INSTRUCTIONS (optional, may be empty):\n    {{ custom_instructions }}\n\n    TASK REQUIREMENTS:\n\n    PHASE 1 - EVIDENCE TO RESEARCH QUESTIONS:\n    1. For each evidence item, link it to relevant RESEARCH questions only (not decision questions):\n       - Provide relationship (supports/refutes/neutral) and confidence 0.0 – 1.0\n       - Summarize what this evidence tells us (<= 2 sentences)\n       - Include rationale referencing key phrases from evidence (<= 220 chars)\n       - Suggest next steps when helpful\n\n    PHASE 2 - RESEARCH QUESTION ANSWERS:\n    2. For each research question, synthesize all linked evidence into findings:\n       - Generate 2-5 specific, evidence-based findings (clear statements, not questions)\n       - List evidence IDs that support each finding\n       - Provide overall confidence based on evidence strength and agreement\n       - Explain reasoning: how the evidence supports these findings\n       - Example finding: \"Users are willing to pay for interview assistance tools (5 mentions across 3 interviews)\"\n\n    PHASE 3 - DECISION QUESTION SYNTHESIS:\n    3. For each decision question, synthesize insights from its research questions:\n       - Create ONE strategic insight that answers the decision (not a list of evidence)\n       - Extract key findings from research questions that inform this decision\n       - List research question IDs that contributed\n       - Provide confidence based on research question coverage\n       - Explain reasoning: how research findings lead to this strategic answer\n       - Recommend 2-4 specific actions based on this insight\n       - Example insight: \"Adopt freemium model with premium interview features\" (NOT \"Users mentioned tools\" - that's RQ-level)\n\n    4. Provide project-wide guidance:\n       - global_goal_summary: overall progress toward research goal\n       - recommended_actions: 2-4 high-level actions for the project team\n\n    OUTPUT RULES:\n    - Return valid JSON matching EvidenceAnalysisResponse exactly.\n    - Omit evidence items that do not meaningfully map to questions (empty links array is acceptable).\n    - Keep confidence within [0.0, 1.0].\n    - Ensure every evidence link references question ids that exist in QUESTION CONTEXT.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Executive summary optimized for status screens\nclass ExecutiveSummary {\n  answered_insights string[] @description(\"Key findings that directly answer user's research questions, leading with pithy finding and then cause if known. Include 1-2 surprises if present.'\")\n  // unanticipated_discoveries string[] @description(\"Surprising findings not related to original questions'\")\n  critical_unknowns string[] @description(\"Important questions that remain unanswered or areas where evidence is insufficient\")\n  completion_percentage int @description(\"0-100 estimate of how much of the original research goal has been addressed\")\n  confidence int @description(\"1-3 with 1 being highest confidence in findings\")\n  next_action string @description(\"Single most important next 1-2 steps to advance the research\")\n}\n\nfunction GenerateExecutiveSummary(\n  research_goal: string,\n  insights_content: string,\n  interview_content: string,\n  custom_instructions: string\n) -> ExecutiveSummary {\n  client CustomGPT4o\n  prompt #\"\n    You are analyzing research findings to create an executive summary of goals and questions answered, with what level of confidence;\n\t\twhat's still unkonwn, and recommend next steps. Keep it pithy without preamble or fluff. Can be partial sentences.\n\n    RESEARCH GOAL:\n    {{ research_goal }}\n\n    INSIGHTS:\n    {{ insights_content }}\n\n    INTERVIEWS:\n    {{ interview_content }}\n\n    CUSTOM INSTRUCTIONS (if provided):\n    {{ custom_instructions }}\n\n    ANALYSIS REQUIREMENTS:\n\n    1. ANSWERED INSIGHTS (2-4 items):\n       - Major insights learned relative to research goal (group and summarizesimilar insights)\n       - Prioritize insights with strong evidence from multiple sources\n\t\t\t - Example: \"Users prefer mobile over desktop for quick tasks, because 8/10 interviews mentioned switching to phones when in a hurry\"\n\t\t\t - Call out truly surprising, UNANTICIPATED INSIGHTS if they exist and are relevant to the goal.\n       - Example: \"Price is less important than expected, because users consistently mentioned convenience over cost in decision-making\"\n       - Include only discoveries with solid evidence\n\n    3. REMAINING UNKNOWNS (1-3 items):\n       - Important questions that remain unanswered or areas with insufficient evidence\n       - Format as clear questions or knowledge gaps without any preample or fluff; partial sentences bullet style ok.\n       - Example: \"How users behave during peak usage times\" or \"Whether pricing sensitivity varies by user segment\"\n\n\t\t4. Recommendations:\n       - 1-2 recommendations that address the biggest gap or highest-value opportunity\n       - Be specific and actionable\n\n    5. COMPLETION PERCENTAGE:\n       - Estimate how much of the research goal has been addressed (0-100)\n       - Consider both breadth (topics covered) and depth (evidence quality)\n\n\n    QUALITY GUIDELINES:\n    - Use concrete evidence from the data, not assumptions\n    - Avoid jargon - write for business stakeholders\n    - Be honest about limitations and gaps\n    - Prioritize actionable insights over interesting but irrelevant findings\n\n\t\tOutput format:\n\t\t{{ ctx.output_format }}\n  \"#\n}\n\n// // Smart Research Question Generation for Onboarding\n// class SuggestedQuestion {\n//   question string\n//   rationale string // Why this question is important for their research\n//   interview_type \"user_interview\" | \"stakeholder_interview\" | \"expert_interview\"\n//   priority int @description(#\" 1 - 3 with 1 being highest \"#)\n// }\n\n// class ResearchQuestionSuggestions {\n//   core_questions SuggestedQuestion[] // 3-4 essential questions\n//   behavioral_questions SuggestedQuestion[] // Understanding user behavior\n//   pain_point_questions SuggestedQuestion[] // Identifying problems\n//   solution_questions SuggestedQuestion[] // Validating solutions\n//   context_questions SuggestedQuestion[] // Understanding environment/constraints\n// }\n\n// function GenerateResearchQuestions(\n// \ttarget_org: string,\n// \ttarget_roles: string,\n// \tresearch_goal: string,\n// \tresearch_goal_details: string,\n// \tassumptions: string,\n// \tunknowns: string,\n// \tcustom_instructions: string\n// ) -> ResearchQuestionSuggestions {\n//   client CustomGPT4o\n//   prompt #\"\n//     You are an expert UX researcher helping someone design interview questions.\n\n//     CONTEXT:\n//     - Target Audience: {{ target_org }}\n//     - User Role/Segment: {{ target_roles }}\n//     - Research Goal: {{ research_goal }}\n// \t\t- Research Goal Details: {{ research_goal_details }}\n// \t\t- Assumptions: {{ assumptions }}\n// \t\t- Unknowns: {{ unknowns }}\n\n// \t\tIf we have custom_instructions, use them, otherwise follow the guidlines below.\n\n// \t\tCUSTOM_INSTRUCTIONS:\n\n//     {{ custom_instructions }}\n\n//     GUIDELINES:\n\n//     Generate specific, actionable interview questions organized by category.\n\n//     1. Questions should be open-ended and behavior-focused\n//     2. Avoid leading questions or yes/no questions\n//     3. Include follow-up prompts in the question\n//     4. Make questions specific to their ICP and goal\n//     5. Prioritize questions that will reveal real user needs and pain points\n\n//     CATEGORIES:\n\n//     Core Questions (3-4 must-ask questions):\n//     - Essential questions that directly address their research goal\n//     - Should uncover key insights about user behavior and needs\n\n//     Behavioral Questions:\n//     - How users currently solve problems\n//     - Workflow and process understanding\n//     - Decision-making factors\n\n//     Pain Point Questions:\n//     - Current frustrations and challenges\n//     - Gaps in existing solutions\n//     - Cost of current approaches\n\n//     Solution Questions (if applicable):\n//     - Validation of potential solutions\n//     - Feature importance and prioritization\n//     - Willingness to pay or adopt\n\n//     Context Questions:\n//     - Environmental factors\n//     - Constraints and limitations\n//     - Stakeholder influences\n\n//     For each question provide:\n//     - The specific question text\n//     - Why it's important for their research (rationale)\n//     - What type of interview it's best for\n//     - Priority level\n\n// \t\tMake questions helpful, unique, conversational and natural, as if asking a friend.\n//     Avoid jargon and make them appropriate for the target audience.\n\n// \t\tOutput format:\n// \t\t{{ ctx.output_format }}\n//   \"#\n// }\n\n// ---------- Core data classes ----------\nclass Category {\n  id string @description(\"Stable string ID for the category (e.g., 'goals', 'pain', 'workflow', 'context', 'constraints', 'willingness-to-pay'). Use lowercase kebab/camel; must be unique within this QuestionSet.\")\n  label string @description(\"Human-readable category name shown in the UI (e.g., 'Goals & Outcomes').\")\n  weight float? @description(\"Optional multiplier (>=0.5 to <=1.5 typical) that boosts selection priority for this category. default = 1.0\")\n}\n\nclass Scores {\n  goalMatch float @description(\"0..1. How strongly this question aligns with the user's stated goals. Higher = more aligned.\")\n  novelty float @description(\"0..1. How different this question is from previously shown/asked items. Higher = more novel.\")\n  importance float @description(\"0..1. Domain importance for understanding needs vs potential. Weight this highest.\")\n  uncertainty float? @description(\"0..1. Confidence gap. Higher = exploring unknowns; helps diversify when uncertainty is high.\")\n}\n\nclass Source {\n\n}\n\nclass Question {\n  id string @description(\"CRITICAL: Unique string identifier (uuid/ulid-like). Must be globally unique across this entire QuestionSet. Generate using crypto.randomUUID() or similar. Never reuse IDs.\")\n  text string @description(\"The complete, conversational question text as you would ask a person. Include natural follow-ups when helpful.\")\n  categoryId string @description(\"Category.id this question belongs to. Must match a Category in this QuestionSet.\")\n  rationale string? @description(\"One short sentence on why this question matters for needs/potential.\")\n  tags string[]? @description(\"Optional short tags for filtering (e.g., 'pricing', 'workflow', 'adoption').\")\n  scores Scores @description(\"Scoring object. Provide values in [0,1] per field; the app computes a composite.\")\n  estimatedMinutes float @description(\"Realistic time estimate in minutes for this question (1-5 minutes typical). Consider question complexity, follow-ups, and discussion depth.\")\n  status \"proposed\" | \"shown\" | \"rejected\" | \"asked\" | \"answered\" @description(\"Lifecycle state. New questions must start as 'proposed'.\")\n  source \"llm\" | \"curated\" | \"custom\" @description(\"Origin of the question. Use 'llm' for generated items by default.\")\n  displayOrder int? @description(\"Optional UI order hint. Leave unset; the app may assign.\")\n  externalRef string? @description(\"Optional reference to a template/library identifier for provenance.\")\n}\n\nclass HistoryItem {\n  questionId string @description(\"The Question.id this event relates to.\")\n  action \"shown\" | \"rejected\" | \"asked\" | \"answered\" @description(\"What happened to the question at the given timestamp.\")\n  ts string @description(\"ISO-8601 timestamp of the event (e.g., '2025-08-27T04:15:00Z').\")\n  interviewId string? @description(\"Optional interview identifier to tie this event to a specific interview.\")\n}\n\nclass QuestionPolicy {\n  totalPerRound int @description(\"Maximum number of questions to surface in the next round.\")\n  perCategoryMin int? @description(\"Minimum number to include from each category for coverage. Use 0–2 typically.\")\n  perCategoryMax int? @description(\"Maximum number allowed from any single category to avoid flooding.\")\n  dedupeWindowRounds int? @description(\"How many previous rounds to consider for avoiding repeats. Use 1–3.\")\n  balanceBy string[]? @description(\"Balancing dimensions. Usually include 'category' and optionally 'novelty' or 'importance'.\")\n}\n\nclass QuestionSet {\n  sessionId string? @description(\"Stable session identifier. Injected by caller from inputs.session_id; LLM should NOT generate.\")\n  policy QuestionPolicy? @description(\"Selection policy. Injected by caller from inputs; LLM should NOT generate.\")\n  categories Category[] @description(\"The complete list of categories available for this session. Keep to < 8.\")\n  questions Question[] @description(\"Pool of proposed questions. Start all as 'proposed'. Do not include duplicates.\")\n  history HistoryItem[] @description(\"Past events for this session. If the caller provides prior history, do not alter it; only append in the app.\")\n  round int? @description(\"Current round number. Injected by caller from inputs.round; LLM should NOT generate.\")\n}\n\n// ---------- Research Structure Classes ----------\nclass DecisionQuestionItem {\n  id string @description(\"Unique identifier for this decision question.\")\n  text string @description(\"The key business decision to be made (e.g., 'Should we build feature X?').\")\n  rationale string? @description(\"Why this decision matters for the business.\")\n}\n\nclass ResearchQuestionItem {\n  id string @description(\"Unique identifier for this research question.\")\n  text string @description(\"Specific research question to investigate (e.g., 'How do users currently solve problem Y?').\")\n  rationale string? @description(\"Why this research question helps answer the decision question.\")\n  decision_question_id string @description(\"ID of the decision question this research question supports.\")\n}\n\nclass InterviewPromptItem {\n  id string @description(\"Unique identifier for this interview prompt.\")\n  text string @description(\"Natural, conversational question to ask in interviews.\")\n  research_question_id string @description(\"ID of the research question this prompt investigates.\")\n}\n\nclass ResearchStructure {\n  decision_questions DecisionQuestionItem[] @description(\"High-level business decisions to be made.\")\n  research_questions ResearchQuestionItem[] @description(\"Specific research questions that support the decisions.\")\n  interview_prompts InterviewPromptItem[] @description(\"Natural interview questions that gather evidence.\")\n}\n\n// ---------- Legacy compatibility (kept) ----------\nclass SuggestedQuestion {\n  question string @description(\"Plain-text question wording.\")\n  rationale string @description(\"Why this question is important for research.\")\n  interview_type \"user_interview\" | \"stakeholder_interview\" | \"expert_interview\" @description(\"Primary interview type this question suits best.\")\n  priority int @description(\"1..3 (1 = highest). Indicate urgency/importance for early rounds.\")\n}\n\nclass ResearchQuestionSuggestions {\n  core_questions SuggestedQuestion[] @description(\"3–4 must-ask questions aligned to the research goal.\")\n  behavioral_questions SuggestedQuestion[] @description(\"Questions to understand current workflows/behaviors.\")\n  pain_point_questions SuggestedQuestion[] @description(\"Questions that surface current problems and friction.\")\n  solution_questions SuggestedQuestion[] @description(\"Questions to validate potential solutions and value.\")\n  context_questions SuggestedQuestion[] @description(\"Questions to capture environment, constraints, stakeholders.\")\n}\n\n// ---------- Inputs ----------\nclass GenerateInputs {\n  customer_problem string? @description(\"The business/customer problem being solved or addressed.\")\n  target_org string? @description(\"Target organization context (industry, size, market).\")\n  target_roles string? @description(\"Primary user roles/segments to interview (comma-separated or natural language).\")\n  offerings string? @description(\"Products and services offered to customers.\")\n  competitors string? @description(\"Other products or solutions customers are using or considering.\")\n  research_goal string @description(\"Short statement of the overarching research goal.\")\n  research_goal_details string? @description(\"Specific details and hypotheses relevant to this study.\")\n  assumptions string? @description(\"Key assumptions the team currently holds.\")\n  unknowns string? @description(\"Open questions and uncertainties to investigate.\")\n  custom_instructions string? @description(\"Optional caller-provided guidance that overrides defaults.\")\n  research_mode string? @description(\"Study mode. Expected: 'exploratory', 'validation', or 'user_testing'.\")\n  session_id string @description(\"Session identifier to embed into the returned QuestionSet.sessionId.\")\n  round int @description(\"1-based round number provided by the caller.\")\n  total_per_round int? @description(\"Default 25: number of questions to show per round.\")\n  per_category_min int? @description(\"Default 3: minimum per category.\")\n  per_category_max int? @description(\"Default 5: maximum per category.\")\n  interview_time_limit int? @description(\"Default 30: Expected interview time in minutes, use this to guide the selection of must ask questions.\")\n}\n\n// ---------- Research Structure Generation ----------\nfunction GenerateResearchStructure(\n  inputs: GenerateInputs\n) -> ResearchStructure {\n  client CustomGPT4o\n  prompt #\"\n  You are a research strategist helping to structure a user research study. Generate a complete research structure with decision questions, research questions, and interview prompts.\n\n  BUSINESS CONTEXT:\n  CUSTOMER PROBLEM: {{ inputs.customer_problem }}\n  OFFERINGS: {{ inputs.offerings }}\n  COMPETITORS: {{ inputs.competitors }}\n  TARGET ORGS: {{ inputs.target_org }}\n  TARGET ROLES: {{ inputs.target_roles }}\n\n  RESEARCH CONTEXT:\n  RESEARCH GOAL: {{ inputs.research_goal }}\n  DETAILS: {{ inputs.research_goal_details }}\n  RESEARCH MODE: {{ inputs.research_mode or \"exploratory\" }}\n  ASSUMPTIONS: {{ inputs.assumptions }}\n  UNKNOWNS: {{ inputs.unknowns }}\n\n  TASK: Create a structured research plan with three levels:\n\n  1. DECISION QUESTIONS (2-3 items):\n     - High-level business decisions that need to be made\n     - Should be strategic and actionable\n     - Examples: \"Should we build feature X?\", \"Which user segment should we prioritize?\"\n     - Each needs a unique ID and clear rationale\n\n  2. RESEARCH QUESTIONS (2-4 per decision question):\n     - Specific questions that help answer each decision question\n     - Should be investigative and focused\n     - Examples: \"How do users currently solve problem Y?\", \"What are the main barriers to adoption?\"\n     - Each needs a unique ID, rationale, and links to a decision question\n\n  3. INTERVIEW PROMPTS (2-3 per research question):\n     - Natural, conversational questions to ask in interviews\n     - Should be open-ended and behavior-focused\n     - Examples: \"Tell me about the last time you...\", \"What's most frustrating about...\"\n     - Each needs a unique ID and links to a research question\n\n  GUIDELINES:\n  - Make interview prompts conversational and natural, like you're talking to a friend\n  - Focus on understanding user behavior, pain points, and needs\n  - Avoid leading questions or yes/no questions\n  - Generate unique IDs for all items (use crypto.randomUUID() style)\n  - Ensure all items have proper relationships (research questions link to decision questions, etc.)\n\n  QUESTION DIVERSITY - Create a balanced mix covering:\n  - Background/Context: Current situation, existing solutions (especially competitors), tools being used\n  - Goals & Outcomes: What they're trying to achieve, success metrics, desired outcomes\n  - Pain Points: Frustrations with current solutions (including competitors), unmet needs, blockers\n  - Workflow & Behavior: Day-to-day processes, specific scenarios, decision-making patterns\n  - Constraints & Barriers: Budget limitations, technical constraints, organizational challenges\n  - Value & Willingness to Pay: What they'd pay for, ROI expectations, budget allocation\n  - Demographics/Firmographics: Company size, industry, role details, team structure\n\n  - If the research mode is \"validation\":\n      * Create exactly four research questions aligned to validation gates: Pain Exists, Awareness, Quantified Impact, Taking Action.\n      * Use deterministic IDs for those research questions: \"pain_exists\", \"awareness\", \"quantified\", \"acting\".\n      * Craft decision questions that frame the business need for validating assumptions.\n      * For each validation research question, include 2-3 interview prompts that directly probe evidence for that gate; including pain awareness, acting on it, Willingness to pay.\n      * When research mode is not \"validation\", follow the general exploratory guidance and choose research question counts based on context.\n  - If research mode is \"user_testing\", emphasise prompts seeking to understand if the user is aware of what is possible and expected ofthem. What actions do they want to take and why? How easy to understand and how usable is it.\n\n  QUALITY REQUIREMENTS:\n  - Decision questions should be strategic and business-focused\n  - Research questions should be specific and investigative\n  - Interview prompts should be natural and open-ended\n  - All text should be clear, concise, and actionable\n\n  Return the complete structure with all relationships properly linked.\n\n  {{ ctx.output_format }}\n  \"#\n}\n\n// ---------- Main generation function ----------\nfunction GenerateQuestionSet(\n  inputs: GenerateInputs\n) -> QuestionSet {\n  client CustomGPT4o\n  prompt #\"\n  You are creating natural conversation starters for informal interviews. Think like a curious friend who wants to understand someone's work and life, not a corporate consultant.\n\n  CRITICAL: Follow these CUSTOM INSTRUCTIONS above all else:\n  {{ inputs.custom_instructions }}\n\n  IMPORTANT: If the custom instructions above conflict with any context below, ALWAYS prioritize the custom instructions. The custom instructions define the true goal and scope of this research.\n\n\tYou will generate a larger set than can be asked in the available time, and prioritize the most important questions based on importance, goalMatch, and novelty.\n\n\tIMPORTANT: For each question, provide a realistic estimatedMinutes value (2-7 minutes typical):\n\t- Simple yes/no or factual questions: 1-2 minutes\n\t- Open-ended exploratory questions: 3-4 minutes\n\t- Complex scenario or deep-dive questions: 5-6 minutes\n\t- Consider follow-up discussion time in your estimate\n\n\tTotal available time: {{ inputs.interview_time_limit }} minutes.\n\tGenerate 25% more questions than can fit to give the interviewer options and backups.\n\n  BACKGROUND CONTEXT (use only if it aligns with custom instructions above):\n  - Customer Problem: {{ inputs.customer_problem }}\n  - Offerings: {{ inputs.offerings }}\n  - Competitors: {{ inputs.competitors }}\n  - Target Org: {{ inputs.target_org }}\n  - Roles/Segments: {{ inputs.target_roles }}\n  - Research Goal: {{ inputs.research_goal }}\n  - Goal Details: {{ inputs.research_goal_details }}\n  - Assumptions: {{ inputs.assumptions }}\n  - Unknowns: {{ inputs.unknowns }}\n\n  RESEARCH MODE: {{ inputs.research_mode or \"exploratory\" }}\n  MODE-SPECIFIC GUIDANCE:\n    - If research mode is \"validation\":\n        * Prioritise questions that surface evidence for the four validation gates (Pain Exists, Awareness, Quantified Impact, Acting/Next Steps).\n        * Ensure categories favour these gates (e.g., use categoryId values of \"pain\", \"awareness\", \"quantified\", \"acting\" when relevant).\n        * Keep prompts crisp and outcome-focused so answers can be mapped to go/no-go decisions.\n    - If research mode is \"user_testing\":\n        * Focus categories on usability, comprehension, task completion, and adoption.\n    - Otherwise keep a balanced exploratory mix across context, goals, pain, workflow, constraints, willingness, and demographics.\n\n  IMPORTANT: Pay special attention to the TARGET ROLES/SEGMENTS above. Create questions that are:\n  1) Highly specific to their daily work, creative processes, and unique challenges\n  2) Focused on their actual tools, platforms, and workflows they use\n  3) Addressing their specific pain points in their creative field\n  4) Understanding their community, audience, and collaboration patterns\n  5) Exploring their business model, income streams, and professional needs\n\n  EXAMPLES of GOOD conversational questions:\n  - \"I'm curious - when you're stuck on a design, what do you actually do? Like, do you take a walk, scroll Instagram, call a friend?\"\n  - \"What's the most annoying thing clients do? I bet you have some stories...\"\n  - \"Show me your workspace - what's the one tool or app you can't live without?\"\n  - \"When was the last time you collaborated with another artist? How did that come about?\"\n  - \"What's your biggest creative struggle right now? The thing that keeps you up at night?\"\n  - \"Where do you actually find your best ideas? I'm always curious about this.\"\n\n  EXAMPLES of BAD formal/corporate questions to AVOID:\n  - \"What challenges do you face in your creative process?\" (too formal)\n  - \"How do you align your content with your organizational mission?\" (corporate speak)\n  - \"What are your primary goals when creating content?\" (consultant-speak)\n  - \"What platforms do you use for inspiration and how do they influence your creative process?\" (too wordy/formal)\n\n  TONE & LANGUAGE REQUIREMENTS:\n  - Write questions like you're having coffee with a friend who does this work\n  - Use casual, natural language - avoid formal research-speak\n  - Be genuinely curious, not corporate or consultant-like\n  - Include contractions, casual phrases, personal touches\n  - Ask about real, specific situations they've experienced\n  - Show you understand their world (tools, platforms, community, struggles)\n\n  GUIDELINES:\n    1) Questions must be conversational, open-ended, and genuinely curious.\n    2) Include natural follow-ups in the question text when helpful.\n    3) Tailor specifically to the roles/segments - get into the weeds of their actual work.\n    4) Ask about specific situations, tools, processes they encounter daily.\n    5) Focus on real stories, concrete examples, day-to-day reality.\n    6) Provide balanced coverage across categories:\n       context, goals, pain, workflow, motivation, constraints, willingness, demographics.\n    7) Provide scores in [0,1]: importance (highest signal), goalMatch, novelty.\n    8) New questions must have status 'proposed'.\n    9) CRITICAL: Use completely unique string IDs for questions (uuid/ulid-like). Never reuse IDs. Each question must have a globally unique identifier.\n    10) Sound like a human talking to another human, not a researcher conducting an interview.\n    11) Do NOT use placeholders or template tokens like [relevant process], <thing>, {something}. If specifics are missing, write a complete, neutral phrase without brackets. The final question text must not contain '[' or ']'.\n\n  LENGTH & CLARITY CONSTRAINTS (strict):\n  - Keep each question short and crisp: 8–18 words (target ~12–16 words), max 140 characters.\n  - Do NOT list or restate roles/organizations in the question text; address the interviewee as \"you\".\n  - No long enumerations, comma chains, or multiple clauses; one clear idea per question.\n  - Avoid jargon and qualifiers; prefer simple, conversational phrasing.\n  - Never stitch together multiple audiences (e.g., \"Special Education Teacher, CIO, Clinical Psychologist...\"). Pick a single perspective implicitly via \"you\".\n\n  OUTPUT SHAPE\n  Return only valid JSON with these fields:\n  - categories: Category[] (required - you generate this)\n  - questions: Question[] (required - you generate this)\n  - history: [] (always empty array)\n\n  DO NOT include sessionId, policy, or round - these will be injected by the system.\n\n  HARD CONSTRAINTS\n  - No placeholders or bracketed variables in any question text.\n  - Max 140 characters per question. If longer, rewrite to fit while preserving meaning.\n\n  Return JSON only:\n  {{ ctx.output_format }}\n  \"#\n}\n\n// Follow-up question generation for dive deeper functionality\nclass FollowUpQuestionScores {\n  importance float @description(\"0.0-1.0 how important this follow-up is\")\n  goalMatch float @description(\"0.0-1.0 how well it matches research goals\")\n  novelty float @description(\"0.0-1.0 how novel/unique this angle is\")\n}\n\nclass FollowUpQuestion {\n  id string @description(\"Unique identifier for the follow-up question\")\n  text string @description(\"The follow-up question text\")\n  rationale string @description(\"Why this follow-up question is valuable\")\n  estimatedMinutes int @description(\"Estimated time in minutes to ask this question\")\n  categoryId string @description(\"Category like 'context', 'pain', 'workflow', etc.\")\n  scores FollowUpQuestionScores @description(\"Scoring metrics for this question\")\n}\n\nclass FollowUpSet {\n  originalQuestion string @description(\"The question we're diving deeper on\")\n  followUps FollowUpQuestion[] @description(\"2-4 follow-up questions\")\n}\n\nfunction GenerateFollowUpQuestions(\n  original_question: string,\n  research_context: string,\n  target_roles: string,\n  custom_instructions: string\n) -> FollowUpSet {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher generating follow-up questions to dive deeper into a specific topic.\n\n    ORIGINAL QUESTION: {{ original_question }}\n\n    RESEARCH CONTEXT: {{ research_context }}\n    TARGET ROLES: {{ target_roles }}\n\n    CUSTOM INSTRUCTIONS (follow these strictly):\n    {{ custom_instructions }}\n\n    TASK: Generate 2-4 thoughtful follow-up questions that dive deeper into the original question. These should:\n\n    1. Explore different angles of the original question\n    2. Uncover underlying motivations, pain points, or workflows\n    3. Ask for specific examples or stories\n    4. Probe for emotional responses or deeper context\n\n    QUALITY GUIDELINES:\n    - Make questions conversational and natural\n    - Avoid yes/no questions - prefer open-ended\n    - Ask for specific examples: \"Can you walk me through...\" or \"Tell me about a time when...\"\n    - Probe for emotions: \"How did that make you feel?\" or \"What was most frustrating about...\"\n    - Explore impact: \"What would happen if...\" or \"How does this affect your...\"\n    - Be specific to the target audience ({{ target_roles }})\n\n    CATEGORIES to use:\n    - context: Background and situational questions\n    - pain: Problems, frustrations, challenges\n    - workflow: Process, behavior, how things work\n    - goals: Motivations, desired outcomes\n    - constraints: Limitations, barriers\n    - willingness: Adoption, willingness to change\n    - demographics: Role, tenure, team size, seniority, geography, org size, etc.\n\n    SCORING:\n    - importance: 0.7-1.0 (these are follow-ups to important questions)\n    - goalMatch: 0.6-0.9 (should align well with research goals)\n    - novelty: 0.4-0.8 (varies by how unique the angle is)\n\n    ESTIMATED TIME:\n    - Simple clarification: 2-3 minutes\n    - Story/example requests: 4-5 minutes\n    - Complex scenario discussion: 5-6 minutes\n\n    KEEP THEM BRIEF:\n    - 6–16 words (max 120 characters) per follow-up.\n    - No role/organization lists; address the person as \"you\".\n\n    Return exactly {{ ctx.output_format }}\n  \"#\n}\n\ntest GenerateQuestionSet_Custom_Instructions2 {\n  functions [GenerateQuestionSet]\n  args {\n\t\tinputs {\n    target_org \"Regional nonprofit hospital network (6 clinics, 450-bed hospital)\",\n    target_roles \"Patients (outpatient), Front-desk staff, Nurses, Primary-care physicians\",\n    research_goal \"Improve patient intake and follow-up experience\",\n    research_goal_details \"Reduce waiting time, clarify instructions, and raise follow-up adherence for chronic care patients (diabetes, hypertension).\",\n    assumptions \"Patients miss follow-ups due to confusing discharge instructions; staff tools are fragmented.\",\n    unknowns \"Which steps create the most confusion? How do staff prioritize time? What would increase adherence?\",\n    custom_instructions \"Favor plain language for patients 8th-grade reading level; include at least 2 questions about accessibility and language.\",\n    session_id \"proj_health_001\",\n    round 1,\n    total_per_round 8,\n    per_category_min 1,\n    per_category_max 4\n\t}\n  }\n}\n",
  "research_analysis.tests.baml": "test GenerateQuestionSet_Pizza_Needs {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"mom and pop pizza shops\"\n    target_roles \"small business owners\"\n    research_goal \"understand operational needs\"\n    research_goal_details \"Identify key pain points and operational challenges facing small pizza shop owners\"\n    assumptions \"Pizza shops struggle with staffing and inventory management\"\n    unknowns \"What specific operational challenges cause the most impact on profitability\"\n    custom_instructions \"\"\n    session_id \"test_pizza_001\"\n    round 1\n    total_per_round 8\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 30\n  } }\n}\n\ntest GenerateQuestionSet_Salon_Scheduling {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Independent salons and neighborhood barbershops\"\n    target_roles \"Salon owners, Barbers, Front-desk staff\"\n    research_goal \"Improve appointment scheduling and reduce no‑shows\"\n    research_goal_details \"Explore booking flow, reminders, walk‑ins vs. appointments, and peak‑time bottlenecks\"\n    assumptions \"SMS reminders reduce no‑shows; most rescheduling happens within 24 hours\"\n    unknowns \"Where do booking mistakes happen? Which reminders actually get noticed? How do walk‑ins impact schedule?\"\n    custom_instructions \"Avoid placeholders; keep questions conversational and specific to salons and barbers.\"\n    session_id \"test_salon_sched_001\"\n    round 1\n    total_per_round 8\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 30\n  } }\n}\n\ntest GenerateQuestionSet_Journaling_Moms {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Consumer mobile apps (wellness & journaling)\"\n    target_roles \"Moms of young kids, Caregivers\"\n    research_goal \"Understand journaling habits, constraints, and motivations for busy moms\"\n    research_goal_details \"When/where they journal, prompts that help, barriers (time/energy), privacy needs, notifications\"\n    assumptions \"Short prompts lower friction; voice capture helps when hands are busy\"\n    unknowns \"Which moments are most journal‑worthy? What keeps streaks going? What feels intrusive?\"\n    custom_instructions \"Friendly tone. No template brackets. Prefer ‘Tell me about…’ and ‘Walk me through…’ when helpful.\"\n    session_id \"test_journaling_moms_001\"\n    round 1\n    total_per_round 10\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 45\n  } }\n}\n\ntest GenerateQuestionSet_SaaS_Willingness {\n  functions [GenerateQuestionSet]\n  args { inputs {\n\t\ttarget_org \"HealthCareVibe\"\n\t\ttarget_roles \"Founding CEO, CTO, CMO\"\n\t\tresearch_goal \"willingness to adopt our healthcare technology\"\n\t\tresearch_goal_details \"We are a healthcare technology company and are looking to understand the willingness of healthcare providers to adopt our platform.\"\n\t\tassumptions \"Healthcare providers are willing to adopt our technology but may have concerns about integrating our platform into their existing systems.\"\n\t\tunknowns \"We are unsure how healthcare providers will perceive our technology and how much they will be willing to pay for it.\"\n\t\tcustom_instructions \"Please generate a list of 5-10 questions to interview healthcare providers about their willingness to adopt our technology. Include questions about their concerns about integrating our platform, their perception of our technology, and their willingness to pay for our services. Please also include questions about their current technology stack and how they currently manage their patient data.\"\n\t\tsession_id \"test_healthcare_001\"\n\t\tround 1\n\t\ttotal_per_round 10\n\t\tper_category_min 1\n\t\tper_category_max 3\n\t\tinterview_time_limit 30\n  }\n\t}\n}\n\ntest GenerateQuestionSet_Custom_Instructions {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Regional nonprofit hospital network (6 clinics, 450-bed hospital)\"\n    target_roles \"Patients (outpatient), Front-desk staff, Nurses, Primary-care physicians\"\n    research_goal \"Improve patient intake and follow-up experience\"\n    research_goal_details \"Reduce waiting time, clarify instructions, and raise follow-up adherence for chronic care patients (diabetes, hypertension).\"\n    assumptions \"Patients miss follow-ups due to confusing discharge instructions; staff tools are fragmented.\"\n    unknowns \"Which steps create the most confusion? How do staff prioritize time? What would increase adherence?\"\n    custom_instructions \"Favor plain language for patients 8th-grade reading level; include at least 2 questions about accessibility and language.\"\n    session_id \"proj_health_001\"\n    round 1\n    total_per_round 8\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 45\n  } }\n}\n\ntest GenerateQuestionSet_Validation_Mode {\n  functions [GenerateQuestionSet]\n  args { inputs {\n    target_org \"Early-stage SaaS startups\"\n    target_roles \"Founders, Heads of Product\"\n    research_goal \"Validate whether the onboarding problem is painful enough to pay for\"\n    research_goal_details \"Focus on evidence for the four validation gates: pain, awareness, quantified impact, acting.\"\n    assumptions \"Teams are losing trial users during onboarding and already track the impact manually.\"\n    unknowns \"How do they measure churn today? What action do they take when onboarding fails?\"\n    custom_instructions \"Keep prompts short and conversational.\"\n    research_mode \"validation\"\n    session_id \"validation_sample_001\"\n    round 1\n    total_per_round 12\n    per_category_min 1\n    per_category_max 3\n    interview_time_limit 30\n  } }\n}\n\ntest GenerateExecutiveSummary_Pizza_Basic {\n  functions [GenerateExecutiveSummary]\n  args {\n    research_goal \"understand operational challenges for pizza shop owners\"\n    insights_content #\"\"\"\nPizza shop owners face three major operational challenges:\n\n1. **Staff Scheduling**: Manual scheduling takes 3-5 hours weekly\n2. **Inventory Waste**: 15-20% food waste due to poor forecasting\n3. **Technology Overwhelm**: Current POS systems too complex\n\nKey findings from 2 interviews with pizza shop owners.\n\"\"\"#\n    interview_content #\"\"\"\nTony (Pizza Palace, 8 years):\n- Biggest challenge: finding reliable part-time staff\n- Uses spreadsheets for everything\n- Rush hour wait time complaints\n\nMaria (Mama Mia's, 15 years):\n- Family business struggling with rising costs\n- Paper schedules, constant sick callouts\n- Would pay for time-saving solutions\n\"\"#,\n\t\t\t\t\tcustom_instructions \"\"\n\t\t\t\t}\n\n}\n",
  "research_lens_extraction.baml": "// Research Lens Extraction (Usability + Validation)\n//\n// Extracts usability findings, hypothesis validation, user journey insights, and research learnings\n\n// ============================================================================\n// Core Research Classes\n// ============================================================================\n\nclass UsabilityFinding {\n  finding_description string @description(\"Description of the usability issue or observation\")\n  severity string @description(\"Severity: 'critical', 'major', 'minor', 'enhancement'\")\n  affected_feature string? @description(\"Specific feature or workflow affected\")\n  user_behavior string @description(\"What the user did or tried to do\")\n  user_expectation string @description(\"What the user expected to happen\")\n  actual_result string @description(\"What actually happened\")\n  suggested_fix string? @description(\"Potential solution or recommendation\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this finding\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n}\n\nclass HypothesisValidation {\n  hypothesis_statement string @description(\"The hypothesis being tested or discussed\")\n  validation_result string @description(\"Result: 'validated', 'invalidated', 'partially_validated', 'inconclusive'\")\n  supporting_evidence string[] @description(\"Evidence that supports or refutes the hypothesis\")\n  confidence_level string @description(\"Confidence: 'high', 'medium', 'low'\")\n  implications string @description(\"What this means for the product or research direction\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this validation\")\n}\n\nclass UserJourneyInsight {\n  journey_stage string @description(\"Stage: 'awareness', 'consideration', 'purchase', 'onboarding', 'usage', 'retention', 'expansion'\")\n  insight_description string @description(\"Key insight about this journey stage\")\n  pain_points string[] @description(\"Pain points encountered at this stage\")\n  moments_of_delight string[] @description(\"Positive experiences at this stage\")\n  opportunity_area string? @description(\"Opportunity to improve this stage\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this insight\")\n}\n\nclass BehaviorPattern {\n  pattern_description string @description(\"Description of the observed behavior pattern\")\n  frequency string @description(\"How common: 'very_common', 'common', 'occasional', 'rare'\")\n  user_segment string? @description(\"Which user segment exhibits this pattern\")\n  triggers string[] @description(\"What triggers this behavior\")\n  implications string @description(\"What this pattern means for product design\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this pattern\")\n}\n\nclass ResearchQuestionInsight {\n  question string @description(\"The research question raised\")\n  status string @description(\"Status: 'answered', 'partially_answered', 'unanswered'\")\n  answer string? @description(\"The answer if found\")\n  follow_up_needed string? @description(\"What follow-up research is needed\")\n  evidence_ids string[] @description(\"IDs of evidence related to this question\")\n}\n\nclass MentalModel {\n  model_description string @description(\"Description of user's mental model or understanding\")\n  matches_product bool @description(\"Does their mental model match how the product actually works?\")\n  gap_description string? @description(\"If not, what's the gap between their model and reality?\")\n  design_recommendation string? @description(\"How to align product with user mental model\")\n  evidence_ids string[] @description(\"IDs of evidence supporting this mental model\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass ResearchLensExtraction {\n  usability_findings UsabilityFinding[] @description(\"Usability issues and observations\")\n  hypothesis_validations HypothesisValidation[] @description(\"Hypotheses tested or discussed\")\n  journey_insights UserJourneyInsight[] @description(\"Insights across the user journey\")\n  behavior_patterns BehaviorPattern[] @description(\"Observed behavioral patterns\")\n  research_questions ResearchQuestionInsight[] @description(\"Research questions raised or answered\")\n  mental_models MentalModel[] @description(\"User mental models uncovered\")\n  key_learnings string[] @description(\"Top 3-5 key research learnings\")\n  recommended_next_research string[] @description(\"Recommended follow-up research\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractResearchLens(\n  evidence_json: string,\n  interview_context: string\n) -> ResearchLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert UX researcher analyzing interview evidence to extract usability findings, validate hypotheses, and understand user behavior.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence and extract comprehensive research insights:\n\n    ### Usability Findings\n    - Identify where users struggled, got confused, or had friction\n    - Note the severity based on impact on user experience\n    - Capture what they tried to do vs what happened\n    - Include their expectations vs reality\n    - Suggest potential fixes based on the issue\n\n    ### Hypothesis Validation\n    - Look for evidence that validates or invalidates assumptions\n    - \"I thought users would...\", \"We assumed...\", \"We believed...\"\n    - Assess confidence level based on strength of evidence\n    - Note implications for product decisions\n\n    ### User Journey Insights\n    - Map insights to specific stages of the user journey\n    - Identify pain points and moments of delight at each stage\n    - Look for opportunities to improve the journey\n    - Focus on transitions between stages\n\n    ### Behavior Patterns\n    - Recurring behaviors or habits mentioned\n    - How frequently these patterns occur\n    - What triggers these behaviors\n    - Implications for product design and features\n\n    ### Research Questions\n    - Questions that were answered during the interview\n    - New questions that emerged\n    - Gaps in understanding that need follow-up research\n\n    ### Mental Models\n    - How users think about or understand the product/domain\n    - Metaphors or analogies they use\n    - Mismatches between their model and actual product behavior\n    - Recommendations to align product with their mental model\n\n    ### Key Learnings\n    - 3-5 most important research insights\n    - Focus on actionable findings\n    - Connect to user needs and product decisions\n\n    ### Recommended Next Research\n    - Follow-up questions to explore\n    - Hypotheses to test in future research\n    - User segments or scenarios to study further\n\n    Be specific and evidence-based. Always link back to evidence IDs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "research_questions.baml": "// Nested Research Questions & Interview Prompts generation\n// Input: goal + decision questions (+ optional audience context)\n// Output: plan with decision_questions[], research_questions[], interview_prompts[], other_data_sources[]\n\nclass DecisionQuestionOut {\n  id string @description(\"Unique UUID. Do not use PII.\")\n  text string @description(\"The business decision the user needs to make\")\n  rationale string @description(\"Why this decision is important for achieving the user's goal\")\n  key_metrics string[] @description(\"Concrete metrics that would inform this business decision\")\n  risks_if_wrong string[] @description(\"Business risks if this decision is made incorrectly\")\n}\n\nclass ResearchQuestionOut {\n  id string @description(\"Unique UUID\")\n  dq_id string @description(\"Links to DecisionQuestionOut.id\")\n  text string @description(\"The research question that needs to be answered to inform the decision\")\n  rationale string @description(\"How answering this research question will help make the business decision\")\n  evidence_types string[] @description(\"Types of evidence needed: QUOTES, ANALYTICS, SURVEY, EXPERIMENT, OBSERVATIONS, MARKET_DATA\")\n  suggested_methods string[] @description(\"Research methods to gather this evidence (e.g., user interviews, analytics analysis)\")\n}\n\nclass InterviewPromptOut {\n  id string @description(\"Unique UUID\")\n  rq_ids string[] @description(\"Links to ResearchQuestionOut.id\")\n  text string @description(\"Open-ended question to ask interviewees to gather evidence for the research question\")\n  followups string[] @description(\"Follow-up questions to ask interviewees to dig deeper\")\n  bias_checks string[] @description(\"Reminders to keep questions neutral and avoid leading the interviewee\")\n}\n\nclass ResearchPlanOut {\n  goal string @description(\"The user's business goal they want to achieve\")\n  decision_questions DecisionQuestionOut[] @description(\"Business decisions the user needs to make\")\n  research_questions ResearchQuestionOut[] @description(\"Questions that need to be answered to inform decisions\")\n  interview_prompts InterviewPromptOut[] @description(\"Questions to ask interviewees to gather evidence\")\n  other_data_sources string[] @description(\"Additional data sources beyond interviews (analytics, surveys, etc.)\")\n}\n\nfunction GenerateNestedResearchQuestions(\n  goal: string,\n  decision_questions: string[],\n  target_orgs: string,\n  target_roles: string,\n  custom_instructions: string\n) -> ResearchPlanOut {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert UX researcher creating a research plan that connects business decisions to interview questions.\n\n    CONTEXT - USER'S BUSINESS SITUATION:\n    - Business Goal: {{ goal }}\n    - Key Decisions They Need to Make:\n    {% for dq in decision_questions %}\n      - {{ dq }}\n    {% endfor %}\n    - Target Interview Participants: {{ target_roles }} at {{ target_orgs }}\n\n    IMPORTANT DISTINCTION:\n    - The USER is the one with the business goal and decisions to make\n    - The INTERVIEWEES are {{ target_roles }} who will be interviewed to provide insights\n    - Interview questions should ask interviewees about THEIR experiences, not the user's business decisions\n\n    If custom instructions are provided, follow them strictly:\n    CUSTOM INSTRUCTIONS:\n    {{ custom_instructions }}\n\n    REQUIREMENTS:\n\n    1) decision_questions: For each business decision the user needs to make:\n       - id: sequential like dq1, dq2, ...\n       - text: clear business decision the user faces\n       - rationale: why this decision matters for achieving their business goal\n       - key_metrics: 2-4 concrete metrics that would inform this business decision\n       - risks_if_wrong: 1-3 business risks if decided incorrectly\n\n    2) research_questions: For each decision, create 1-3 research questions that need answers:\n       - id: rq{dq index}{letter} e.g., rq1a, rq1b, ...\n       - dq_id: link to the parent decision question id\n       - text: what needs to be learned from {{ target_roles }} to inform the business decision\n       - rationale: how this research insight will help make the business decision\n       - evidence_types: 1-3 tags (QUOTES, ANALYTICS, SURVEY, EXPERIMENT, OBSERVATIONS, MARKET_DATA, SUPPORT_TICKETS, BETA_LOGS)\n       - suggested_methods: 1-3 methods (e.g., user interviews, segmented analytics, A/B test, survey)\n\n    3) interview_prompts: Create interview questions to ask {{ target_roles }} at {{ target_orgs }}:\n       - id: ip1, ip2, ...\n       - rq_ids: one or more linked research question ids\n       - text: OPEN-ENDED question asking interviewees about THEIR experiences, behaviors, or perspectives (NOT about the user's business decisions)\n       - followups: 2-3 follow-up questions to dig deeper into the interviewee's experiences\n       - bias_checks: 1-2 reminders to keep questions neutral and avoid leading the interviewee\n\n    4) other_data_sources: 2-4 additional data sources beyond interviews (analytics, logs, competitor research, surveys, etc.).\n\n    INTERVIEW QUESTION GUIDELINES:\n    - Ask interviewees about THEIR experiences, not the user's business\n    - Use \"Tell me about...\" \"Walk me through...\" \"Describe...\" formats\n    - Focus on behaviors, motivations, pain points, and decision-making processes\n    - Avoid yes/no questions and leading language unless the question_category is 'demographic' or intentionally very specific\n    - Make questions specific to {{ target_roles }} at {{ target_orgs }}\n    - Example: Instead of \"How should we improve our pricing?\" ask \"Tell me about your experience evaluating and choosing between similar products or services\"\n\n    Return only valid JSON that matches the schema exactly:\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "sales_lens_extraction.baml": "// Sales Lens BANT Extraction\n//\n// Extracts Budget, Authority, Need, Timeline (BANT) framework data from evidence.\n// Also identifies stakeholder roles, next steps, and deal qualification signals.\n\n// ============================================================================\n// Core BANT Classes\n// ============================================================================\n\nclass BudgetInfo {\n  has_budget_discussion bool @description(\"Whether budget was explicitly discussed\")\n  amount_mentioned string? @description(\"Any specific amount or range mentioned (e.g., '$50K', '100-150K range')\")\n  budget_status string? @description(\"Status: 'approved', 'pending', 'not_discussed', 'insufficient', or 'flexible'\")\n  pricing_sensitivity string @description(\"Sensitivity level: 'high', 'medium', or 'low'\")\n  payment_terms string? @description(\"Payment structure if mentioned (e.g., 'annual contract', 'per seat', 'usage-based')\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  supporting_quote string? @description(\"Most relevant verbatim quote about budget\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass AuthorityInfo {\n  decision_maker_identified bool @description(\"Whether a clear decision maker was identified\")\n  decision_maker_name string? @description(\"Name of the decision maker if known\")\n  decision_maker_role string? @description(\"Role/title of decision maker (e.g., 'VP Engineering', 'CEO')\")\n  approval_process string? @description(\"Described approval process (e.g., 'needs board approval', 'can decide independently')\")\n  stakeholders_involved string[] @description(\"Other stakeholders involved in decision\")\n  blockers string[] @description(\"Identified blockers or obstacles (e.g., 'CFO concerned about cost', 'legal review required')\")\n  political_dynamics string? @description(\"Any power dynamics or politics mentioned\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass NeedInfo {\n  primary_pain_points string[] @description(\"Top 3-5 pain points or needs expressed\")\n  pain_severity string @description(\"Overall severity: 'critical', 'significant', 'moderate', or 'minor'\")\n  impact_on_business string? @description(\"How the problem impacts their business\")\n  current_workarounds string[] @description(\"Current solutions or workarounds they're using\")\n  must_have_features string[] @description(\"Features they explicitly said are must-haves\")\n  nice_to_have_features string[] @description(\"Features that are desirable but not critical\")\n  competing_priorities string[] @description(\"Other projects or initiatives competing for attention\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass TimelineInfo {\n  urgency_level string @description(\"Urgency: 'immediate', 'high', 'medium', or 'low'\")\n  target_date string? @description(\"Specific date or timeframe mentioned (e.g., 'Q1 2025', 'by March', 'within 3 months')\")\n  deadline_type string? @description(\"Type of deadline: 'hard_deadline', 'soft_target', 'flexible', or 'no_deadline'\")\n  implementation_timeline string? @description(\"Expected implementation timeframe\")\n  external_drivers string[] @description(\"External factors driving timeline (e.g., 'end of fiscal year', 'product launch')\")\n  confidence float @description(\"Confidence in this assessment (0.0 to 1.0)\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass NextStepInfo {\n  action_item string @description(\"Specific action to be taken\")\n  owner string? @description(\"Who is responsible (name or role)\")\n  due_date string? @description(\"When it should be done\")\n  commitment_level string @description(\"Level of commitment: 'firm', 'tentative', or 'vague'\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this\")\n}\n\nclass StakeholderRole {\n  person_name string @description(\"Name of the CUSTOMER stakeholder (NOT internal team members like sales reps)\")\n  person_role string? @description(\"Their job title or role at the CUSTOMER organization\")\n  role_type string @description(\"Buying role: MUST be one of: 'economic_buyer', 'decision_maker', 'influencer', 'champion', or 'blocker'. Only for customer-side people.\")\n  influence_level string @description(\"Influence level: 'high', 'medium', or 'low'\")\n  sentiment string @description(\"Their sentiment toward the solution: 'positive', 'neutral', 'negative', or 'skeptical'\")\n  key_concerns string[] @description(\"Their main concerns or objections\")\n  key_motivations string[] @description(\"What motivates them about this solution\")\n  evidence_ids string[] @description(\"IDs of evidence pieces that support this assessment\")\n}\n\nclass DealQualificationSignals {\n  positive_signals string[] @description(\"Positive signals that indicate a qualified opportunity\")\n  warning_flags string[] @description(\"Warning flags or red flags to watch out for\")\n  overall_qualification string @description(\"Overall assessment: 'highly_qualified', 'qualified', 'somewhat_qualified', or 'not_qualified'\")\n  recommended_actions string[] @description(\"Recommended next actions based on qualification\")\n}\n\n// ============================================================================\n// Main Output Schema\n// ============================================================================\n\nclass SalesLensExtraction {\n  budget BudgetInfo @description(\"Budget information and constraints\")\n  authority AuthorityInfo @description(\"Decision-making authority and process\")\n  need NeedInfo @description(\"Customer needs and pain points\")\n  timeline TimelineInfo @description(\"Timeline and urgency information\")\n  next_steps NextStepInfo[] @description(\"Agreed-upon next steps and action items\")\n  stakeholders StakeholderRole[] @description(\"Stakeholder analysis and roles\")\n  deal_qualification DealQualificationSignals @description(\"Deal qualification assessment\")\n  key_insights string[] @description(\"Top 3-5 strategic insights for the sales team\")\n  risks_and_concerns string[] @description(\"Identified risks or concerns to address\")\n}\n\n// ============================================================================\n// Main Extraction Function\n// ============================================================================\n\nfunction ExtractSalesLensBant(\n  evidence_json: string,\n  interview_context: string\n) -> SalesLensExtraction {\n  client CustomGPT4o\n\n  prompt #\"\n    You are an expert sales analyst extracting BANT (Budget, Authority, Need, Timeline) framework information from customer interview evidence.\n\n    ## Interview Context\n    {{ interview_context }}\n\n    ## Evidence from Interview\n    {{ evidence_json }}\n\n    ## Instructions\n\n    Analyze the evidence above and extract comprehensive BANT information. For each assessment:\n    1. Base your analysis ONLY on the evidence provided - do not infer beyond what's stated\n    2. Always include the evidence_ids that support each claim\n    3. Use verbatim quotes when available for supporting_quote fields\n    4. Assign confidence scores based on clarity and specificity of evidence\n    5. Identify stakeholder dynamics and power structures\n\n    ### Budget\n    - Look for: pricing discussions, budget constraints, cost concerns, ROI conversations, payment terms\n    - Assess sensitivity based on how much they focus on price vs value\n    - Include specific amounts if mentioned, even if approximate\n\n    ### Authority\n    - Identify who has decision-making power\n    - Map the approval process and stakeholders involved\n    - Flag any blockers or political dynamics\n    - Note if they're speaking independently or need buy-in\n\n    ### Need\n    - Extract all pain points mentioned, ranked by severity\n    - Understand business impact of these problems\n    - Distinguish between must-haves and nice-to-haves\n    - Note current workarounds or competing solutions\n\n    ### Timeline\n    - Assess urgency level based on language used\n    - Extract any specific dates or timeframes\n    - Identify external drivers (fiscal year, product launches, etc.)\n    - Determine if deadlines are hard requirements or soft targets\n\n    ### Stakeholders\n    - IMPORTANT: Only identify CUSTOMER-SIDE stakeholders (prospects, clients, decision makers from the customer organization)\n    - EXCLUDE internal team members (sales reps, account executives, customer success, support staff, etc.) - they are NOT stakeholders\n    - Example: If \"DJ\" is conducting the interview or representing your company, DO NOT include them as economic_buyer or decision_maker\n    - Example: If \"Stephen\" is the prospect being interviewed, include them with appropriate customer-side role (e.g., decision_maker, influencer)\n    - Map each CUSTOMER stakeholder to a buying role (economic_buyer, decision_maker, influencer, champion, blocker)\n    - Assess their influence level and sentiment\n    - Identify their specific concerns and motivations\n    - This is CRITICAL for navigating complex B2B sales\n\n    ### Next Steps\n    - Extract specific, actionable commitments\n    - Note who owns each action and when it's due\n    - Assess commitment level (firm vs tentative)\n\n    ### Deal Qualification\n    - Identify positive signals (strong need, clear budget, engaged champion, etc.)\n    - Flag warning signs (lack of urgency, no clear authority, vague needs, etc.)\n    - Provide an overall qualification assessment\n    - Recommend specific actions to advance or qualify out\n\n    ## Output Requirements\n    - Be specific and evidence-based\n    - Always link back to evidence IDs\n    - Use confidence scores to indicate certainty\n    - Provide actionable insights for the sales team\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "synthesize_cross_lens.baml": "// Cross-lens synthesis: takes ALL lens analyses across a project and produces\n// an executive-level summary that spans every lens type.\n//\n// Unlike per-lens synthesis (which only looks at one template at a time),\n// this function sees the full picture: BANT + Discovery + Empathy + custom lenses\n// combined into a single overview with key findings and recommended actions.\n\nclass CrossLensFinding {\n  title string @description(\"Short headline, 5-10 words\")\n  description string @description(\"2-3 sentence explanation of the finding\")\n  severity \"critical\" | \"important\" | \"notable\"\n  people_count int @description(\"How many unique people this finding relates to\")\n  mention_count int @description(\"Total mentions across all lenses\")\n  category string @description(\"Topic bucket: pricing, product, onboarding, competition, etc.\")\n  supporting_lenses string[] @description(\"Which lens templates contributed to this finding\")\n}\n\nclass CrossLensRecommendedAction {\n  title string @description(\"Actionable task title, imperative mood\")\n  description string @description(\"Why this matters and what to do\")\n  priority \"high\" | \"medium\" | \"low\"\n  category string @description(\"Product, Sales, Support, Research, etc.\")\n}\n\nclass PersonSnapshot {\n  person_name string\n  role string?\n  organization string?\n  key_needs string[] @description(\"Top 2-3 needs or pain points\")\n  engagement_signal string @description(\"One-line assessment: champion, evaluator, blocker, etc.\")\n}\n\nclass CrossLensSynthesisResult {\n  executive_summary string @description(\"3-5 paragraph overview of ALL findings across ALL lenses. Written for a busy founder/PM. Lead with the most important insight.\")\n  key_findings CrossLensFinding[] @description(\"5-8 key findings sorted by severity. Cross-reference across lens types.\")\n  person_snapshots PersonSnapshot[] @description(\"Brief snapshot of each person mentioned, with their key needs and engagement level\")\n  recommended_actions CrossLensRecommendedAction[] @description(\"3-6 concrete next steps. Prioritized. Each should be actionable.\")\n  patterns string[] @description(\"2-4 macro patterns visible only when looking across all lens types\")\n  risks string[] @description(\"1-3 risks or blind spots identified\")\n  overall_confidence float @description(\"0.0-1.0 average confidence across all analyses\")\n  analysis_count int\n  lens_count int\n}\n\nfunction SynthesizeCrossLensInsights(\n  project_context: string,\n  lens_summaries_json: string,\n  all_analyses_json: string,\n  people_context: string?,\n  custom_instructions: string?\n) -> CrossLensSynthesisResult {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert insight synthesizer for a customer intelligence platform.\n    You have access to analyses from MULTIPLE different lens types applied to the\n    same set of conversations. Your job is to produce a unified executive briefing.\n\n    ## Project Context\n    {{ project_context }}\n\n    ## Per-Lens Summaries (already synthesized per lens type)\n    {{ lens_summaries_json }}\n\n    ## All Individual Analyses (raw data across all lenses and conversations)\n    {{ all_analyses_json }}\n\n    {% if people_context %}\n    ## People Context\n    {{ people_context }}\n    {% endif %}\n\n    {% if custom_instructions %}\n    ## Custom Instructions\n    {{ custom_instructions }}\n    {% endif %}\n\n    ## Instructions\n\n    ### Executive Summary\n    Write a 3-5 paragraph overview that a busy founder or PM can read in 60 seconds.\n    - Lead with the single most important finding\n    - Cross-reference findings across lens types (e.g. \"The pricing concerns\n      flagged by the Sales BANT lens align with the pain points identified in\n      Customer Discovery\")\n    - Include concrete numbers: \"7/10 prospects\", \"mentioned by 3 people\"\n    - End with the recommended priority action\n\n    ### Key Findings\n    Identify 5-8 findings that emerge from looking across ALL lenses together.\n    The power of cross-lens analysis is seeing things no single lens reveals:\n    - A BANT-qualified prospect who has deep pains in Discovery = hot lead\n    - A pattern in Empathy Maps that contradicts the Discovery lens = investigate\n    - Consistent themes across 3+ lens types = high-confidence finding\n\n    Sort by severity: critical > important > notable.\n    Track which lenses support each finding.\n\n    ### Person Snapshots\n    For each person mentioned across analyses, create a brief snapshot:\n    - Their top needs (from any lens)\n    - Their engagement signal (champion, evaluator, blocker, neutral)\n    - Their role and organization\n\n    ### Recommended Actions\n    3-6 concrete, actionable next steps. Each should be specific enough to\n    create a task from. Prioritize by impact and urgency.\n\n    ### Patterns\n    2-4 macro patterns only visible from the cross-lens view.\n\n    ### Risks\n    1-3 blind spots or risks the team should be aware of.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
  "synthesize_lens_insights.baml": "// Cross-interview synthesis for aggregated lens views\n// Takes multiple individual lens analyses and synthesizes key takeaways\n\nclass SynthesizedInsight {\n  title string @description(\"Short, actionable title (5-10 words)\")\n  insight string @description(\"The key finding or pattern observed across interviews\")\n  supporting_interviews string[] @description(\"List of interview_ids that support this insight\")\n  confidence float @description(\"0.0-1.0 based on consistency across interviews\")\n  category \"consensus\" | \"pattern\" | \"discrepancy\" | \"recommendation\" @description(\"Type of insight\")\n}\n\nclass FieldSynthesis {\n  field_key string @description(\"The field being synthesized\")\n  field_name string @description(\"Human-readable field name\")\n  consensus_value string? @description(\"If there's consensus, what is it\")\n  value_range string? @description(\"If values vary, show the range\")\n  discrepancies SynthesisDiscrepancy[]? @description(\"Notable conflicts or outliers\")\n  interview_count int @description(\"Number of interviews with data for this field\")\n}\n\nclass SynthesisDiscrepancy {\n  interview_id string\n  interview_title string\n  value string\n  note string @description(\"Why this is notable or different\")\n}\n\nclass SectionSynthesis {\n  section_key string\n  section_name string\n  summary string @description(\"2-3 sentence synthesis of this section across all interviews\")\n  fields FieldSynthesis[]\n}\n\nclass EntityAggregation {\n  entity_type string @description(\"stakeholders, next_steps, objections, etc.\")\n  total_count int\n  top_items string[] @description(\"Most frequently mentioned items\")\n  patterns string? @description(\"Any patterns observed\")\n}\n\nclass LensSynthesisResult {\n  executive_summary string @description(\"3-5 bullet points with the most important cross-interview insights. Each bullet should be concrete and actionable. Use format: KEY_FINDING: detail\")\n  key_takeaways SynthesizedInsight[] @description(\"2-4 synthesized insights from the data\")\n  sections SectionSynthesis[] @description(\"Per-section synthesis with field-level rollup\")\n  entities EntityAggregation[] @description(\"Aggregated entities across interviews\")\n  recommendations string[] @description(\"Actionable next steps based on the synthesis\")\n  conflicts_to_review string[] @description(\"Notable discrepancies that need attention\")\n  overall_confidence float @description(\"Average confidence across synthesized insights\")\n  interview_count int @description(\"Total interviews analyzed\")\n  synthesis_notes string? @description(\"Any caveats or methodology notes\")\n}\n\nfunction SynthesizeLensInsights(\n  template_name: string,\n  template_definition: string,\n  analyses_json: string,\n  custom_instructions: string?\n) -> LensSynthesisResult {\n  client CustomGPT4o\n  prompt #\"\n    You are an expert at synthesizing insights from multiple conversation analyses.\n    You've been given {{ template_name }} lens analyses from multiple interviews.\n    Your job is to find patterns, build consensus, and highlight discrepancies.\n\n    ## Lens Template\n    {{ template_definition }}\n\n    ## Individual Interview Analyses\n    {{ analyses_json }}\n\n    {% if custom_instructions %}\n    ## Custom Instructions\n    {{ custom_instructions }}\n    {% endif %}\n\n    ## Synthesis Instructions\n\n    ### Executive Summary\n    Create a 3-5 bullet executive summary using this format:\n    - KEY_FINDING: Specific detail (N interviews)\n\n    Example:\n    - BUDGET CONSENSUS: $50-100K range confirmed across 4/5 prospects\n    - TIMELINE RISK: 60% have hard Q2 deadlines, 2 need faster\n    - TOP PAIN: Manual data entry mentioned in 8/10 interviews\n    - MISSING: No technical evaluator identified in 3 deals\n\n    ### Key Takeaways\n    Identify 2-4 major insights:\n    - \"consensus\" - Agreement across multiple interviews\n    - \"pattern\" - Recurring theme or behavior\n    - \"discrepancy\" - Notable conflict requiring attention\n    - \"recommendation\" - Action to take based on findings\n\n    ### Section Synthesis\n    For each section in the template:\n    1. Write a 2-3 sentence summary of findings across all interviews\n    2. For each field, determine:\n       - consensus_value: If most interviews agree, what's the answer\n       - value_range: If values vary, show the spectrum\n       - discrepancies: Call out any outliers that need review\n\n    ### Entity Aggregation\n    Aggregate entities (stakeholders, next_steps, objections) across interviews:\n    - Count total occurrences\n    - List most common items\n    - Note any patterns\n\n    ### Recommendations\n    Based on the synthesis, provide 3-5 actionable recommendations.\n\n    ### Conflicts to Review\n    List any significant discrepancies that need human review.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}